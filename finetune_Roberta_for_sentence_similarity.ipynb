{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "T4oNyr44Q328",
    "H9bEBAmTdmd1",
    "pjnqYh30doi7",
    "pj2lyYT1dtf3"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u88zo-xxO5vY"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from huggingface_hub import HfApi, login, hf_hub_download\n",
    "from google.colab import userdata\n",
    "\n",
    "from supplementary_file_for_sentence_similarity import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the tokenizer and a dataset"
   ],
   "metadata": {
    "id": "_L4TSubBPCmT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the tokenizer\n",
    "\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "id": "wg-rNyjRPGE4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "380e7213f07941378531652de79fed6e",
      "bc78d9f0d9a1418496450775c4808bbd",
      "d5c1faf503be4588b63001d2b0786f3f",
      "cfa0b5dd57d94d40a05d91b58c082263",
      "83e164dc5f43401c877e4116dda5de8f",
      "07528653dee24236a9c3458c511a3749",
      "edb4dd55fb894caf953d98de2c33edad",
      "5b5cc64f9cbc4235affa7b520b6f8040",
      "0aa2e730bd58405d9c63275d565cf291",
      "7aa49d5b7487437e9112d4efd82e51b9",
      "ed4a95b3d748463d8ea8bb595b8b143d",
      "720e0c50333340a2b79b9da12880b5e4",
      "36d380ef57fd4d8ead6c86e49b12d550",
      "8433fb5d468f4d4d8d439c118b171de1",
      "303248158bab40f2a761d4300e7ee464",
      "772d19ed026745908a7e3899d47a1cf9",
      "16dbc1a4555145ad96ff3a5961ddb118",
      "f93f53bfca34443689c743ecceae6b95",
      "31c15389d23f408583211c637397ef7d",
      "d934a9075c5341e59a9e91d74ec9e126",
      "f61942da7d874f22b20040556b6cd076",
      "b26dd4361f80453d9f7eb35e055c0a20",
      "f75c1db6cab24c088e498c3116abe6d6",
      "cadba6bcb8374e4cb6c7e70d8b43638b",
      "9a3d815f7b9b40dd950fa0b665facb30",
      "095c324594f747b38929e2629a90a344",
      "21f73afc84fb48419c41709084f95aae",
      "03bf56faef5e4f939440311157336042",
      "8c205e19c477441090076a5c71bdd91f",
      "d300a26096bb45dcb98f8d45f0841a75",
      "14f1d2120b444890898c464d1ac37c77",
      "859a9cb7a4a84e7d910d18ddbf114adc",
      "1d95892583e54a8cacbc7acf4c42ad53",
      "d88280f656de408e8155e04e70e0dc0f",
      "256b49b59bd349ac88313db3c7d352e3",
      "3beda274ded340c480029f8df3d1ab9f",
      "7fb605ace4e4465cbcd9b198f62c7be7",
      "3992317cf56b4c7399f49aec0acc0072",
      "6c75b8c449bb4d25ac5db12ef64492b4",
      "393a95437eba489ca547281d3f6e960d",
      "d5e06d1a90b445afbc5e7a31dee72d7e",
      "a76b71dd63704e9cabe8d9c8223a2042",
      "19ea1af1cdaa4c4695a2e5e8a77c8b80",
      "fa1f646e7c7e459e9aecbbcfbae4dc15",
      "e18be56051a74382885fdc5590d5a11f",
      "af9b6da54a96417f9c3b9d721e2e7271",
      "24402d43d7fb4f9cbfdfdcdc38899fc0",
      "63ae4b352dfd4a709f1bb2cde400866e",
      "b7bd8dd7a82449939655fbd04d8a6aac",
      "3605974769514e1dabd2a62964220ab6",
      "dac0289cc73745fe9a5c2a92bd18722f",
      "950b3e570c2d479da1de78090cbf2fc8",
      "ce0b36fc69754a90943a429cd40d51ca",
      "90177d4b61cf4f96a6099968eb8754dc",
      "6fa50d40c7ef4088ba4de20b2757da3b"
     ]
    },
    "outputId": "8338b7a1-5671-4b5b-e325-6780af27aa17"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "380e7213f07941378531652de79fed6e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "720e0c50333340a2b79b9da12880b5e4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f75c1db6cab24c088e498c3116abe6d6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d88280f656de408e8155e04e70e0dc0f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e18be56051a74382885fdc5590d5a11f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = sentence_similarity_dataloaders(tokenizer)\n",
    "\n",
    "set_seed(42)\n",
    "train_dataloader, val_dataloader, test_dataloader = dataloader.get_dataloaders()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "ad7400cf2d7f4c0688cace48fb884675",
      "c703dfe854494ae098918eeb612563ac",
      "5732ae88c2db4792aa848b3889d3bcbb",
      "51c288c0e7c548dd9ed184179d99bfae",
      "d3737cbc22994659b5114167daf1d1b0",
      "d724f42536b04e7da134364b7568b766",
      "4024111526ca480296cd819afa513bb5",
      "144a562793aa4631952a1413af95c208",
      "1e6eb77fea3d4e36944a7f0dd33788a6",
      "d8906a92c3f541f788f40fcbb986e1d1",
      "91d2ddd933b149f1874808fcc4f5d2d1",
      "4a1756e02189430091d30761413a4cfc",
      "ac1c3af6dd6a4dcca7fdc19d5de23050",
      "5ba0d0557dbe4d56a87ec92eb16828d7",
      "5b34dbf415034f868c9f152e69951d05",
      "7ed66fc7307a439d876aeee709205742",
      "cddc30442fc24438bec5357eed9d790a",
      "dc0abe0d7b504b359eb708bf13895a71",
      "84dd1289f671433798c2f8a51bd18d99",
      "fb6e29aa691e4099a9d8e78fa3bbfd68",
      "48bdd53b823543e594b6ad3e8d192e0f",
      "cd9bae4a2b9d411c9090c6a0cc5865c0",
      "06a3a9cc0a1c4737bfacdf4a14c3f37c",
      "9ca2682a6cdc4da595ed4418fe176a50",
      "e8f3cec48af841c68370d65cb5396433",
      "0885256f6b664af3980d95cd11200dde",
      "1cf541e931de4666ba7a49c88f14b8ec",
      "600b9d6798ec44ca8a3f7b2e979be40c",
      "fe44e038c7644307943ee7a7aa518b0d",
      "fb1d22492a2d4f0a859f6f5c5bc3b67a",
      "4f856c79dad84fedbf29d17d582be100",
      "459f73ad6fd040c8a74ad4ef73df7b48",
      "47060eb48e62443daafe9e684c4b7b71",
      "fb59bd37ba2546a29ea023f77f7e3651",
      "915c520d1f9646d59d8aa66aa73c074a",
      "aaa4f2c2f62642d6922d4f1ffa57d580",
      "12f8324b618f4998a17a12265d50c12e",
      "1aadda3a85bb4f48970aec6f54e98e55",
      "fdab7f9650c241cdbcbd2bcb3f63e32c",
      "3ca614ce138d4249a8b633f88034b41b",
      "9f51d687e1d84a409077c62401756b31",
      "0d3522ec2df84c0e9302dcb01ee9d77c",
      "21de2f0ee16748d38d964929a1a5ae04",
      "ac16cfe4e7ac4481aca63557737ecf42",
      "3adb1107134b42d5bb5d2cd7e3266964",
      "fe25b1a5e73943afb780c81866fe6cc0",
      "4cf19697487f42b9951e33d1782f3462",
      "00f668f4d1a34ec4bff04285f1e4d138",
      "8f09605cd7e14a8cadfe1b789f3f5d09",
      "ff27b2836e0d455095712d8340cfd975",
      "5b13860d3b2043ccaf1338578d99f178",
      "06168d48c1624c66aa5c46c3b743b633",
      "c29c010fe72847bbbb4cf428cd68ac71",
      "56ba4cce6ec54f4dbf4297c77c043174",
      "1db234ca85ba46329f831c985475b1ab",
      "0fdfbfe6adbb42499e5707149a0eb78d",
      "3c98ea8ab6f04b38b30ecd2c61679c55",
      "65a8a561fbe44d1c9266a878746dfdbb",
      "e48127a1b8db48c79d1e28df23d2328d",
      "08fd149de4e84dc583b5cba4eb20779d",
      "92c2270f0e5b414bbc39b2e06182cdb5",
      "4a693624aaa4499290151c7f2cc20a24",
      "f0c8ee2faeea40899a2f407d0066b376",
      "3452cc4eef5148ce9597583851230f69",
      "9109db4405474feaa46184075042f78d",
      "6cf6f97c31b04df384e8d1efe0f3584d",
      "baa014e0d4164f4a935dbbd14b972fac",
      "31596f8d9ecb4563aa0eef3ebcde7681",
      "4b177f7f97414280baf17e90b1a60172",
      "333632b7bda04b709fb8ca91cdc0e4f3",
      "b67882a119fd4c8c8f4abff4a2509f5b",
      "8266cffbe62941409aba2d94dfe44d2e",
      "fd740517347147b2979ff71b93894406",
      "f3bd7624e70e48de93879aae56618f41",
      "1fda32f301054d50ac90de13db467677",
      "f7c3a181efe2498c9fae025a42f122f5",
      "22629a85492d46898675d5acd8858aa8",
      "75f39619309b42959ccc9c76174e1d59",
      "6a009589105143fbba21ba8cf2fc21f5",
      "1af183e5110d41b190191be12c1478bd",
      "de0006b3a3e544d39db8548c967703bb",
      "3bf0fc2520ed43ad856f2d2f3a915981",
      "98eedcb269fb45e7815532f42142475e",
      "7d7cf106aba246de9631ddcaf08a3fd8",
      "f05365f623e8498983dc4e3c4c2177e7",
      "fe5554a2f09b49c89887753b28d53c5f",
      "7411245a5df948e2929e6bdabbf404d8",
      "c8e48de1dc8f4adfb33b3ea93b571bc6",
      "c8dbfff3a7744cf9858d095ae080f57f",
      "4ec459f00bd74705b00e1eab601c52e0",
      "175ebafff8304ac691bac3c60ee9772b",
      "c729a1f0b3a342649c28a516a5217a61",
      "f9afba29196c44c3846b1987c2e9ee03",
      "f7780a856af64e1cab0f75d1bfdbccc7",
      "214a8fd6aee1456e8ab9d2fed7ef9f7d",
      "8222b86fd7674dff8d9ef57080ea64da",
      "22d6166ea31d4813a5c7e157febc20c8",
      "9dec3e26983b4673b7f4ff1dd4d0a459",
      "198b8b3f79f249ee9d9a525c8ba187b2",
      "3ca87dd0a0fe4cde9bbaca18871b8e5f",
      "698b5843cc1e4fed80f8b0ac24d113a0",
      "375a89cae23846aabb1742fc59e10fde",
      "d4e2ea518f8c4d678765e5e987b024b2",
      "04fdaa5008fc46b98aaec6960131e3bd",
      "1db7479155134929bc6a66d116d9dc4c",
      "d7b051211df748b8b77e9793bba4a629",
      "aa48e8089d524374bd923cbe33c1d818",
      "39c23fa980c244729362f3ffe4daab94",
      "50f4d09f02a5413b8fc6cc8af6fc322b",
      "bc09a99709a7483690fdef57a89c285d"
     ]
    },
    "id": "z2Fx9p0qB4ri",
    "outputId": "5d8a53f7-6c4c-494f-d217-b01b02401039"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad7400cf2d7f4c0688cace48fb884675"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4a1756e02189430091d30761413a4cfc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06a3a9cc0a1c4737bfacdf4a14c3f37c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb59bd37ba2546a29ea023f77f7e3651"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3adb1107134b42d5bb5d2cd7e3266964"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fdfbfe6adbb42499e5707149a0eb78d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "baa014e0d4164f4a935dbbd14b972fac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75f39619309b42959ccc9c76174e1d59"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8dbfff3a7744cf9858d095ae080f57f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ca87dd0a0fe4cde9bbaca18871b8e5f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Experiments"
   ],
   "metadata": {
    "id": "T4oNyr44Q328"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr_list = [1e-5, 3e-5, 5e-5]\n",
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "PqytZjpiXnjN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 137"
   ],
   "metadata": {
    "id": "H9bEBAmTdmd1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(137)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e25dcc2bb069488c99ef35e28100388c",
      "b6dc8cccabcf4af7aa5fd88bbc14699b",
      "701fa7f19c59489b979665c64d2b9839",
      "dc0187d8d2ee4e308bd2ae1686c1289c",
      "a949b9dc49484c5b85f4163cdcb60c04",
      "a637542a94db46f5aed3e17d693da898",
      "3a80ac3bdd6a4f3eaa8cc88eefd91afa",
      "f97f55fd70684766bb5251b3eb038b11",
      "e66919805f414480bd65c558caa7793d",
      "4157ca036954428582f96251b018dbc0",
      "ca01d9f374cc4a5dbf56a11f2ccfc6fa"
     ]
    },
    "id": "mwqNqM-Jk3W3",
    "outputId": "c67218bb-e16e-42ac-db81-c7887591a1fd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e25dcc2bb069488c99ef35e28100388c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.7095115031551951 --validation loss: 0.710458541617674 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.6192328661095863 --validation loss: 0.6165644386235405 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6095815974253195 --validation loss: 0.6076498849719179 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6517966723714779 --validation loss: 0.6414962951459137 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.5148398482721616 --validation loss: 0.5041248327961155 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 250 -- training loss: 0.43404882982340776 --validation loss: 0.4147685043075505 -- validation accuracy 0.7965686274509803\n",
      "Epoch 0 Step 300 -- training loss: 0.4147768060155294 --validation loss: 0.3979383258550775 -- validation accuracy 0.8063725490196079\n",
      "Epoch 0 Step 350 -- training loss: 0.3508332989509329 --validation loss: 0.3314112857276318 -- validation accuracy 0.8651960784313726\n",
      "Epoch 0 Step 400 -- training loss: 0.3637208527152899 --validation loss: 0.37345358517532257 -- validation accuracy 0.8235294117647058\n",
      "Epoch 0 Step 450 -- training loss: 0.28553116616989793 --validation loss: 0.28974529311937447 -- validation accuracy 0.8774509803921569\n",
      "Epoch 0 Step 458 -- training loss: 0.2773033364682026 --validation loss: 0.28683727519477115 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 0 -- training loss: 0.27718497238128015 --validation loss: 0.2872692027366629 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 50 -- training loss: 0.2549181955547959 --validation loss: 0.28400409619743916 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 100 -- training loss: 0.26212432736648583 --validation loss: 0.32132782483948213 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 150 -- training loss: 0.22789766938143566 --validation loss: 0.30881956416894407 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 200 -- training loss: 0.23992055847688956 --validation loss: 0.2979635079117382 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 250 -- training loss: 0.1928192968409273 --validation loss: 0.2722139584229273 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 300 -- training loss: 0.18623343775199 --validation loss: 0.29593122619039874 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 350 -- training loss: 0.24669059326624687 --validation loss: 0.39809064271257205 -- validation accuracy 0.8382352941176471\n",
      "Epoch 1 Step 400 -- training loss: 0.16598658609429215 --validation loss: 0.28262438888058944 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 450 -- training loss: 0.16905347417333935 --validation loss: 0.2819008736633787 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.15891900348978236 --validation loss: 0.28010233338264856 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 0 -- training loss: 0.1549606199207876 --validation loss: 0.27625144324174117 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 50 -- training loss: 0.111723887844697 --validation loss: 0.3087143127021252 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.14809014577487553 --validation loss: 0.3802274500713775 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 150 -- training loss: 0.13514543291940181 --validation loss: 0.36482945630582525 -- validation accuracy 0.8602941176470589\n",
      "Epoch 2 Step 200 -- training loss: 0.09507338686852283 --validation loss: 0.29674708269828676 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 250 -- training loss: 0.07582942247877714 --validation loss: 0.3365466641444786 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 300 -- training loss: 0.080690942739171 --validation loss: 0.29825694892811133 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 350 -- training loss: 0.08266164879426198 --validation loss: 0.32362577191773145 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.08136687370794288 --validation loss: 0.32214373008658487 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 450 -- training loss: 0.05744886028271956 --validation loss: 0.32167645388593274 -- validation accuracy 0.8970588235294118\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.06188034750866117 --validation loss: 0.3518341007258962 -- validation accuracy 0.8872549019607843\n",
      "The best accuracy was 0.8970588235294118 after step 458 of epoch 1.\n",
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.7095115031551951 --validation loss: 0.710458541617674 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.6150312169185131 --validation loss: 0.6097743581323063 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6003719088428681 --validation loss: 0.5944801551454207 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6197447857955443 --validation loss: 0.6041837822572858 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.4983413711449939 --validation loss: 0.4885190509113611 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 250 -- training loss: 0.4058675510090551 --validation loss: 0.39332450692560156 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 300 -- training loss: 0.4038945266769992 --validation loss: 0.4165356674176805 -- validation accuracy 0.8259803921568627\n",
      "Epoch 0 Step 350 -- training loss: 0.41904576252618386 --validation loss: 0.4243399103482564 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 400 -- training loss: 0.44595459815366334 --validation loss: 0.4612375852816245 -- validation accuracy 0.7941176470588235\n",
      "Epoch 0 Step 450 -- training loss: 0.32978381813059443 --validation loss: 0.35447052946569874 -- validation accuracy 0.8480392156862745\n",
      "Epoch 0 Step 458 -- training loss: 0.32344441455109185 --validation loss: 0.34438538785074274 -- validation accuracy 0.8504901960784313\n",
      "Epoch 1 Step 0 -- training loss: 0.3251671392170303 --validation loss: 0.34569967669599194 -- validation accuracy 0.8504901960784313\n",
      "Epoch 1 Step 50 -- training loss: 0.28691093920687444 --validation loss: 0.3147694510864277 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 100 -- training loss: 0.27497809324697603 --validation loss: 0.31357461250588003 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 150 -- training loss: 0.2579909625558552 --validation loss: 0.30569329364773107 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 200 -- training loss: 0.24724718357775205 --validation loss: 0.296684946353529 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.23708921765060467 --validation loss: 0.3078225027660237 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 300 -- training loss: 0.22819891595535288 --validation loss: 0.3060709677782713 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 350 -- training loss: 0.2669294436172073 --validation loss: 0.3822557820810699 -- validation accuracy 0.8406862745098039\n",
      "Epoch 1 Step 400 -- training loss: 0.21940340222040097 --validation loss: 0.31051652725128565 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 450 -- training loss: 0.198304742351499 --validation loss: 0.29265623196375135 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 458 -- training loss: 0.19674705378792384 --validation loss: 0.2816651439403786 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 0 -- training loss: 0.1970148514976526 --validation loss: 0.2815296044573188 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.23230035411912242 --validation loss: 0.3291024818066873 -- validation accuracy 0.8578431372549019\n",
      "Epoch 2 Step 100 -- training loss: 0.172346368392479 --validation loss: 0.302249473218313 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 150 -- training loss: 0.16845804785859156 --validation loss: 0.288038456410754 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 200 -- training loss: 0.1545202873651271 --validation loss: 0.2923608373521882 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 250 -- training loss: 0.14939620067144305 --validation loss: 0.3102966956063813 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 300 -- training loss: 0.15080644447794733 --validation loss: 0.31457591602834417 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 350 -- training loss: 0.14299479891669842 --validation loss: 0.2998262844413665 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 400 -- training loss: 0.13928164487952177 --validation loss: 0.2951757559077997 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 450 -- training loss: 0.13841332753304564 --validation loss: 0.2925835545996533 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 458 -- training loss: 0.13840046504001116 --validation loss: 0.29275450820797216 -- validation accuracy 0.8897058823529411\n",
      "The best accuracy was 0.8921568627450981 after step 200 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6947074596139081 --validation loss: 0.6949678577628791 -- validation accuracy 0.37254901960784315\n",
      "Epoch 0 Step 50 -- training loss: 0.6459061873504539 --validation loss: 0.6428830541816413 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6357620035121644 --validation loss: 0.6332526767955107 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 150 -- training loss: 0.6865443760663076 --validation loss: 0.6916228581000777 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.5426917399780943 --validation loss: 0.5398568762283699 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 250 -- training loss: 0.6216095750887669 --validation loss: 0.6169086981053445 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.528742421459009 --validation loss: 0.5274633274358862 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 350 -- training loss: 0.566578207712028 --validation loss: 0.5745292089733423 -- validation accuracy 0.7426470588235294\n",
      "Epoch 0 Step 400 -- training loss: 0.6102870963108046 --validation loss: 0.6021166408763212 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 450 -- training loss: 0.5060111541861023 --validation loss: 0.5289147364742616 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 458 -- training loss: 0.7548280597982973 --validation loss: 0.789495990702919 -- validation accuracy 0.7426470588235294\n",
      "Epoch 1 Step 0 -- training loss: 0.7265694346076004 --validation loss: 0.7501017293509316 -- validation accuracy 0.7377450980392157\n",
      "Epoch 1 Step 50 -- training loss: 0.4505503015645449 --validation loss: 0.4699857699520448 -- validation accuracy 0.8014705882352942\n",
      "Epoch 1 Step 100 -- training loss: 0.45362745064730736 --validation loss: 0.5125762162109216 -- validation accuracy 0.7867647058823529\n",
      "Epoch 1 Step 150 -- training loss: 0.4595272845075281 --validation loss: 0.5190061533860132 -- validation accuracy 0.7377450980392157\n",
      "Epoch 1 Step 200 -- training loss: 0.3969031424628883 --validation loss: 0.43278045820839267 -- validation accuracy 0.8063725490196079\n",
      "Epoch 1 Step 250 -- training loss: 0.32867910862293637 --validation loss: 0.39137421519148585 -- validation accuracy 0.8333333333333334\n",
      "Epoch 1 Step 300 -- training loss: 0.35998781824034026 --validation loss: 0.43992960715995116 -- validation accuracy 0.7818627450980392\n",
      "Epoch 1 Step 350 -- training loss: 0.3879696958594852 --validation loss: 0.4584481362618652 -- validation accuracy 0.8014705882352942\n",
      "Epoch 1 Step 400 -- training loss: 0.34834929545915205 --validation loss: 0.4112858389522515 -- validation accuracy 0.8137254901960784\n",
      "Epoch 1 Step 450 -- training loss: 0.31504067864618013 --validation loss: 0.3854586391472349 -- validation accuracy 0.8137254901960784\n",
      "Epoch 1 Step 458 -- training loss: 0.37828060189233625 --validation loss: 0.4391820790136562 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 0 -- training loss: 0.40145934051742743 --validation loss: 0.46173183181706595 -- validation accuracy 0.7622549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.3748368442724084 --validation loss: 0.47467679486555214 -- validation accuracy 0.7916666666666666\n",
      "Epoch 2 Step 100 -- training loss: 0.2788471003998404 --validation loss: 0.48334487651785213 -- validation accuracy 0.821078431372549\n",
      "Epoch 2 Step 150 -- training loss: 0.30325329695749126 --validation loss: 0.41287094792898965 -- validation accuracy 0.8235294117647058\n",
      "Epoch 2 Step 200 -- training loss: 0.2602236777105752 --validation loss: 0.3620295981858291 -- validation accuracy 0.8357843137254902\n",
      "Epoch 2 Step 250 -- training loss: 0.23418628171183706 --validation loss: 0.3707048048575719 -- validation accuracy 0.8431372549019608\n",
      "Epoch 2 Step 300 -- training loss: 0.2476154101610768 --validation loss: 0.37581913834255115 -- validation accuracy 0.8553921568627451\n",
      "Epoch 2 Step 350 -- training loss: 0.253591435695623 --validation loss: 0.4084123836136332 -- validation accuracy 0.8357843137254902\n",
      "Epoch 2 Step 400 -- training loss: 0.2131579439105032 --validation loss: 0.3606812305310193 -- validation accuracy 0.8186274509803921\n",
      "Epoch 2 Step 450 -- training loss: 0.17620278738666334 --validation loss: 0.34540025897177995 -- validation accuracy 0.8504901960784313\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.1632902209823525 --validation loss: 0.3680057324761269 -- validation accuracy 0.8553921568627451\n",
      "The best accuracy was 0.8553921568627451 after step 300 of epoch 2.\n",
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6947074596139081 --validation loss: 0.6949678577628791 -- validation accuracy 0.37254901960784315\n",
      "Epoch 0 Step 50 -- training loss: 0.617431222223768 --validation loss: 0.6131184200445811 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 100 -- training loss: 0.6085776200351632 --validation loss: 0.6060074690510245 -- validation accuracy 0.7107843137254902\n",
      "Epoch 0 Step 150 -- training loss: 0.5272546563143304 --validation loss: 0.5223024668646794 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 200 -- training loss: 0.48064474761486053 --validation loss: 0.4595169302295236 -- validation accuracy 0.7254901960784313\n",
      "Epoch 0 Step 250 -- training loss: 0.5003743044756077 --validation loss: 0.48933588815670387 -- validation accuracy 0.7426470588235294\n",
      "Epoch 0 Step 300 -- training loss: 0.48900691473406127 --validation loss: 0.47842740106816384 -- validation accuracy 0.7990196078431373\n",
      "Epoch 0 Step 350 -- training loss: 0.3566670433774363 --validation loss: 0.34300212912699757 -- validation accuracy 0.8455882352941176\n",
      "Epoch 0 Step 400 -- training loss: 0.39095299482378043 --validation loss: 0.4008333495288503 -- validation accuracy 0.7941176470588235\n",
      "Epoch 0 Step 450 -- training loss: 0.2905296892869187 --validation loss: 0.32059736980819237 -- validation accuracy 0.8700980392156863\n",
      "Epoch 0 Step 458 -- training loss: 0.28509417865709413 --validation loss: 0.31492913167412373 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 0 -- training loss: 0.2846996673425428 --validation loss: 0.31377328760629775 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 50 -- training loss: 0.29209784614348333 --validation loss: 0.3365938797885296 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 100 -- training loss: 0.30521292498128283 --validation loss: 0.39036930672020886 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 150 -- training loss: 0.2584140187165901 --validation loss: 0.3234175288794087 -- validation accuracy 0.875\n",
      "Epoch 1 Step 200 -- training loss: 0.23743166218152623 --validation loss: 0.3002621415345108 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 250 -- training loss: 0.22069135058695585 --validation loss: 0.31512550817912116 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 300 -- training loss: 0.20686977997844255 --validation loss: 0.29570638581964315 -- validation accuracy 0.875\n",
      "Epoch 1 Step 350 -- training loss: 0.2570895946367536 --validation loss: 0.3973405912116754 -- validation accuracy 0.8063725490196079\n",
      "Epoch 1 Step 400 -- training loss: 0.17394026390567 --validation loss: 0.27621138972394604 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 450 -- training loss: 0.1684630144182552 --validation loss: 0.2934963607649301 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.15837142285982184 --validation loss: 0.272032278242941 -- validation accuracy 0.9068627450980392\n",
      "Epoch 2 Step 0 -- training loss: 0.1581324412241935 --validation loss: 0.2718456463669153 -- validation accuracy 0.9044117647058824\n",
      "Epoch 2 Step 50 -- training loss: 0.1378442979917896 --validation loss: 0.2963380752880053 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 100 -- training loss: 0.11946516618901591 --validation loss: 0.26661525241227124 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 150 -- training loss: 0.10883150471390625 --validation loss: 0.2873152748626821 -- validation accuracy 0.9068627450980392\n",
      "Epoch 2 Step 200 -- training loss: 0.10124639777947533 --validation loss: 0.28936130268608823 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 250 -- training loss: 0.09034276671742124 --validation loss: 0.2840039064861177 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 300 -- training loss: 0.08431042132144367 --validation loss: 0.28631608221935584 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 350 -- training loss: 0.08228376903266835 --validation loss: 0.30313492241753814 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 400 -- training loss: 0.07806372284444865 --validation loss: 0.31629257914427594 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 450 -- training loss: 0.07654129198350597 --validation loss: 0.3062546992510119 -- validation accuracy 0.8872549019607843\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.07652352147782322 --validation loss: 0.3065065922599067 -- validation accuracy 0.8872549019607843\n",
      "The best accuracy was 0.9068627450980392 after step 458 of epoch 1.\n",
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6810652118882322 --validation loss: 0.6807034506517298 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6291330246364369 --validation loss: 0.6241140336382622 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 100 -- training loss: 0.63473338576963 --validation loss: 0.6302839213726568 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6711580652686765 --validation loss: 0.6587418905075859 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6330896982829815 --validation loss: 0.627539265389536 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.6306621868625965 --validation loss: 0.6236327880737829 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.6299676037432062 --validation loss: 0.6224805858789706 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.6478714818268819 --validation loss: 0.6445679302309074 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 400 -- training loss: 0.6334109696557579 --validation loss: 0.6252235764381933 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6353872190503513 --validation loss: 0.6305362693234986 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6306848779223324 --validation loss: 0.6241869692708931 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.6306038567703014 --validation loss: 0.6238964036399243 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6365848087537263 --validation loss: 0.6321236310051936 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.6307577827787088 --validation loss: 0.6234168112277985 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 150 -- training loss: 0.6384575835759864 --validation loss: 0.6341600821298712 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.6300939762384543 --validation loss: 0.6237700721796822 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6316340890325493 --validation loss: 0.6255941034532061 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6195379232009771 --validation loss: 0.6214195811281017 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6606685808800924 --validation loss: 0.6609086230689404 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.6256621002761367 --validation loss: 0.6225080694638047 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.6157998668602089 --validation loss: 0.6174795282822029 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6165022000767826 --validation loss: 0.618463617329504 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6160067651006911 --validation loss: 0.618647517526851 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.6268673900165849 --validation loss: 0.6386989512864281 -- validation accuracy 0.6397058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.6336142305195461 --validation loss: 0.6252282735179452 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.6666013320546784 --validation loss: 0.6650206049283346 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.654718646426606 --validation loss: 0.6519834621279847 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.6374617178715393 --validation loss: 0.6329570348356285 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.6311470299374824 --validation loss: 0.6240371267000834 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.6319441447980004 --validation loss: 0.6260804609925139 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 400 -- training loss: 0.6310548569382146 --validation loss: 0.6246018240264818 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.6326581113089144 --validation loss: 0.6263674468386407 -- validation accuracy 0.6838235294117647\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.6307238418941664 --validation loss: 0.6241848164913701 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.7009803921568627 after step 50 of epoch 0.\n",
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6810652118882322 --validation loss: 0.6807034506517298 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6321441878550452 --validation loss: 0.63021014250961 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 100 -- training loss: 0.6123922724349826 --validation loss: 0.6085916097257652 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5726706071357062 --validation loss: 0.5737485938212451 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6193472639148272 --validation loss: 0.615129151765038 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.6301382742416365 --validation loss: 0.6233882711214178 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.6285926630164543 --validation loss: 0.6218146348700804 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.5912766396869501 --validation loss: 0.5958363647554435 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 400 -- training loss: 0.6192600548364757 --validation loss: 0.6389607269974316 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6332137454179377 --validation loss: 0.6281031913617078 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6311931569851562 --validation loss: 0.6255732809796053 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.63091009985128 --validation loss: 0.6251839253247953 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6331019076906258 --validation loss: 0.6282878044773551 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.6268429532160167 --validation loss: 0.6208168934373295 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 150 -- training loss: 0.6343195220873507 --validation loss: 0.6291439100807789 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.6309937021831022 --validation loss: 0.6248729135475907 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6307240094104883 --validation loss: 0.6243343376645855 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6311052148118778 --validation loss: 0.6243647634983063 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6388096734719079 --validation loss: 0.6293161406236536 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.6312853129730764 --validation loss: 0.6240571334081537 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.6349030819463833 --validation loss: 0.6297468835232305 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6319814204909963 --validation loss: 0.6261770438914206 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6316192475409289 --validation loss: 0.6259070617311141 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.6352979137616999 --validation loss: 0.630579576772802 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.6311790530847828 --validation loss: 0.6245859183517157 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.6318871898329076 --validation loss: 0.6260562907246983 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.6316176895742063 --validation loss: 0.62473692204438 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.6327059320245173 --validation loss: 0.6271731695708107 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.6311252539194228 --validation loss: 0.6239369295391382 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.6308705329505446 --validation loss: 0.6239736319756976 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 400 -- training loss: 0.6312846426480736 --validation loss: 0.6239591048044317 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.6321838835096047 --validation loss: 0.6240560377345366 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 458 -- training loss: 0.6313020683062103 --validation loss: 0.6240557338677201 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.7156862745098039 after step 50 of epoch 0.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiments 1-4, we see overfitting after epoch 1. So we ignore epoch 2 in these experiments.\n",
    "\n",
    "In experiments 1,2, and 4, we also see some oscillations in both train and validation losses in epoch 1, but overall losses go down. In experiment 3, we see oscillations in both losses even from the beginning.\n",
    "\n",
    "The best results for experiment 1 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 89.7 and 0.280, respectively.\n",
    "\n",
    "The best results for experiment 2 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 89.0 and 0.282, respectively.\n",
    "\n",
    "The best results for experiment 3 is achieved after step 450 of epoch 1, where the validation accuracy and validation loss are 81.4 and 0.385, respectively.\n",
    "\n",
    "The best results for experiment 4 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 90.7 and 0.272, respectively.\n",
    "\n",
    "In experiments 5 and 6, both train and validation losses remain constant (up to some oscillations) and the accuracy remain constant as well. This suggests that the (consntant or initial) learning rate of $5\\times 10^{-5}$ is probably too large.\n",
    "\n",
    "Based on these observations, we conclude that experiment 4 leads to the best results."
   ],
   "metadata": {
    "id": "QRT46YxhTT9d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 23"
   ],
   "metadata": {
    "id": "pjnqYh30doi7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(23)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0df81798281647f18cc1053771049faa",
      "100e726a8d8f4d5f9faa7cbb960f3132",
      "e06ffbabd304471e8d5e11d973795bba",
      "fcdde73417594361bb72bddf6234c563",
      "1311f2bd8d8e4b14aad24873127f3e3e",
      "b3d8f654270043d2aff91d9edb1fe7fe",
      "fbaf8f95bf38492cbd0fd3016446f510",
      "b6ab8c0722994e8c8f9ffc50e46e5eee",
      "cb372b08bc5b41d89612de369b706dd0",
      "63a00e7e3f634d69840683543f3b0f7d",
      "24de6583e59b41fa952f98e4fed35925"
     ]
    },
    "id": "P4Q9VvTU3NVw",
    "outputId": "65165967-b98f-4c6f-fdf5-eff3c63efb99"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0df81798281647f18cc1053771049faa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6695231836865411 --validation loss: 0.6682174696641809 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5935074584416574 --validation loss: 0.5881349900189567 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5653804466615315 --validation loss: 0.5531215416450127 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5381281334979862 --validation loss: 0.5281262800974005 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 200 -- training loss: 0.42328779250058735 --validation loss: 0.4217899751429464 -- validation accuracy 0.8284313725490197\n",
      "Epoch 0 Step 250 -- training loss: 0.3967063057851168 --validation loss: 0.4040442792808308 -- validation accuracy 0.8161764705882353\n",
      "Epoch 0 Step 300 -- training loss: 0.43097002489374614 --validation loss: 0.4330519204046212 -- validation accuracy 0.7965686274509803\n",
      "Epoch 0 Step 350 -- training loss: 0.4246422101566994 --validation loss: 0.46205124996748625 -- validation accuracy 0.8137254901960784\n",
      "Epoch 0 Step 400 -- training loss: 0.36179535629832404 --validation loss: 0.36755437535398144 -- validation accuracy 0.8480392156862745\n",
      "Epoch 0 Step 450 -- training loss: 0.33281223682893646 --validation loss: 0.35692744599837883 -- validation accuracy 0.8480392156862745\n",
      "Epoch 0 Step 458 -- training loss: 0.30423722151577604 --validation loss: 0.32242371996535973 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 0 -- training loss: 0.3016874177994162 --validation loss: 0.3221589955775177 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 50 -- training loss: 0.3020522609060886 --validation loss: 0.34051383513153766 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 100 -- training loss: 0.31904788512517424 --validation loss: 0.3617802900718708 -- validation accuracy 0.821078431372549\n",
      "Epoch 1 Step 150 -- training loss: 0.2731947531611182 --validation loss: 0.3257872548465635 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 200 -- training loss: 0.25820009154318335 --validation loss: 0.32585015637325304 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 250 -- training loss: 0.25961557149883024 --validation loss: 0.37804252758403034 -- validation accuracy 0.8480392156862745\n",
      "Epoch 1 Step 300 -- training loss: 0.29208582292325097 --validation loss: 0.3488122630937427 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 350 -- training loss: 0.251025911120288 --validation loss: 0.3297741040587425 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 400 -- training loss: 0.2146507585522656 --validation loss: 0.31099114486692 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 450 -- training loss: 0.17661020994868154 --validation loss: 0.2891194358029786 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 458 -- training loss: 0.18552738577249198 --validation loss: 0.2943161571873169 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 0 -- training loss: 0.18535726805966274 --validation loss: 0.29412025549248155 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 50 -- training loss: 0.14756116024086613 --validation loss: 0.28890094089814844 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 100 -- training loss: 0.14836891549223455 --validation loss: 0.3084706783696425 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 150 -- training loss: 0.1615044835758089 --validation loss: 0.3153724372752157 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 200 -- training loss: 0.20083575457494812 --validation loss: 0.42935804829147517 -- validation accuracy 0.8578431372549019\n",
      "Epoch 2 Step 250 -- training loss: 0.11907454665794903 --validation loss: 0.30742692079979417 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 300 -- training loss: 0.20992576210578998 --validation loss: 0.4285455340903033 -- validation accuracy 0.8406862745098039\n",
      "Epoch 2 Step 350 -- training loss: 0.13287903010045748 --validation loss: 0.2917281992587389 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 400 -- training loss: 0.0991804755865018 --validation loss: 0.3019494138767614 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 450 -- training loss: 0.10714965636085126 --validation loss: 0.34294660215941714 -- validation accuracy 0.8553921568627451\n",
      "Epoch 2 Step 458 -- training loss: 0.10079786041041346 --validation loss: 0.33756035149973984 -- validation accuracy 0.8627450980392157\n",
      "The best accuracy was 0.8995098039215687 after step 50 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6695231836865411 --validation loss: 0.6682174696641809 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6069191875411015 --validation loss: 0.600809653600057 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5731071185052784 --validation loss: 0.564489521816665 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5374747838719478 --validation loss: 0.5288021950160756 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 200 -- training loss: 0.4268347047642685 --validation loss: 0.41702817584954055 -- validation accuracy 0.8161764705882353\n",
      "Epoch 0 Step 250 -- training loss: 0.39263811452651076 --validation loss: 0.39190588248711006 -- validation accuracy 0.8529411764705882\n",
      "Epoch 0 Step 300 -- training loss: 0.3814238416343473 --validation loss: 0.37863950475173835 -- validation accuracy 0.8504901960784313\n",
      "Epoch 0 Step 350 -- training loss: 0.41764680961905803 --validation loss: 0.4361601051162271 -- validation accuracy 0.8235294117647058\n",
      "Epoch 0 Step 400 -- training loss: 0.38297592700826316 --validation loss: 0.39307446281115216 -- validation accuracy 0.8235294117647058\n",
      "Epoch 0 Step 450 -- training loss: 0.32548503743277657 --validation loss: 0.34880147874355316 -- validation accuracy 0.8455882352941176\n",
      "Epoch 0 Step 458 -- training loss: 0.3131583805453673 --validation loss: 0.34340472198000144 -- validation accuracy 0.8333333333333334\n",
      "Epoch 1 Step 0 -- training loss: 0.3099542831705806 --validation loss: 0.34108274210901823 -- validation accuracy 0.8357843137254902\n",
      "Epoch 1 Step 50 -- training loss: 0.2917047324377337 --validation loss: 0.33364582792216657 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 100 -- training loss: 0.3679407890033878 --validation loss: 0.4257671764376117 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 150 -- training loss: 0.2893968896457442 --validation loss: 0.3481406769623943 -- validation accuracy 0.875\n",
      "Epoch 1 Step 200 -- training loss: 0.27204829992519486 --validation loss: 0.3391025156586194 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 250 -- training loss: 0.24820599817794653 --validation loss: 0.3269328466233085 -- validation accuracy 0.875\n",
      "Epoch 1 Step 300 -- training loss: 0.23012838614921943 --validation loss: 0.30835724746187526 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 350 -- training loss: 0.2597373619164322 --validation loss: 0.3420089532566421 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 400 -- training loss: 0.2230076232563891 --validation loss: 0.3062096541272659 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 450 -- training loss: 0.20673255996539183 --validation loss: 0.30541588599775354 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 458 -- training loss: 0.20316220383303876 --validation loss: 0.2898697600352998 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 0 -- training loss: 0.20316166908750088 --validation loss: 0.28943217516529796 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 50 -- training loss: 0.1893991184682628 --validation loss: 0.27896419269781486 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 100 -- training loss: 0.18060518873749962 --validation loss: 0.2899952434441623 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 150 -- training loss: 0.1785368968332937 --validation loss: 0.29013695998811256 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 200 -- training loss: 0.17411142787520728 --validation loss: 0.28705977498754565 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.1679267969219854 --validation loss: 0.29485118327041465 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 300 -- training loss: 0.1677914998029442 --validation loss: 0.2928483319998372 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 350 -- training loss: 0.16558997086320307 --validation loss: 0.28067169196027164 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.16267549207998128 --validation loss: 0.2825457936554563 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 450 -- training loss: 0.16063603914641086 --validation loss: 0.28429226069619845 -- validation accuracy 0.8872549019607843\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.16055014753645216 --validation loss: 0.28439018236217545 -- validation accuracy 0.8848039215686274\n",
      "The best accuracy was 0.8946078431372549 after step 200 of epoch 2.\n",
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6589438468542493 --validation loss: 0.6570845316438114 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5542853225939673 --validation loss: 0.548541850903455 -- validation accuracy 0.7107843137254902\n",
      "Epoch 0 Step 100 -- training loss: 0.5836625208911813 --validation loss: 0.5804559903986314 -- validation accuracy 0.696078431372549\n",
      "Epoch 0 Step 150 -- training loss: 0.43159161589244355 --validation loss: 0.4148337535706221 -- validation accuracy 0.8308823529411765\n",
      "Epoch 0 Step 200 -- training loss: 0.4747516358340228 --validation loss: 0.4774866799513499 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 250 -- training loss: 0.5587689075984207 --validation loss: 0.5566040926119861 -- validation accuracy 0.7524509803921569\n",
      "Epoch 0 Step 300 -- training loss: 0.414687930401374 --validation loss: 0.4242635676089455 -- validation accuracy 0.8186274509803921\n",
      "Epoch 0 Step 350 -- training loss: 0.5928101907108864 --validation loss: 0.6007117313497207 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 400 -- training loss: 0.3582896703208973 --validation loss: 0.3846437302874584 -- validation accuracy 0.8161764705882353\n",
      "Epoch 0 Step 450 -- training loss: 0.37288258534760776 --validation loss: 0.4025489448332319 -- validation accuracy 0.8455882352941176\n",
      "Epoch 0 Step 458 -- training loss: 0.30311337308978464 --validation loss: 0.35601350898836176 -- validation accuracy 0.8455882352941176\n",
      "Epoch 1 Step 0 -- training loss: 0.30115370294951666 --validation loss: 0.35669177887486475 -- validation accuracy 0.8406862745098039\n",
      "Epoch 1 Step 50 -- training loss: 0.29595776000070284 --validation loss: 0.3948073221334055 -- validation accuracy 0.8431372549019608\n",
      "Epoch 1 Step 100 -- training loss: 0.32645668876651585 --validation loss: 0.37285612991043166 -- validation accuracy 0.8308823529411765\n",
      "Epoch 1 Step 150 -- training loss: 0.28193676186835065 --validation loss: 0.3542457077579171 -- validation accuracy 0.8382352941176471\n",
      "Epoch 1 Step 200 -- training loss: 0.31616922268899633 --validation loss: 0.38706955328291537 -- validation accuracy 0.8382352941176471\n",
      "Epoch 1 Step 250 -- training loss: 0.29910762209550745 --validation loss: 0.4443536885447946 -- validation accuracy 0.8259803921568627\n",
      "Epoch 1 Step 300 -- training loss: 0.33383206794269726 --validation loss: 0.4134428813761356 -- validation accuracy 0.8480392156862745\n",
      "Epoch 1 Step 350 -- training loss: 0.19279935951537427 --validation loss: 0.31867752056203635 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 400 -- training loss: 0.17093419174466906 --validation loss: 0.30627255939750697 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.14679956104614506 --validation loss: 0.28247375581778733 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 458 -- training loss: 0.15476951717697326 --validation loss: 0.2674182324725039 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 0 -- training loss: 0.15444343155635468 --validation loss: 0.2676043388452016 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 50 -- training loss: 0.14979413019448584 --validation loss: 0.2892164959590517 -- validation accuracy 0.8627450980392157\n",
      "Epoch 2 Step 100 -- training loss: 0.1507774278377477 --validation loss: 0.36988348429839984 -- validation accuracy 0.8480392156862745\n",
      "Epoch 2 Step 150 -- training loss: 0.16814464701579027 --validation loss: 0.3458882923438853 -- validation accuracy 0.8627450980392157\n",
      "Epoch 2 Step 200 -- training loss: 0.1239874521483442 --validation loss: 0.33682400861061085 -- validation accuracy 0.8627450980392157\n",
      "Epoch 2 Step 250 -- training loss: 0.12029933491681169 --validation loss: 0.42760247886454794 -- validation accuracy 0.8651960784313726\n",
      "Epoch 2 Step 300 -- training loss: 0.16005794868108558 --validation loss: 0.39767641764061123 -- validation accuracy 0.8553921568627451\n",
      "Epoch 2 Step 350 -- training loss: 0.11298393666610317 --validation loss: 0.3789506412531231 -- validation accuracy 0.8480392156862745\n",
      "Epoch 2 Step 400 -- training loss: 0.07107218030651459 --validation loss: 0.34767633896576716 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 450 -- training loss: 0.07394057384860542 --validation loss: 0.30413898025803704 -- validation accuracy 0.8848039215686274\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.06764359988905246 --validation loss: 0.3385030342740755 -- validation accuracy 0.8725490196078431\n",
      "The best accuracy was 0.8995098039215687 after step 458 of epoch 1.\n",
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6589438468542493 --validation loss: 0.6570845316438114 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5863408955353797 --validation loss: 0.5830099249587339 -- validation accuracy 0.7181372549019608\n",
      "Epoch 0 Step 100 -- training loss: 0.5481619011683792 --validation loss: 0.5280616002924302 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 150 -- training loss: 0.6537124352257756 --validation loss: 0.6515997765110988 -- validation accuracy 0.6862745098039216\n",
      "Epoch 0 Step 200 -- training loss: 0.4394521601579288 --validation loss: 0.4309568892360902 -- validation accuracy 0.8186274509803921\n",
      "Epoch 0 Step 250 -- training loss: 0.412158476923286 --validation loss: 0.39726442931329503 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 300 -- training loss: 0.43370816077477015 --validation loss: 0.4352886171317568 -- validation accuracy 0.8063725490196079\n",
      "Epoch 0 Step 350 -- training loss: 0.38677314097520316 --validation loss: 0.3752311225615296 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 400 -- training loss: 0.36349065182629103 --validation loss: 0.37326668042178246 -- validation accuracy 0.8774509803921569\n",
      "Epoch 0 Step 450 -- training loss: 0.40728476323787943 --validation loss: 0.44272881015843035 -- validation accuracy 0.8406862745098039\n",
      "Epoch 0 Step 458 -- training loss: 0.36383069503021653 --validation loss: 0.3953362947293356 -- validation accuracy 0.8455882352941176\n",
      "Epoch 1 Step 0 -- training loss: 0.3412218391895294 --validation loss: 0.3793334844065647 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 50 -- training loss: 0.3387242298175567 --validation loss: 0.37092785960903357 -- validation accuracy 0.8186274509803921\n",
      "Epoch 1 Step 100 -- training loss: 0.3127283330576612 --validation loss: 0.32090070025593626 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 150 -- training loss: 0.28822258934540945 --validation loss: 0.38312045835396824 -- validation accuracy 0.8455882352941176\n",
      "Epoch 1 Step 200 -- training loss: 0.2623021282450436 --validation loss: 0.29033062271043364 -- validation accuracy 0.875\n",
      "Epoch 1 Step 250 -- training loss: 0.27024830974159614 --validation loss: 0.3301689766493498 -- validation accuracy 0.8382352941176471\n",
      "Epoch 1 Step 300 -- training loss: 0.22623559702309518 --validation loss: 0.2965565848292089 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 350 -- training loss: 0.25584664862107864 --validation loss: 0.3619906655056219 -- validation accuracy 0.8308823529411765\n",
      "Epoch 1 Step 400 -- training loss: 0.20136026213907338 --validation loss: 0.27312433409194153 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 450 -- training loss: 0.1727547854700477 --validation loss: 0.26169973794443935 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 458 -- training loss: 0.16614991609891774 --validation loss: 0.2584145206081517 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 0 -- training loss: 0.16570516538954377 --validation loss: 0.2589540736494111 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.1411280932061147 --validation loss: 0.29503403919036775 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 100 -- training loss: 0.14908594181578533 --validation loss: 0.3002459243597353 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 150 -- training loss: 0.13267241550349754 --validation loss: 0.27369372504672 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 200 -- training loss: 0.1322769910357852 --validation loss: 0.32531255406017107 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 250 -- training loss: 0.1027937577946075 --validation loss: 0.29734176779896315 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 300 -- training loss: 0.09976514658133838 --validation loss: 0.27756852049417063 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 350 -- training loss: 0.0948241294132371 --validation loss: 0.2670811883849548 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 400 -- training loss: 0.09061166358409624 --validation loss: 0.2672903286293149 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 450 -- training loss: 0.0879409251144168 --validation loss: 0.27101125191057135 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 458 -- training loss: 0.0879058040270667 --validation loss: 0.27107638067693685 -- validation accuracy 0.9019607843137255\n",
      "The best accuracy was 0.9019607843137255 after step 400 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6497920916490825 --validation loss: 0.6472402086444929 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.633785577186572 --validation loss: 0.6290013357704761 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6356001748238773 --validation loss: 0.627111950341393 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.632310843220983 --validation loss: 0.6266066712491652 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6412640421738551 --validation loss: 0.6374463427300546 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.6424187903570454 --validation loss: 0.6323590138379265 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.6316689267787019 --validation loss: 0.6242588103986254 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.6325878530805666 --validation loss: 0.6245336737118515 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 400 -- training loss: 0.6326086445181978 --validation loss: 0.6245458435778525 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6307965546911318 --validation loss: 0.6239269556952458 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6453100098763676 --validation loss: 0.6419511390667335 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.6471551781386332 --validation loss: 0.6437805388488022 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6383600868690508 --validation loss: 0.6289319577170354 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.7002896660033914 --validation loss: 0.7006693120096245 -- validation accuracy 0.3161764705882353\n",
      "Epoch 1 Step 150 -- training loss: 0.6320940962544194 --validation loss: 0.6245124299152225 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.6401957880567621 --validation loss: 0.6304652258461597 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6314577416786701 --validation loss: 0.6253663172908858 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6307057102001831 --validation loss: 0.6240824420078128 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6376725852749187 --validation loss: 0.6288089039278966 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.631372609689085 --validation loss: 0.6249124997971105 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.631246123113923 --validation loss: 0.6240478929351357 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6320576967756733 --validation loss: 0.6257487845187094 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6322425938899221 --validation loss: 0.626026429382025 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.6321738325302897 --validation loss: 0.6261766950289408 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.6321180963438321 --validation loss: 0.6245277185066074 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.6346206325461402 --validation loss: 0.6293756979353288 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.6320097809393681 --validation loss: 0.6240935611958597 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.6350941537901726 --validation loss: 0.6299580849853217 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.6349610403861875 --validation loss: 0.6264093401385289 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.630912179650824 --validation loss: 0.6240623090781418 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 400 -- training loss: 0.6320231212769718 --validation loss: 0.6262056108783273 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.6467051736539745 --validation loss: 0.6360858182112376 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 458 -- training loss: 0.6343825738674156 --validation loss: 0.625600291817796 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.6838235294117647 after step 0 of epoch 0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6497920916490825 --validation loss: 0.6472402086444929 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6328684729818166 --validation loss: 0.6276626131113838 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.63088196243336 --validation loss: 0.6246747321942273 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.632264292123271 --validation loss: 0.6265431017267937 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6398025857597135 --validation loss: 0.6357908903383741 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.6387009465486655 --validation loss: 0.6292142546644398 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.630721917923759 --validation loss: 0.6240334563395556 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.6320367870377559 --validation loss: 0.6242135722263187 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 400 -- training loss: 0.6328775913886775 --validation loss: 0.6247173541901159 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6314036877326716 --validation loss: 0.6240234860018188 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6350170346646528 --validation loss: 0.6302192111810049 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.6364826374973347 --validation loss: 0.6316331864572039 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6409363844685565 --validation loss: 0.6310919651798174 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.6542220532504561 --validation loss: 0.6515635999978757 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 150 -- training loss: 0.6343333018631198 --validation loss: 0.6261175602090125 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.6332656504801416 --validation loss: 0.6249790629919838 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6324870840266898 --validation loss: 0.6268445557239009 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6309950656880481 --validation loss: 0.6239650471537721 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6323322545339339 --validation loss: 0.6246659118755191 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.6312766932194529 --validation loss: 0.6247268570404426 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.6312972624707066 --validation loss: 0.6240690940735387 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6314437387425915 --validation loss: 0.623959537230286 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6314138625961503 --validation loss: 0.6239679677813661 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.631174812973974 --validation loss: 0.6244933418199128 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.6307505288025392 --validation loss: 0.6239937888640984 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.6313588234853641 --validation loss: 0.6239553041317883 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.6321175454229051 --validation loss: 0.6241425240741056 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.6313094805138822 --validation loss: 0.6247930894879734 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.6309823254224781 --validation loss: 0.6239755527645934 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.6312883865080108 --validation loss: 0.6239848265460893 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 400 -- training loss: 0.6311058792283593 --validation loss: 0.6247589821908989 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.6312928854899729 --validation loss: 0.6247596559571285 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 458 -- training loss: 0.631475430233546 --validation loss: 0.624751033151851 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.6838235294117647 after step 0 of epoch 0.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiments 1-4, we see overfitting after epoch 1. Even though we see some oscillations in train and validation losses in epoch 1 of these experiments, overall losses go down.\n",
    "\n",
    "The best results for experiment 1 is achieved after step 450 of epoch 1, where the validation accuracy and validation loss are 88.2 and 0.289, respectively.\n",
    "\n",
    "The best results for experiment 2 is achieved after step 50 of epoch 2, where the validation accuracy and validation loss are 89.2 and 0.279, respectively.\n",
    "\n",
    "The best results for experiment 3 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 90.0 and 0.267, respectively.\n",
    "\n",
    "The best results for experiment 4 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 88.5 and 0.258, respectively.\n",
    "\n",
    "In experiments 5 and 6, train and validation losses (as well as validation accuracy) remain constant.\n",
    "\n",
    "Based on these observations, both experiments 3 and 4 seem to give us the best results. Experiment 3 leads to the best validation accuracy (90.0) whereas experiment 4 leads a better validation loss (0.258). We choose to prefer lower validation loss than higher validation accuracy, and for this reason, we take experiment 4 as a better option."
   ],
   "metadata": {
    "id": "rLB131BgV1wH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 114"
   ],
   "metadata": {
    "id": "pj2lyYT1dtf3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(114)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cd6d1d6925bc4b6a885311bbf08c5270",
      "94f8bf6a950e44a6bae9865143fb0a80",
      "fdab65b8cbad43db9bccfc82dbdc366b",
      "99dbe1281a5e4d078571e7031270df12",
      "3a627cc9b70a47729897015542b0ffd4",
      "4625d87aab5743b6b146308d22ed1254",
      "719530e320d54c6e8720acff2dc567d8",
      "370baf02fc1443cc8ecb3f5eb38ea7f9",
      "67d2399e88cd4acb8d520e42bb51e480",
      "95b88e1bcb6d47a28130217b9554b6f9",
      "42af8413648d4117ae46bcb12534c029"
     ]
    },
    "id": "yq0ytGQosgAY",
    "outputId": "20c88c92-7bea-4517-8cfb-91fb3e6470d3"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd6d1d6925bc4b6a885311bbf08c5270"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6472485588786389 --validation loss: 0.6439174331870734 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6174490010946145 --validation loss: 0.6144932327317256 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5673886464831616 --validation loss: 0.5620796084403992 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.46169380928858433 --validation loss: 0.4546802821112614 -- validation accuracy 0.75\n",
      "Epoch 0 Step 200 -- training loss: 0.4527818841417371 --validation loss: 0.4490890573052799 -- validation accuracy 0.7720588235294118\n",
      "Epoch 0 Step 250 -- training loss: 0.38337334729974565 --validation loss: 0.3824194018162933 -- validation accuracy 0.8431372549019608\n",
      "Epoch 0 Step 300 -- training loss: 0.37189484291054586 --validation loss: 0.37868840539572285 -- validation accuracy 0.8480392156862745\n",
      "Epoch 0 Step 350 -- training loss: 0.34198283830612963 --validation loss: 0.3703908191299906 -- validation accuracy 0.8700980392156863\n",
      "Epoch 0 Step 400 -- training loss: 0.3187756635216197 --validation loss: 0.3251100664629656 -- validation accuracy 0.8725490196078431\n",
      "Epoch 0 Step 450 -- training loss: 0.3188990805387367 --validation loss: 0.350086542686411 -- validation accuracy 0.8578431372549019\n",
      "Epoch 0 Step 458 -- training loss: 0.30520564025117813 --validation loss: 0.3308461064509317 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 0 -- training loss: 0.30515681266833367 --validation loss: 0.3301430998333529 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 50 -- training loss: 0.2607558931270716 --validation loss: 0.30555939853337466 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 100 -- training loss: 0.27976990896956855 --validation loss: 0.32432310502318773 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 150 -- training loss: 0.248508751432945 --validation loss: 0.3427596775194009 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 200 -- training loss: 0.2421666172278278 --validation loss: 0.29286353976703156 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.2637075941820988 --validation loss: 0.39704345705389393 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 300 -- training loss: 0.2050375834123631 --validation loss: 0.313459639382713 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 350 -- training loss: 0.21492106314496925 --validation loss: 0.3044566337165295 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 400 -- training loss: 0.20240684079456758 --validation loss: 0.3080363159305325 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 450 -- training loss: 0.16219538408646073 --validation loss: 0.28773550937573117 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 458 -- training loss: 0.1743234342800084 --validation loss: 0.3163907402468955 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 0 -- training loss: 0.16728537505561555 --validation loss: 0.3062123343275458 -- validation accuracy 0.875\n",
      "Epoch 2 Step 50 -- training loss: 0.14614824082272246 --validation loss: 0.2872503163183437 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 100 -- training loss: 0.13552506046860696 --validation loss: 0.336935642303205 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 150 -- training loss: 0.1427223331960474 --validation loss: 0.3223101142063445 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 200 -- training loss: 0.129996320393042 --validation loss: 0.3078037157983464 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 250 -- training loss: 0.12109791208667303 --validation loss: 0.33160442318402084 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 300 -- training loss: 0.2325092494880379 --validation loss: 0.5198032325955436 -- validation accuracy 0.8284313725490197\n",
      "Epoch 2 Step 350 -- training loss: 0.11739676502028029 --validation loss: 0.31982036661721913 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 400 -- training loss: 0.1036316669487226 --validation loss: 0.28585027654965717 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 450 -- training loss: 0.09954269801130547 --validation loss: 0.3110346750575392 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 458 -- training loss: 0.09675266591665661 --validation loss: 0.29662579104450404 -- validation accuracy 0.8897058823529411\n",
      "The best accuracy was 0.8946078431372549 after step 150 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6472485588786389 --validation loss: 0.6439174331870734 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6222130482882456 --validation loss: 0.6181539974960626 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5920884793620224 --validation loss: 0.5875646337574604 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.4615751320013293 --validation loss: 0.47049711337860894 -- validation accuracy 0.7475490196078431\n",
      "Epoch 0 Step 200 -- training loss: 0.43364473028120654 --validation loss: 0.43219192559812586 -- validation accuracy 0.7230392156862745\n",
      "Epoch 0 Step 250 -- training loss: 0.3719698004505733 --validation loss: 0.3832336437030166 -- validation accuracy 0.8406862745098039\n",
      "Epoch 0 Step 300 -- training loss: 0.4423681117740332 --validation loss: 0.44244082213616837 -- validation accuracy 0.7892156862745098\n",
      "Epoch 0 Step 350 -- training loss: 0.4166752012864502 --validation loss: 0.4385894997885414 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 400 -- training loss: 0.32859834113558006 --validation loss: 0.32580838051131544 -- validation accuracy 0.8872549019607843\n",
      "Epoch 0 Step 450 -- training loss: 0.34101959531376047 --validation loss: 0.37649517667059806 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 458 -- training loss: 0.33929693895292695 --validation loss: 0.35600855888104904 -- validation accuracy 0.875\n",
      "Epoch 1 Step 0 -- training loss: 0.3395060232002491 --validation loss: 0.3547004855730954 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 50 -- training loss: 0.3023423572884536 --validation loss: 0.3238517276066191 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 100 -- training loss: 0.2747258255765459 --validation loss: 0.30025070657332736 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 150 -- training loss: 0.250774063794896 --validation loss: 0.2933071113246329 -- validation accuracy 0.9019607843137255\n",
      "Epoch 1 Step 200 -- training loss: 0.24492348549980872 --validation loss: 0.2841380006980662 -- validation accuracy 0.9019607843137255\n",
      "Epoch 1 Step 250 -- training loss: 0.23046751654745448 --validation loss: 0.28221183876488726 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 300 -- training loss: 0.22964603327466318 --validation loss: 0.3015916843295974 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 350 -- training loss: 0.23292231998022864 --validation loss: 0.27761681487455087 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 400 -- training loss: 0.2173679760030282 --validation loss: 0.2892582275009915 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 450 -- training loss: 0.19618527306556247 --validation loss: 0.2698379484388758 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.1876942617412908 --validation loss: 0.2677275372632578 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 0 -- training loss: 0.18741272260639857 --validation loss: 0.2676104947778524 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 50 -- training loss: 0.18080879009302406 --validation loss: 0.272588206089887 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 100 -- training loss: 0.16647527687766941 --validation loss: 0.2880009359260108 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 150 -- training loss: 0.16222183643038787 --validation loss: 0.28233827517240073 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 200 -- training loss: 0.16373369750852873 --validation loss: 0.270159926575919 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.17372217824508096 --validation loss: 0.30671399592549775 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 300 -- training loss: 0.1518702655807462 --validation loss: 0.2703392705971412 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 350 -- training loss: 0.1492081223266739 --validation loss: 0.2710887638614604 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.14790484211194554 --validation loss: 0.26800532547720507 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 450 -- training loss: 0.1460948861467861 --validation loss: 0.26910204258656095 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 458 -- training loss: 0.14606514955568484 --validation loss: 0.26925971559888007 -- validation accuracy 0.8970588235294118\n",
      "The best accuracy was 0.9019607843137255 after step 150 of epoch 1.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6448946821144204 --validation loss: 0.6412843909918093 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6071448505963635 --validation loss: 0.6016232266145594 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6702033924121483 --validation loss: 0.6723944942156473 -- validation accuracy 0.5196078431372549\n",
      "Epoch 0 Step 150 -- training loss: 0.42154761118112305 --validation loss: 0.41360824482113706 -- validation accuracy 0.8161764705882353\n",
      "Epoch 0 Step 200 -- training loss: 0.5710662842965594 --validation loss: 0.5707667277139776 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.4437970536434313 --validation loss: 0.4327423993278952 -- validation accuracy 0.8308823529411765\n",
      "Epoch 0 Step 300 -- training loss: 0.45766467079195583 --validation loss: 0.4602741440575497 -- validation accuracy 0.8014705882352942\n",
      "Epoch 0 Step 350 -- training loss: 0.35678478215936743 --validation loss: 0.3746762690956102 -- validation accuracy 0.8284313725490197\n",
      "Epoch 0 Step 400 -- training loss: 0.41208646438350344 --validation loss: 0.41853194464655485 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 450 -- training loss: 0.37785000503387844 --validation loss: 0.4011850158373515 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 458 -- training loss: 0.4073659141988276 --validation loss: 0.4357457128809948 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 0 -- training loss: 0.4168524272204225 --validation loss: 0.4460284460116835 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 50 -- training loss: 0.33675951441680946 --validation loss: 0.3685785293871281 -- validation accuracy 0.8480392156862745\n",
      "Epoch 1 Step 100 -- training loss: 0.2611414087299168 --validation loss: 0.32982097814480466 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 150 -- training loss: 0.28976757349426124 --validation loss: 0.3896804649163695 -- validation accuracy 0.8480392156862745\n",
      "Epoch 1 Step 200 -- training loss: 0.27670770925763905 --validation loss: 0.3065733252202763 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 250 -- training loss: 0.22086858041868554 --validation loss: 0.3079002175626217 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 300 -- training loss: 0.226125171150371 --validation loss: 0.3619337960274196 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 350 -- training loss: 0.320623367700182 --validation loss: 0.360490399832819 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 400 -- training loss: 0.22658071524518378 --validation loss: 0.37537731911402705 -- validation accuracy 0.8504901960784313\n",
      "Epoch 1 Step 450 -- training loss: 0.24665477941693303 --validation loss: 0.3174187123191123 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 458 -- training loss: 0.30334934011134185 --validation loss: 0.36950039951240315 -- validation accuracy 0.8063725490196079\n",
      "Epoch 2 Step 0 -- training loss: 0.30249510845067973 --validation loss: 0.36963514355467814 -- validation accuracy 0.8063725490196079\n",
      "Epoch 2 Step 50 -- training loss: 0.15226562846703598 --validation loss: 0.28193662151256027 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 100 -- training loss: 0.136860282259764 --validation loss: 0.33502723068437157 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 150 -- training loss: 0.1497907347141203 --validation loss: 0.27778270614205625 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 200 -- training loss: 0.1232076388619402 --validation loss: 0.3060354888073954 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 250 -- training loss: 0.11861699906001294 --validation loss: 0.27217195586611825 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 300 -- training loss: 0.11903780087735301 --validation loss: 0.30113214513688696 -- validation accuracy 0.8700980392156863\n",
      "Epoch 2 Step 350 -- training loss: 0.10291782661375624 --validation loss: 0.3242488109013614 -- validation accuracy 0.8700980392156863\n",
      "Epoch 2 Step 400 -- training loss: 0.09040394382782621 --validation loss: 0.31624185461916177 -- validation accuracy 0.8602941176470589\n",
      "Epoch 2 Step 450 -- training loss: 0.07661935484974212 --validation loss: 0.30987092125795634 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 458 -- training loss: 0.08050943709289034 --validation loss: 0.3141334894861953 -- validation accuracy 0.8774509803921569\n",
      "The best accuracy was 0.8970588235294118 after step 250 of epoch 1.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6448946821144204 --validation loss: 0.6412843909918093 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.622123702354161 --validation loss: 0.6173617606069527 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6766177692444496 --validation loss: 0.6768086646117416 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 150 -- training loss: 0.5808221340049585 --validation loss: 0.5813268896411447 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 200 -- training loss: 0.4874726285374762 --validation loss: 0.4773085576062109 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 250 -- training loss: 0.41652365569390504 --validation loss: 0.4409679989604389 -- validation accuracy 0.8137254901960784\n",
      "Epoch 0 Step 300 -- training loss: 0.4179290009739612 --validation loss: 0.41499631399033116 -- validation accuracy 0.8431372549019608\n",
      "Epoch 0 Step 350 -- training loss: 0.34576035523888593 --validation loss: 0.3768205818007974 -- validation accuracy 0.8529411764705882\n",
      "Epoch 0 Step 400 -- training loss: 0.35482420546686466 --validation loss: 0.351661027062173 -- validation accuracy 0.8504901960784313\n",
      "Epoch 0 Step 450 -- training loss: 0.328937752419892 --validation loss: 0.3782130742043841 -- validation accuracy 0.8504901960784313\n",
      "Epoch 0 Step 458 -- training loss: 0.32152600471165704 --validation loss: 0.3405867701067644 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 0 -- training loss: 0.325071469517445 --validation loss: 0.34143370974297615 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 50 -- training loss: 0.34709586744645127 --validation loss: 0.41462096230437356 -- validation accuracy 0.8529411764705882\n",
      "Epoch 1 Step 100 -- training loss: 0.2796971144028868 --validation loss: 0.32445886460881607 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 150 -- training loss: 0.24678513283327969 --validation loss: 0.3120883557324608 -- validation accuracy 0.875\n",
      "Epoch 1 Step 200 -- training loss: 0.25088709613109467 --validation loss: 0.3120107230018167 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 250 -- training loss: 0.22260333094461812 --validation loss: 0.3186623516912554 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 300 -- training loss: 0.202800284864174 --validation loss: 0.32507689198588624 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 350 -- training loss: 0.21973838670126494 --validation loss: 0.30689483135938644 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 400 -- training loss: 0.1902480965778475 --validation loss: 0.3013845827503532 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 450 -- training loss: 0.15044686890740866 --validation loss: 0.29864481894993317 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 458 -- training loss: 0.15502103642927795 --validation loss: 0.2979914711824819 -- validation accuracy 0.8676470588235294\n",
      "Epoch 2 Step 0 -- training loss: 0.15381715602539722 --validation loss: 0.297256279152398 -- validation accuracy 0.8676470588235294\n",
      "Epoch 2 Step 50 -- training loss: 0.12345288816255097 --validation loss: 0.31779835253552186 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 100 -- training loss: 0.12334238896085546 --validation loss: 0.3735327926080893 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 150 -- training loss: 0.11646354941789198 --validation loss: 0.3563356877980279 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 200 -- training loss: 0.10756506527366202 --validation loss: 0.3335998790822558 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 250 -- training loss: 0.1056480890754732 --validation loss: 0.3739834324657625 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 300 -- training loss: 0.09176160821646517 --validation loss: 0.3381171772603457 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 350 -- training loss: 0.08778752605755426 --validation loss: 0.34555228222526757 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 400 -- training loss: 0.08317754075716377 --validation loss: 0.32688495262489453 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 450 -- training loss: 0.08000194241114221 --validation loss: 0.32691427771294235 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 458 -- training loss: 0.07986905502382674 --validation loss: 0.32699032372101117 -- validation accuracy 0.8872549019607843\n",
      "The best accuracy was 0.8921568627450981 after step 350 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6426618735514954 --validation loss: 0.638711319250219 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6316457829703952 --validation loss: 0.6257051159353817 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6337695747678835 --validation loss: 0.6285211823734582 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6347753252988287 --validation loss: 0.6299369790974785 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6383528900302313 --validation loss: 0.629155566294988 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.6334736769235731 --validation loss: 0.6251174398497039 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.6321934622617069 --validation loss: 0.6241308170206407 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.6311106267577942 --validation loss: 0.6250692553379956 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 400 -- training loss: 0.6311000911498641 --validation loss: 0.6241158527486464 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6307041277553002 --validation loss: 0.624198851632137 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6316778666313437 --validation loss: 0.6251328622593599 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.6312609797339553 --validation loss: 0.6250420405584223 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6318369798021379 --validation loss: 0.6254014296858919 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.6434754443584184 --validation loss: 0.6398065300548778 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 150 -- training loss: 0.631225292329435 --validation loss: 0.6239693497910219 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.631838520108225 --validation loss: 0.6254042200013703 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6322308589170701 --validation loss: 0.6244552410116383 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6347402738719724 --validation loss: 0.6297062308180565 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6316569273508192 --validation loss: 0.6259300796424642 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.630917902865441 --validation loss: 0.6239546017319548 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.6309109731437335 --validation loss: 0.6240624078348571 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6330549185182534 --validation loss: 0.6248364092088213 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6330480279486164 --validation loss: 0.6249925318886252 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.6316558856979694 --validation loss: 0.6241341250784257 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.6314608156681061 --validation loss: 0.6239747066123813 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.6311033978441442 --validation loss: 0.6240935243812262 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.6403936835935173 --validation loss: 0.636325948378619 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.639466636645768 --validation loss: 0.6300843317134708 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.6309738433828541 --validation loss: 0.6239822986079198 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.631467911412773 --validation loss: 0.6239767033679813 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 400 -- training loss: 0.6419756844931958 --validation loss: 0.6381198623601128 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.6309461398192221 --validation loss: 0.6243889892802519 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 458 -- training loss: 0.63795403775826 --validation loss: 0.6290436433810814 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.6838235294117647 after step 0 of epoch 0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6426618735514954 --validation loss: 0.638711319250219 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6315188698779004 --validation loss: 0.6255039093541164 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6330436341513216 --validation loss: 0.6275956017129561 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6340110010441092 --validation loss: 0.6290045713677126 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6375863454051007 --validation loss: 0.6285182260999492 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.6336133347617255 --validation loss: 0.6252190686908423 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.6330326032015233 --validation loss: 0.6246570687667996 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.6333012627620324 --validation loss: 0.6275750398635864 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 400 -- training loss: 0.6298225777211532 --validation loss: 0.6229458422053094 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6307306015673286 --validation loss: 0.6243160507258247 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6314154355614273 --validation loss: 0.6246163441854364 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.6310087340459845 --validation loss: 0.6245511016424965 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6312941011520252 --validation loss: 0.6242388188838959 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.63614655118882 --validation loss: 0.6313982547498217 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 150 -- training loss: 0.6309961138987074 --validation loss: 0.6239596003410863 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.6315237975847747 --validation loss: 0.6248543916964063 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6313503232007452 --validation loss: 0.623999250870125 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6354556766730248 --validation loss: 0.6305728800156537 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6308922794259971 --validation loss: 0.6239451976383433 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.6307728176283162 --validation loss: 0.6239649933927199 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.6310857742830039 --validation loss: 0.6247264205240736 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6310989252882067 --validation loss: 0.6240675145504522 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6309112277945143 --validation loss: 0.6240317967592501 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.6323450924524294 --validation loss: 0.6245217966098412 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.6313579993440175 --validation loss: 0.6239456814878127 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.6311394456035431 --validation loss: 0.6239934312362297 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.6308937768790717 --validation loss: 0.6241937151142195 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.6313375363812208 --validation loss: 0.6239914672047484 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.6313675155696786 --validation loss: 0.6240012505475212 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.6310904407163591 --validation loss: 0.6242315833475075 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 400 -- training loss: 0.6311434803445355 --validation loss: 0.6248409128656575 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.6312182580074194 --validation loss: 0.6249763924701541 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 458 -- training loss: 0.6310174203516351 --validation loss: 0.624946593653922 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.6838235294117647 after step 0 of epoch 0.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiments 1, 2, and 4, we see overfitting after epoch 1. In experiments 1,2, and 4, we also see some oscillations in both train and validation losses in epoch 1, but overall losses go down. In experiment 3, we see oscillations in both losses even in epoch 0, but overall losses go down until step 150 of epoch 2.\n",
    "\n",
    "The best results for experiment 1 is achieved after step 450 of epoch 1, where the validation accuracy and validation loss are 88.7 and 0.288, respectively.\n",
    "\n",
    "The best results for experiment 2 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 88.5 and 0.289, respectively.\n",
    "\n",
    "The best results for experiment 3 is achieved after step 150 of epoch 2, where the validation accuracy and validation loss are 88.5 and 0.278, respectively.\n",
    "\n",
    "The best results for experiment 4 is achieved after step 458 of epoch 1, where the validation accuracy and validation loss are 86.8 and 0.298, respectively.\n",
    "\n",
    "In experiments 5 and 6, both train and validation losses remain constant (up to some oscillations) and the accuracy remain constant as well. This suggests that the (consntant or initial) learning rate of $5\\times 10^{-5}$ is probably too large.\n",
    "\n",
    "Based on these observations, we conclude that experiment 3 leads to the best results."
   ],
   "metadata": {
    "id": "hRiOTFSPYbiH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "We conclude that the experiment with a random seed of 23 with a linearly decreasing learning rate from $3\\times 10^{-5}$ to zero leads to the best result (validation loss of 0.258) if we stop after step 458 of epoch 1."
   ],
   "metadata": {
    "id": "8RA1IrJ8ZZvE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Repeating the best performing experiment\n",
    "with the stopping condition to get the\n",
    "model weights and to calculate test accuracy.\n",
    "'''\n",
    "\n",
    "lr = 3e-5\n",
    "lr_scheduler = True\n",
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "stopping_condition = {'step': 458, 'epoch': 1}\n",
    "\n",
    "set_seed(23)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "trainer_config = {'optimizer' : AdamW,\n",
    "              'num_epochs' : num_epochs,\n",
    "              'learning_rate' : lr,\n",
    "              'lr_scheduler' : lr_scheduler,\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "trainer = sentence_similarity_trainer(model=model,\n",
    "                  train_dataloader = train_dataloader,\n",
    "                  val_dataloader = val_dataloader,\n",
    "                  device = device,\n",
    "                  trainer_config = trainer_config,\n",
    "                  stopping_condition = stopping_condition,\n",
    "                  )\n",
    "\n",
    "# Running the training loops\n",
    "trainer.train()"
   ],
   "metadata": {
    "id": "U9CEBG_9ZYVb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526,
     "referenced_widgets": [
      "fabcdfa61dda4451b10e5da0c9b9f83a",
      "ca1f7fc435234ab9b8a62a07877ec91d",
      "a284032862674e41a59ee37292ca5aca",
      "154e02eb588b40eda4ddaf7a2028f772",
      "92e8a35ccd8642f5bac7bad8d60cd2fb",
      "3a11ca4b8a7a400ba02e3f40a5cc35b2",
      "07dfb3949ede4a6b929ea2ad78f1d6db",
      "1e2a7dfa6c02402986765c38472c5d83",
      "c3db06858c264b55818c8769d437680c",
      "76daed649e534f7e8ca1b8bf28165c3d",
      "ad95920328874418afc1d942d1cd5f52"
     ]
    },
    "outputId": "463ab15c-d89f-45c1-e19d-46e7faaa3b5e"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fabcdfa61dda4451b10e5da0c9b9f83a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 Step 0 -- training loss: 0.6589438468542493 --validation loss: 0.6570845316438114 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5863408955353797 --validation loss: 0.5830099249587339 -- validation accuracy 0.7181372549019608\n",
      "Epoch 0 Step 100 -- training loss: 0.5481619011683792 --validation loss: 0.5280616002924302 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 150 -- training loss: 0.6537124352257756 --validation loss: 0.6515997765110988 -- validation accuracy 0.6862745098039216\n",
      "Epoch 0 Step 200 -- training loss: 0.4394521601579288 --validation loss: 0.4309568892360902 -- validation accuracy 0.8186274509803921\n",
      "Epoch 0 Step 250 -- training loss: 0.412158476923286 --validation loss: 0.39726442931329503 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 300 -- training loss: 0.43370816077477015 --validation loss: 0.4352886171317568 -- validation accuracy 0.8063725490196079\n",
      "Epoch 0 Step 350 -- training loss: 0.38677314097520316 --validation loss: 0.3752311225615296 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 400 -- training loss: 0.36349065182629103 --validation loss: 0.37326668042178246 -- validation accuracy 0.8774509803921569\n",
      "Epoch 0 Step 450 -- training loss: 0.40728476323787943 --validation loss: 0.44272881015843035 -- validation accuracy 0.8406862745098039\n",
      "Epoch 0 Step 458 -- training loss: 0.36383069503021653 --validation loss: 0.3953362947293356 -- validation accuracy 0.8455882352941176\n",
      "Epoch 1 Step 0 -- training loss: 0.3412218391895294 --validation loss: 0.3793334844065647 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 50 -- training loss: 0.3387242298175567 --validation loss: 0.37092785960903357 -- validation accuracy 0.8186274509803921\n",
      "Epoch 1 Step 100 -- training loss: 0.3127283330576612 --validation loss: 0.32090070025593626 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 150 -- training loss: 0.28822258934540945 --validation loss: 0.38312045835396824 -- validation accuracy 0.8455882352941176\n",
      "Epoch 1 Step 200 -- training loss: 0.2623021282450436 --validation loss: 0.29033062271043364 -- validation accuracy 0.875\n",
      "Epoch 1 Step 250 -- training loss: 0.27024830974159614 --validation loss: 0.3301689766493498 -- validation accuracy 0.8382352941176471\n",
      "Epoch 1 Step 300 -- training loss: 0.22623559702309518 --validation loss: 0.2965565848292089 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 350 -- training loss: 0.25584664862107864 --validation loss: 0.3619906655056219 -- validation accuracy 0.8308823529411765\n",
      "Epoch 1 Step 400 -- training loss: 0.20136026213907338 --validation loss: 0.27312433409194153 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 450 -- training loss: 0.1727547854700477 --validation loss: 0.26169973794443935 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 458 -- training loss: 0.16614991609891774 --validation loss: 0.2584145206081517 -- validation accuracy 0.8848039215686274\n",
      "The best accuracy was 0.8848039215686274 after step 450 of epoch 1.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Calculating the test loss\n",
    "'''\n",
    "\n",
    "def test_evaluation():\n",
    "\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "      test_losses = []\n",
    "      test_accuracies = []\n",
    "\n",
    "      for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "        # Getting the batch loss\n",
    "        batch = {k: v.to(trainer.device) for k, v in batch.items()}\n",
    "        outputs = trainer.model(**batch)\n",
    "        test_losses.append(outputs.loss.item())\n",
    "        # Getting the batch accuracy\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        test_accuracy = (predictions == batch['labels']).float().mean()\n",
    "        test_accuracies.append(test_accuracy.item())\n",
    "\n",
    "      avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "      avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "    trainer.model.train()\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy\n",
    "\n",
    "test_loss, test_acc = test_evaluation()\n",
    "print(f\"{test_loss=}\")\n",
    "print(f\"{test_acc=}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjS1xGweakNS",
    "outputId": "66bf9a23-08f9-4a6f-ad56-3ec1a6df1296"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_loss=0.3181992418184463\n",
      "test_acc=0.8674768518518519\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Uploading the weights on HF\n",
    "'''\n",
    "\n",
    "# Save model weights\n",
    "file_name = \"model_weights.pth\"\n",
    "trainer.save_model(file_name)\n",
    "\n",
    "# Logging into Hugging face Hub\n",
    "hf_token = userdata.get('hf_TOKEN')\n",
    "login(token=hf_token)\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"mudassirmoosa/sentence-similarity-transformer-comparison\"\n",
    "\n",
    "# Uploading model weights\n",
    "api.upload_file(\n",
    "    path_or_fileobj=file_name,\n",
    "    path_in_repo=\"RoBERTa_for_sentence_similarity.pth\",\n",
    "    repo_id=repo_id,\n",
    "    token=hf_token\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "referenced_widgets": [
      "b39c76ae7d9c4cbfbe742c102466aa78",
      "42770c05304d491c8a94c2cf54028a92",
      "c2a006227d2145d7972d25b03a3ee4e6",
      "df1c5db9b78c45b4a334a9c93e42fc7e",
      "a6b85089d7974c32a73e350f2ee119d6",
      "2ffd53f41baf4505a735aba23658d5af",
      "1409a9cb5fbd403f8df8b9fdfe440c1c",
      "da235059d1614fe9b78f904ab17d7a87",
      "a1a5293b306b4362b20420c55366a37b",
      "918d2454fe6e4eaab04b21dcb3b53328",
      "2e379f0f999c4aa48c20d7f88beda27b",
      "3d07136310df421aa797c8a187ba4849",
      "37e89cc9127f4420ab5cb82a442fdf84",
      "a6961aa18aae465dbb522fdf1bc66dfc",
      "eff303e303814db38ce79ddddf615f04",
      "f8c7f4d3eee742d6a065248d0a6ad244",
      "005d80e5247d44a4941794aaacce1f00",
      "fdd676bf147741eab1155ea2b867ea6e",
      "ef58af1c572544dba0b98469d0d1fbd9",
      "c44ad227981949b49af2a278759dd138",
      "a67a9b86e2574628965563aa23b06bad",
      "f19144efeb274f0487db510ce809aade",
      "bfc17eb265d846368f95f26f5574f834",
      "acecccddce6b40ba83ec895da13f8d1c",
      "84e0357e6a1c4531ab3c50e2d3b156a4",
      "44eba2ed6c734ea8a9a5a3335124540b",
      "b833b255711349cfb90fc3aea3039e66",
      "f01cedcfb3ee40f1bd08e4d4d45c59ef",
      "dac2b99029b0411a87a5d1d11766fb53",
      "04fc036f2e3e431db80116851388c53c",
      "2e16323f43b7410ca99b2045c81a8d77",
      "abce83d1014c47fa863232b2d0a12564",
      "fb3c3d373017402fa40f68112d0e026f"
     ]
    },
    "id": "D-97uMWBapAK",
    "outputId": "34875ecd-5ad7-4b42-8c89-68f91799a6eb"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b39c76ae7d9c4cbfbe742c102466aa78"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d07136310df421aa797c8a187ba4849"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  model_weights.pth                     :   0%|          |  566kB /  499MB            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfc17eb265d846368f95f26f5574f834"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mudassirmoosa/sentence-similarity-transformer-comparison/commit/ba70e57022248fadc243e4dbeaa1e4a6b4724724', commit_message='Upload RoBERTa_for_sentence_similarity.pth with huggingface_hub', commit_description='', oid='ba70e57022248fadc243e4dbeaa1e4a6b4724724', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mudassirmoosa/sentence-similarity-transformer-comparison', endpoint='https://huggingface.co', repo_type='model', repo_id='mudassirmoosa/sentence-similarity-transformer-comparison'), pr_revision=None, pr_num=None)"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  }
 ]
}