{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "T4oNyr44Q328",
    "QCydNnu6d5JG",
    "5C3JtLW3d7CQ",
    "zcrQ56Bzd96H"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u88zo-xxO5vY"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from huggingface_hub import HfApi, login, hf_hub_download\n",
    "from google.colab import userdata\n",
    "\n",
    "from supplementary_file_for_sentence_similarity import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the tokenizer and a dataset"
   ],
   "metadata": {
    "id": "_L4TSubBPCmT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the tokenizer\n",
    "\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Set padding token to EOS token\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "metadata": {
    "id": "wg-rNyjRPGE4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "a93d78e0dd76417d991d0fb73c90e327",
      "913d8ad54c6941daa6174a697be75dd3",
      "e2483ed7ba8847c4b18b60ee23613061",
      "5c977f1fd0d54a93b27aa045cc4a0cd7",
      "aebe4b945b5844d0963a7a2e722526cb",
      "197891cc46b342d2870e99647279d52a",
      "ad5e9f8e50994aca8f468097232dac0c",
      "c7824bf4e3b4494d9a003868106d7661",
      "dca92b1a146f4a66bc5ea980f2c84be4",
      "252a9ba74ef84b6cb374193fd22afe8c",
      "799d0cbb145d4e49b9c56c0ad3c7021d",
      "f1abd7c5f8484425ad4a31ee30bc1130",
      "e901f29760db469689ad0c2bd5573ac3",
      "f4a2fae2ccf94077bb9b3ee41f1f398b",
      "ca9cf9710d6f4959a23f34a7c0377e72",
      "400923f2dda94d98a64abbdf6b1ad6fa",
      "cbddbaf88bae4fc49b4b641ffc44b7f5",
      "695758cda62140ff9067ec486b35648f",
      "54f0ea3897884fd8baeda5ac38f54161",
      "ea32203170414a738295cee4b3a3c276",
      "9e6c2691e40e4390806284d71498ab96",
      "1e188d3cc09c4ae987bc2b8bae2158fd",
      "c0c3cb0773dc4cddbb616f939dd8417e",
      "3a5261c5448741e6b90f24567fae4002",
      "d037d3084f5b407ba16ecbca8ee2b658",
      "4a78dbc285fd4e45850fb47b28b28c3d",
      "fd1d6839984c404391cab75c659c7996",
      "505ef623e6024b26868c121ecb267991",
      "8c51b9c1eeaa4600b35110ddc1ffa741",
      "453e2a0ae70c4469865575ddaef97d1d",
      "1d635a85226e449bbfc7d33f71f574c7",
      "9ddfd8cab3194c69b180317c266de3c9",
      "171fe22db68d4fcb81aaec79a0043d97",
      "6f453161b6ff4f55a0b8c41b05b020b8",
      "2fbd9d3d12e740b7870372626760c9f9",
      "d20f2abacddb46c39d925e92a1618912",
      "9566e8c3c07d4395822abc2d6691ce44",
      "c27ae23a6f184cfd97b185cd8f3fc761",
      "097d3ec28e08460bb28633cad856c301",
      "d4c4327ea40f4b5e8cadf158179b0303",
      "b59e60ddaabe4784b734b0f574f5d402",
      "f32fd614533c45fe830297a8364a575a",
      "4f2b70b47fb7465dbfb7d302ceb91002",
      "0a02eb463dbd4c7aacb45c2e7fff831b",
      "66b59afc429b405e8fd8b8a5004add96",
      "b48bf4e0b6224bd2955de50c37a4ee09",
      "16a4080e0501496cb7307d1bc264d7a8",
      "016c9ce5aadc4c5c8de6dec38fd415b7",
      "f4643ff8538d4fdeb0df6756c9e05ecf",
      "c01b779c1a614b4997ab04f78f8e2525",
      "cd440a07c2ed4f3086b781805e597f69",
      "1afe600530a54e7d9f137f020115c157",
      "820b0b4ae5d747f3b3977a00d0e9859d",
      "eb7405ecd9d4480faa289a1766cd1f57",
      "6b6930790d7444a19af29828b6e90e65"
     ]
    },
    "outputId": "bcdd9168-7932-4ac2-829f-1647e011b481"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a93d78e0dd76417d991d0fb73c90e327"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f1abd7c5f8484425ad4a31ee30bc1130"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0c3cb0773dc4cddbb616f939dd8417e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f453161b6ff4f55a0b8c41b05b020b8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66b59afc429b405e8fd8b8a5004add96"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = sentence_similarity_dataloaders(tokenizer)\n",
    "\n",
    "set_seed(42)\n",
    "train_dataloader, val_dataloader, test_dataloader = dataloader.get_dataloaders()"
   ],
   "metadata": {
    "id": "k-8IUA_JP9zN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "2ae6004fd49d48c4b793b345e47f835a",
      "084da1b606a143e695cf4876178d93d2",
      "f9d75413c2aa4129adb1182f17537bd4",
      "35a82b4a3e6440fd8caf42ac19b1bc38",
      "701c4e66daf04b979e333ed4696d3e8a",
      "a1fc0de7416a48fbb97ec4177e883fe7",
      "78e471a1fcc2432e98358d624cc540fc",
      "782b5c1661ad4e628b0d1237b9f82adb",
      "58b751dc2c3b420eb8e58f1c59703e28",
      "a720b3764d384f5c98394027bd9368d7",
      "4fbd5c41399e49578dff784d87c26f95",
      "0c559312a0164ab7b1e2a85e0898ddab",
      "b19c9b1a5175449f9b488b80bbc144be",
      "9b4568f781c54761a03a38f4a33751b4",
      "309343b58ca8474581857e028ab8830e",
      "ed57bb65546745e4afe2a03f6de01236",
      "91fcd4d8d6de4345a86854042abfed6c",
      "9bf805de42294ef4aeea12b6f4dcc90a",
      "7718644ffef94bfab556e51f3ff4c60a",
      "c47149384c7c40ffa11c0e19e910517d",
      "8974ec8147064b0384e434d6301cbe36",
      "a047d8596b5b48ff9921737db9155de3",
      "db8b7776339d46f796d57d2d88956090",
      "71704f0323bd480490120bebe8688da1",
      "c154627eb35643a7969af7add71873c3",
      "f48c484b0ada4f4483eedffb9e2b3c36",
      "916ae411977b4dc9979f8b9273ebf49b",
      "0179a9221706442597efbf03afd72dfd",
      "e4edfc59841d4f9c9a0843b68b6d2ec7",
      "63a26fee5aba4614b446c4e1827f74a2",
      "217b0ca89f064a199dba736c8bea19ac",
      "34bda1c3a2ba4b899d0ea2255594f9dc",
      "5a545f4c97184c39ac3f0a4273db9555",
      "9402971444c6423e9b511ffe86d893a1",
      "c511481d57b3425b9c26af76097b6084",
      "560bc3dd028e45229a449e3ebe4fc0aa",
      "6f81144ffc5c4675b4bcab7139c1c9be",
      "e5bb1e11f57a482ea7aaa8b476d9c6c4",
      "0639295358824734b394520e7d69d6d7",
      "69f1c0d2665443a2af46fc4d3973bfb2",
      "1139fdf687a34d72aad3536d7cffb34a",
      "a5cfec2ee75f4da08efb4dbc95e83b60",
      "9d73fa1cf33f488a831afffaaa4347ba",
      "636abe8b784340d2a88558514e4967e0",
      "f5ea291308f54b33afa26fc62ab338d5",
      "7dc079959e884951aff4451d203ce2be",
      "8dcc9ad1939b451d9f8f873e5a7c929d",
      "11be59ce40154f77aab974ef30fc9b7b",
      "cce331bae8c2485d9409d4a07b480a2c",
      "54110d6d4b394b3abfa26a8471550419",
      "56c6d42daaf54c4ba99f1359dc21f900",
      "f2abb06eafc9486b96549c25c6d02a7f",
      "034617f030f64057980de5e255fccaef",
      "d2685d7fa1564995b97a7fea90184ee1",
      "cc5b936a0a8642f08973165f05de8d76",
      "ade50f825b5a4fed8d46752f0d212238",
      "7fbbfb03135c42079793bcda426a1be5",
      "3346305be75e472cafc4edb886cf7e02",
      "9ada98f5eb344f77b932bb0394bf1730",
      "ac1e7d695d5c468d853ba449c6094a8e",
      "be4251705374445dbdfd76a2e57031c2",
      "de716daab1a749f09113d6f31994dfd9",
      "fddc5597653a4479ba83697edec3ecf0",
      "5ce3efac73ab43ec8e146f3cd17e4b38",
      "273c9b9f9a684c8ea8391e3e3225bc57",
      "ff433eb98dfb41d0811a4182a5b38899",
      "d8c0cd9923a64aaf8ad4ba5ad2aaf724",
      "a7d7a46e2a23424694950964fef652ff",
      "aba89cfefdf3428d80a2d62bafb1e22d",
      "ba97df5103654f8498b8cd4d3807b4b8",
      "a5d15a0efc8542afac5d98ba673ffc0d",
      "c914407ed78245e6991efcae07afc3ac",
      "0421c3c525da49e4838c239e6d485189",
      "9fa80890b5c44726b4e3685ef5a56934",
      "268c2297e24841f6acc0bca4e1c04743",
      "cd75c11b4c4b43ec9b73996b2ec4babb",
      "b6e5f629101643c0ba2c6ba04783225a",
      "c30364e5c9cb44b98155c62810dcba3d",
      "c0238e932b1246d2acb57eece2b044c1",
      "8eb9d9cfc5734367a7f06b7d91e6ed50",
      "bbe90fa3e52d4dbb977f32520f8cc392",
      "2dcfc9975bcc4f1f98b558ca574af58e",
      "3ebd0838b19140f98ca1de36f6cfcbcb",
      "0215a27c0fc2465393782f9681726573",
      "8313581a0a594b599154bd0d951134df",
      "302e007b58104204a4ccd76f71d5a4bb",
      "1d66f598ba8c44f289a78f122c1f79f8",
      "a1a6d9e24fff4bf29595e884bbc5ad84",
      "d71e9fa96d9e401e9fc3890534d66fa5",
      "e42d057ed7204ae48239ee88af2dbdb6",
      "046a9030b2b8404ab95e69cfc66a33a1",
      "3f48f7b253fe4db38ea8484beca8f5a7",
      "6c3d49a1789b4583bb3daa47a0ac30d7",
      "7ad2cc84c62e4d80ab7e5dafd86d64d5",
      "02b98732633f4b689de8faf9524706cc",
      "a2e9387506324892a4931d686e45ec09",
      "92dab9f25cc644bc8a14d1f7434cb3c3",
      "ea66bcae4bf34a579ff88f3ddb642c6d",
      "55e965e332c042e192fddb726d725587",
      "cb781d700d5f4411b435e9985237d14c",
      "1fad572c05a14c02b29c62dc4ef8b420",
      "2bead987938e44568485421c38b23fdd",
      "2f2b675b373041ed891fb0b39d48a391",
      "c1e8dc32094f4d68a94fe51d4c2ca6d4",
      "ad49c1cceba64297a3413990b473edca",
      "3df442caa9924f818592adf66f66867b",
      "40ff4eada88f4f5298b1d6311e07d33f",
      "151ddfed01234da6a3aaae5a5b3f3762",
      "98c2a6be5c1a476abc42592607e8a2b4",
      "a33a723d8a6b4d01aa5cc2073949a508"
     ]
    },
    "outputId": "1afb22f8-8d0a-479a-a5c7-d9df2c5c635b"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ae6004fd49d48c4b793b345e47f835a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c559312a0164ab7b1e2a85e0898ddab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db8b7776339d46f796d57d2d88956090"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9402971444c6423e9b511ffe86d893a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5ea291308f54b33afa26fc62ab338d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ade50f825b5a4fed8d46752f0d212238"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8c0cd9923a64aaf8ad4ba5ad2aaf724"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c30364e5c9cb44b98155c62810dcba3d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d71e9fa96d9e401e9fc3890534d66fa5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb781d700d5f4411b435e9985237d14c"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Experiments"
   ],
   "metadata": {
    "id": "T4oNyr44Q328"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr_list = [1e-5, 3e-5, 5e-5]\n",
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "PqytZjpiXnjN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 137"
   ],
   "metadata": {
    "id": "QCydNnu6d5JG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(137)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    # Set padding token to EOS token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7a839a3161e947f0b165b97677d4d478",
      "14fde500c1724b3093af9922aad1881e",
      "c0e635d0700c4f95a42bbc04eda32090",
      "2bc3ff6f85294ad291f4e401dadb8dca",
      "475566579fe049879131b322e4ab23ee",
      "0e88a7b147bd418e9f0b2c83cdd2114e",
      "02765b71fbe24e7ab21bff20d3a28c87",
      "ddc54674cf364951be375012a19dc602",
      "1629e2f711564d00ba4c648088599f4c",
      "20d1def0ec2c4c2e8e358bef3c00fd1b",
      "69279e17b2a94cb99928befd27f6a0bf"
     ]
    },
    "id": "KFwBWkRhc_Nb",
    "outputId": "1b8a7d86-9cf1-41a2-cdac-d2806c5b35aa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a839a3161e947f0b165b97677d4d478"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 2.096025940574592 --validation loss: 2.0981458086593476 -- validation accuracy 0.32107843137254904\n",
      "Epoch 0 Step 50 -- training loss: 0.6075662261520336 --validation loss: 0.5871494488388884 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6230084758925541 --validation loss: 0.6189404784464368 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 150 -- training loss: 0.609856319226211 --validation loss: 0.6232486072124219 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 200 -- training loss: 0.5549501094293491 --validation loss: 0.5656997952975479 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 250 -- training loss: 0.580116110381088 --validation loss: 0.5907023829572341 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 300 -- training loss: 0.5401024531759727 --validation loss: 0.5467386473627651 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 350 -- training loss: 0.5209414809292957 --validation loss: 0.5344443309540842 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 400 -- training loss: 0.5113056034563933 --validation loss: 0.5302390894469093 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 450 -- training loss: 0.5113894536539361 --validation loss: 0.532124369167814 -- validation accuracy 0.7279411764705882\n",
      "Epoch 0 Step 458 -- training loss: 0.5033930375490313 --validation loss: 0.5235933059570836 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 0 -- training loss: 0.5029796573591129 --validation loss: 0.5230703225322798 -- validation accuracy 0.7426470588235294\n",
      "Epoch 1 Step 50 -- training loss: 0.5216055450583595 --validation loss: 0.5517833218270657 -- validation accuracy 0.7132352941176471\n",
      "Epoch 1 Step 100 -- training loss: 0.4912272816227672 --validation loss: 0.5239965941976098 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 150 -- training loss: 0.47549770999707947 --validation loss: 0.5077153952682719 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 200 -- training loss: 0.4605233990516278 --validation loss: 0.503662516673406 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 250 -- training loss: 0.4618981112776758 --validation loss: 0.5072128655863744 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 300 -- training loss: 0.459214123619278 --validation loss: 0.5094768431256799 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 350 -- training loss: 0.4617328157319742 --validation loss: 0.528367918788218 -- validation accuracy 0.7426470588235294\n",
      "Epoch 1 Step 400 -- training loss: 0.46419949013098655 --validation loss: 0.538367891720697 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 450 -- training loss: 0.4338996538928911 --validation loss: 0.5012737611929575 -- validation accuracy 0.7818627450980392\n",
      "Epoch 1 Step 458 -- training loss: 0.426497230326558 --validation loss: 0.4977693481772554 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 0 -- training loss: 0.42592331669689004 --validation loss: 0.4968635229503407 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 50 -- training loss: 0.4403544521539559 --validation loss: 0.5217931723477793 -- validation accuracy 0.7475490196078431\n",
      "Epoch 2 Step 100 -- training loss: 0.43166217060195594 --validation loss: 0.5319225154086655 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 150 -- training loss: 0.42801160938339816 --validation loss: 0.5306671419564415 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 200 -- training loss: 0.3853001446262294 --validation loss: 0.48917429821164 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 250 -- training loss: 0.3764546861738161 --validation loss: 0.500301925575032 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 300 -- training loss: 0.37241766398086784 --validation loss: 0.5161282285755756 -- validation accuracy 0.7671568627450981\n",
      "Epoch 2 Step 350 -- training loss: 0.37236908954732556 --validation loss: 0.5234500499917012 -- validation accuracy 0.7671568627450981\n",
      "Epoch 2 Step 400 -- training loss: 0.34582029953436655 --validation loss: 0.4849180383425133 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 450 -- training loss: 0.3363911985766654 --validation loss: 0.5048390399007237 -- validation accuracy 0.7745098039215687\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.3355970421972358 --validation loss: 0.48012871718874167 -- validation accuracy 0.7794117647058824\n",
      "The best accuracy was 0.7818627450980392 after step 450 of epoch 1.\n",
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 2.096025940574592 --validation loss: 2.0981458086593476 -- validation accuracy 0.32107843137254904\n",
      "Epoch 0 Step 50 -- training loss: 0.6089085876487179 --validation loss: 0.5882904687348534 -- validation accuracy 0.6813725490196079\n",
      "Epoch 0 Step 100 -- training loss: 0.6221720403413368 --validation loss: 0.6171437612935609 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 150 -- training loss: 0.60873581115197 --validation loss: 0.6202989273211535 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 200 -- training loss: 0.5572249415718132 --validation loss: 0.5664025609399758 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 250 -- training loss: 0.5839446057811022 --validation loss: 0.594105182909498 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 300 -- training loss: 0.5464912083219079 --validation loss: 0.5529249757528305 -- validation accuracy 0.7107843137254902\n",
      "Epoch 0 Step 350 -- training loss: 0.5227532787390524 --validation loss: 0.5347235570935642 -- validation accuracy 0.7279411764705882\n",
      "Epoch 0 Step 400 -- training loss: 0.527717934292386 --validation loss: 0.5447992320154228 -- validation accuracy 0.7107843137254902\n",
      "Epoch 0 Step 450 -- training loss: 0.5118875141237297 --validation loss: 0.528598315283364 -- validation accuracy 0.7328431372549019\n",
      "Epoch 0 Step 458 -- training loss: 0.5098874894232531 --validation loss: 0.52711068648918 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 0 -- training loss: 0.5094864665812656 --validation loss: 0.5266962641594457 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 50 -- training loss: 0.5303735958010543 --validation loss: 0.5534930956714293 -- validation accuracy 0.7181372549019608\n",
      "Epoch 1 Step 100 -- training loss: 0.5059632527152957 --validation loss: 0.5284623985781389 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 150 -- training loss: 0.491876111148749 --validation loss: 0.5145887939953336 -- validation accuracy 0.75\n",
      "Epoch 1 Step 200 -- training loss: 0.48432715230647777 --validation loss: 0.5129684087108163 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 250 -- training loss: 0.4950010548295019 --validation loss: 0.5261128664601082 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 300 -- training loss: 0.47708216143978965 --validation loss: 0.5071172018845876 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 350 -- training loss: 0.4729651504547248 --validation loss: 0.51010563268381 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 400 -- training loss: 0.4804616620305577 --validation loss: 0.5216491970361448 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 450 -- training loss: 0.46318577238092756 --validation loss: 0.5057426606323204 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 458 -- training loss: 0.46160250084072935 --validation loss: 0.5048781919713113 -- validation accuracy 0.7598039215686274\n",
      "Epoch 2 Step 0 -- training loss: 0.46125253132485616 --validation loss: 0.504519426355175 -- validation accuracy 0.7622549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.4621785158425375 --validation loss: 0.5065284461951723 -- validation accuracy 0.7671568627450981\n",
      "Epoch 2 Step 100 -- training loss: 0.4562506030652518 --validation loss: 0.503631097428939 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 150 -- training loss: 0.45653358739770317 --validation loss: 0.5060943125509748 -- validation accuracy 0.7598039215686274\n",
      "Epoch 2 Step 200 -- training loss: 0.4540009381562017 --validation loss: 0.5056431462951735 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 250 -- training loss: 0.4473800332263145 --validation loss: 0.4997446534096026 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 300 -- training loss: 0.44337508445991153 --validation loss: 0.4968331733755037 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 350 -- training loss: 0.45036947339253747 --validation loss: 0.5091655371235866 -- validation accuracy 0.7549019607843137\n",
      "Epoch 2 Step 400 -- training loss: 0.4416515183572156 --validation loss: 0.49852632979551953 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 450 -- training loss: 0.4419602576748738 --validation loss: 0.49953756671325833 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 458 -- training loss: 0.44196913972464524 --validation loss: 0.49947315220739325 -- validation accuracy 0.7769607843137255\n",
      "The best accuracy was 0.7794117647058824 after step 300 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 1.7515341689838564 --validation loss: 1.7445332735192542 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.608549735255231 --validation loss: 0.616916735382641 -- validation accuracy 0.6764705882352942\n",
      "Epoch 0 Step 100 -- training loss: 0.6389864011138093 --validation loss: 0.6549954393915102 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 150 -- training loss: 0.6004718259658689 --validation loss: 0.6073870048219082 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 200 -- training loss: 0.57142725379119 --validation loss: 0.5803293030635983 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 250 -- training loss: 0.5688868812681024 --validation loss: 0.5785399391955021 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 300 -- training loss: 0.5460404257304269 --validation loss: 0.5543616963367836 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 350 -- training loss: 0.580060755310495 --validation loss: 0.5974108378092448 -- validation accuracy 0.6813725490196079\n",
      "Epoch 0 Step 400 -- training loss: 0.5178678162347258 --validation loss: 0.5467466577595356 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 450 -- training loss: 0.5178910678897808 --validation loss: 0.5438999054478664 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 458 -- training loss: 0.5155651007732275 --validation loss: 0.5402729826814988 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 0 -- training loss: 0.5171047617926836 --validation loss: 0.541950862197315 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 50 -- training loss: 0.5266062806569413 --validation loss: 0.5627582829956915 -- validation accuracy 0.7205882352941176\n",
      "Epoch 1 Step 100 -- training loss: 0.4822777464888454 --validation loss: 0.5210445307049096 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 150 -- training loss: 0.45835706559141737 --validation loss: 0.5094186669471217 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 200 -- training loss: 0.45331458951912673 --validation loss: 0.5241104899083867 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 250 -- training loss: 0.434781807553924 --validation loss: 0.5057955185572306 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 300 -- training loss: 0.41709622755354525 --validation loss: 0.4939823022075728 -- validation accuracy 0.7696078431372549\n",
      "Epoch 1 Step 350 -- training loss: 0.42523640963961096 --validation loss: 0.5182754195788327 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 400 -- training loss: 0.4455644556509903 --validation loss: 0.5626794967581245 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 450 -- training loss: 0.3871039500163791 --validation loss: 0.49499593762790456 -- validation accuracy 0.7769607843137255\n",
      "Epoch 1 Step 458 -- training loss: 0.371946095689839 --validation loss: 0.4756053239107132 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 0 -- training loss: 0.37265099453575473 --validation loss: 0.47158077534507303 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 50 -- training loss: 0.41423676796014014 --validation loss: 0.5555737700824644 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.37991639365866164 --validation loss: 0.568278432622844 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 150 -- training loss: 0.3408172068577706 --validation loss: 0.4809456168144357 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 200 -- training loss: 0.31616572500865964 --validation loss: 0.4804410306262035 -- validation accuracy 0.7720588235294118\n",
      "Epoch 2 Step 250 -- training loss: 0.3124937968803387 --validation loss: 0.4864649844228053 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 300 -- training loss: 0.30854670800195605 --validation loss: 0.5274836510127666 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 350 -- training loss: 0.36524027061277353 --validation loss: 0.6243279465273315 -- validation accuracy 0.7573529411764706\n",
      "Epoch 2 Step 400 -- training loss: 0.24074817399346232 --validation loss: 0.4532570457633804 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 450 -- training loss: 0.25025142308868353 --validation loss: 0.4770348513243245 -- validation accuracy 0.7843137254901961\n",
      "Epoch 2 Step 458 -- training loss: 0.2534568282351515 --validation loss: 0.4542592319787717 -- validation accuracy 0.7965686274509803\n",
      "The best accuracy was 0.8014705882352942 after step 400 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 1.7515341689838564 --validation loss: 1.7445332735192542 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.6213669430196674 --validation loss: 0.6136673501893586 -- validation accuracy 0.6740196078431373\n",
      "Epoch 0 Step 100 -- training loss: 0.6243433563732633 --validation loss: 0.625625716120589 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 150 -- training loss: 0.6006905606304638 --validation loss: 0.6103566896681692 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 200 -- training loss: 0.5689069581317486 --validation loss: 0.5832686903429967 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 250 -- training loss: 0.5832340672839441 --validation loss: 0.5985899842252919 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 300 -- training loss: 0.5512469333955665 --validation loss: 0.5675468205236921 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 350 -- training loss: 0.5463026744802533 --validation loss: 0.5667770306269327 -- validation accuracy 0.7328431372549019\n",
      "Epoch 0 Step 400 -- training loss: 0.5247113360234076 --validation loss: 0.551106627665314 -- validation accuracy 0.7279411764705882\n",
      "Epoch 0 Step 450 -- training loss: 0.5211783681624855 --validation loss: 0.5497036915199429 -- validation accuracy 0.7181372549019608\n",
      "Epoch 0 Step 458 -- training loss: 0.5151991948712625 --validation loss: 0.5436231540698632 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 0 -- training loss: 0.514695489718244 --validation loss: 0.5431459960984248 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 50 -- training loss: 0.5354387707732342 --validation loss: 0.5715994180417528 -- validation accuracy 0.7083333333333334\n",
      "Epoch 1 Step 100 -- training loss: 0.49777675642427016 --validation loss: 0.5361881545361351 -- validation accuracy 0.75\n",
      "Epoch 1 Step 150 -- training loss: 0.47968867758780004 --validation loss: 0.5243351401067248 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 200 -- training loss: 0.4690478722319364 --validation loss: 0.522201891038932 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 250 -- training loss: 0.4665235876712404 --validation loss: 0.5274910374599344 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 300 -- training loss: 0.45156066369646775 --validation loss: 0.5124315435395521 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 350 -- training loss: 0.46684955323443694 --validation loss: 0.5480959319016513 -- validation accuracy 0.7328431372549019\n",
      "Epoch 1 Step 400 -- training loss: 0.4657152764142079 --validation loss: 0.5560059646765391 -- validation accuracy 0.7303921568627451\n",
      "Epoch 1 Step 450 -- training loss: 0.4285249728587718 --validation loss: 0.5121965157050713 -- validation accuracy 0.7696078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.42651737010621815 --validation loss: 0.5119878392593533 -- validation accuracy 0.7622549019607843\n",
      "Epoch 2 Step 0 -- training loss: 0.4255640264235291 --validation loss: 0.5103539847860149 -- validation accuracy 0.7622549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.42837687899117116 --validation loss: 0.5191511342338487 -- validation accuracy 0.7622549019607843\n",
      "Epoch 2 Step 100 -- training loss: 0.4130458561196306 --validation loss: 0.5011062435075349 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 150 -- training loss: 0.41737116966599475 --validation loss: 0.5151688731184193 -- validation accuracy 0.7573529411764706\n",
      "Epoch 2 Step 200 -- training loss: 0.4044862423652138 --validation loss: 0.5110327864394468 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.38713251424381157 --validation loss: 0.4941571588609733 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 300 -- training loss: 0.3827290518740943 --validation loss: 0.48653613527615863 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 350 -- training loss: 0.39307924054871457 --validation loss: 0.5136566054002911 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.3760520839385997 --validation loss: 0.48412617807294805 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 450 -- training loss: 0.37558937815377136 --validation loss: 0.49068031883707236 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 458 -- training loss: 0.375665942543797 --validation loss: 0.4905850875611399 -- validation accuracy 0.7769607843137255\n",
      "The best accuracy was 0.7794117647058824 after step 300 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 1.4354786700477786 --validation loss: 1.4263130099165673 -- validation accuracy 0.33088235294117646\n",
      "Epoch 0 Step 50 -- training loss: 0.6022826246186799 --validation loss: 0.6074196252168393 -- validation accuracy 0.6862745098039216\n",
      "Epoch 0 Step 100 -- training loss: 0.5875854487967127 --validation loss: 0.5901244615807253 -- validation accuracy 0.678921568627451\n",
      "Epoch 0 Step 150 -- training loss: 0.5495845113184976 --validation loss: 0.5695550219685424 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 200 -- training loss: 0.5851028784622554 --validation loss: 0.6023961378663194 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 250 -- training loss: 0.505504358405641 --validation loss: 0.5261382489812141 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 300 -- training loss: 0.4790444188388085 --validation loss: 0.510176428100642 -- validation accuracy 0.7475490196078431\n",
      "Epoch 0 Step 350 -- training loss: 0.4833844631975253 --validation loss: 0.5229101625143313 -- validation accuracy 0.7622549019607843\n",
      "Epoch 0 Step 400 -- training loss: 0.4655087488117041 --validation loss: 0.5415470778357749 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 450 -- training loss: 0.4377702906046038 --validation loss: 0.4934266002154818 -- validation accuracy 0.7745098039215687\n",
      "Epoch 0 Step 458 -- training loss: 0.4279190324782546 --validation loss: 0.493207560450423 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 0 -- training loss: 0.42539035433128247 --validation loss: 0.4917111715265349 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 50 -- training loss: 0.6290604768884988 --validation loss: 0.7451255341224811 -- validation accuracy 0.7156862745098039\n",
      "Epoch 1 Step 100 -- training loss: 0.3623463313028314 --validation loss: 0.4921504381824942 -- validation accuracy 0.7941176470588235\n",
      "Epoch 1 Step 150 -- training loss: 0.40152704227951097 --validation loss: 0.5644507600980646 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 200 -- training loss: 0.35209545337296777 --validation loss: 0.523441292199434 -- validation accuracy 0.75\n",
      "Epoch 1 Step 250 -- training loss: 0.29997434978391607 --validation loss: 0.46147217528492795 -- validation accuracy 0.7867647058823529\n",
      "Epoch 1 Step 300 -- training loss: 0.2995547010829116 --validation loss: 0.4862227740825391 -- validation accuracy 0.7818627450980392\n",
      "Epoch 1 Step 350 -- training loss: 0.36614454032402804 --validation loss: 0.6258605569601059 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 400 -- training loss: 0.3215742498222325 --validation loss: 0.6012887680793509 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.23921448290185732 --validation loss: 0.48371514005988253 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 458 -- training loss: 0.23380276648437276 --validation loss: 0.4390171973728666 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 0 -- training loss: 0.23430118217966914 --validation loss: 0.4388297258638868 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 50 -- training loss: 0.2973628388502187 --validation loss: 0.7391798130839187 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 100 -- training loss: 0.18835970799414306 --validation loss: 0.567780144804833 -- validation accuracy 0.7941176470588235\n",
      "Epoch 2 Step 150 -- training loss: 0.15271499482123485 --validation loss: 0.46111028919032976 -- validation accuracy 0.8112745098039216\n",
      "Epoch 2 Step 200 -- training loss: 0.22335943995243496 --validation loss: 0.6918761485128426 -- validation accuracy 0.7720588235294118\n",
      "Epoch 2 Step 250 -- training loss: 0.16087939374733204 --validation loss: 0.45826149812223865 -- validation accuracy 0.7941176470588235\n",
      "Epoch 2 Step 300 -- training loss: 0.15670569362940595 --validation loss: 0.6185153785946906 -- validation accuracy 0.7843137254901961\n",
      "Epoch 2 Step 350 -- training loss: 0.2287929200527739 --validation loss: 0.7741953812028263 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 400 -- training loss: 0.13538125742324233 --validation loss: 0.5935114644029561 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 450 -- training loss: 0.086154475597125 --validation loss: 0.4718683432130253 -- validation accuracy 0.7941176470588235\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.0833679464745106 --validation loss: 0.5015465018211627 -- validation accuracy 0.8063725490196079\n",
      "The best accuracy was 0.8112745098039216 after step 150 of epoch 2.\n",
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 1.4354786700477786 --validation loss: 1.4263130099165673 -- validation accuracy 0.33088235294117646\n",
      "Epoch 0 Step 50 -- training loss: 0.6030037818651054 --validation loss: 0.6080950393396265 -- validation accuracy 0.678921568627451\n",
      "Epoch 0 Step 100 -- training loss: 0.5872716867975679 --validation loss: 0.5900714987633275 -- validation accuracy 0.6813725490196079\n",
      "Epoch 0 Step 150 -- training loss: 0.553512653429264 --validation loss: 0.5731417478299609 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 200 -- training loss: 0.5832387178422059 --validation loss: 0.6001031577002769 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 250 -- training loss: 0.5129258544681379 --validation loss: 0.5330427394193762 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 300 -- training loss: 0.501240334528334 --validation loss: 0.525399397985608 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 350 -- training loss: 0.5047306015860281 --validation loss: 0.542747460159601 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 400 -- training loss: 0.4550694413564304 --validation loss: 0.5174834418530557 -- validation accuracy 0.7671568627450981\n",
      "Epoch 0 Step 450 -- training loss: 0.4546985746338996 --validation loss: 0.5061191466509127 -- validation accuracy 0.7720588235294118\n",
      "Epoch 0 Step 458 -- training loss: 0.44094848986674495 --validation loss: 0.49756983448477354 -- validation accuracy 0.7794117647058824\n",
      "Epoch 1 Step 0 -- training loss: 0.4399564285683476 --validation loss: 0.4982061570181566 -- validation accuracy 0.7794117647058824\n",
      "Epoch 1 Step 50 -- training loss: 0.5155577821523146 --validation loss: 0.6247332521221217 -- validation accuracy 0.7254901960784313\n",
      "Epoch 1 Step 100 -- training loss: 0.3884057118222604 --validation loss: 0.49696624717291665 -- validation accuracy 0.7794117647058824\n",
      "Epoch 1 Step 150 -- training loss: 0.37492491836479025 --validation loss: 0.509373843962071 -- validation accuracy 0.7769607843137255\n",
      "Epoch 1 Step 200 -- training loss: 0.3740664910614361 --validation loss: 0.5189671837816051 -- validation accuracy 0.75\n",
      "Epoch 1 Step 250 -- training loss: 0.3236467992980236 --validation loss: 0.4878014831566343 -- validation accuracy 0.7843137254901961\n",
      "Epoch 1 Step 300 -- training loss: 0.28413534467970886 --validation loss: 0.45845777190783443 -- validation accuracy 0.7867647058823529\n",
      "Epoch 1 Step 350 -- training loss: 0.3004806358894751 --validation loss: 0.5116937031932905 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 400 -- training loss: 0.32875924869917317 --validation loss: 0.578085236397444 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.25514688435333227 --validation loss: 0.46255790135439706 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 458 -- training loss: 0.2694117172594813 --validation loss: 0.5074064864539632 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 0 -- training loss: 0.26420703426425496 --validation loss: 0.49857129857820626 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 50 -- training loss: 0.24770073713389812 --validation loss: 0.5459826499515888 -- validation accuracy 0.7990196078431373\n",
      "Epoch 2 Step 100 -- training loss: 0.2406120414658975 --validation loss: 0.6098683608659342 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 150 -- training loss: 0.21266570517464595 --validation loss: 0.57010687982627 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 200 -- training loss: 0.18593667770993605 --validation loss: 0.5338061966878527 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 250 -- training loss: 0.16203834629396469 --validation loss: 0.5215716136290747 -- validation accuracy 0.8161764705882353\n",
      "Epoch 2 Step 300 -- training loss: 0.152960023965508 --validation loss: 0.5222454567750295 -- validation accuracy 0.8088235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.16365301983140831 --validation loss: 0.5892980623917252 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 400 -- training loss: 0.13129072640018136 --validation loss: 0.4954199643403876 -- validation accuracy 0.821078431372549\n",
      "Epoch 2 Step 450 -- training loss: 0.13356605223288723 --validation loss: 0.5201379838308283 -- validation accuracy 0.8161764705882353\n",
      "Epoch 2 Step 458 -- training loss: 0.13338468067321627 --validation loss: 0.5195557442219818 -- validation accuracy 0.8161764705882353\n",
      "The best accuracy was 0.821078431372549 after step 400 of epoch 2.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiment 1, we observe overfitting after epoch 1. The best result in experiment 1 is at step 458 of epoch 1, where the validation accuracy is 77.7% and validation loss is 0.498.\n",
    "\n",
    "On the other hand, we do not see overfitting in exper 2, and the best result is at step 300 of epoch 2. The validation accuracy and validation loss are 77.9% and 0.497 at this step.\n",
    "\n",
    "In experiment 3, we see some oscillations in validation loss in epoch 2, but overall validation loss goes down. The best result is at step 400 of epoch 2, where the validation accuracy and validation loss are 80.1% and 0.453, respectively.\n",
    "\n",
    "In experiment 4, we do not see any signs of overfitting. The best result is at step 400 of epoch 2, where the validation accuracy is 77.9% and validation loss is 0.484.\n",
    "\n",
    "We observe overfitting in epoch 2 in experiment 5. The best result is at step 458 of epoch 1. The validation accuracy and validation loss at this step are 78.7% and 0.439, respectively.\n",
    "\n",
    "In experiment 6, we observe overfitting after step 300 of epoch 1. The validation accuracy at this step is 78.7% whereas the validation loss is 0.458.\n",
    "\n",
    "Therefore, we conclude that the best results are achieved with experiment 5."
   ],
   "metadata": {
    "id": "WSXZLNv7Sgsc"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 23"
   ],
   "metadata": {
    "id": "5C3JtLW3d7CQ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(23)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    # Set padding token to EOS token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "50faaca8e44f42f89afe65e1ff5ccec8",
      "9870228c9d9b4a34ad7b4409689a3eff",
      "4441ea39a38c4ec482633603b7ae9d52",
      "6af1fd2877924a53827f5cdcfc2d49b8",
      "f24cb54912ae41c880fddf1f73faadfc",
      "08d2622b534c4528a402547c9f6e2630",
      "6fd359b2d8e94f93922dd146885e40c6",
      "3cebffcc2dcd48ffa40138d8af9a9b5b",
      "8f392b741f474a1882d9f543d7804cc9",
      "69dcf5d4ab864e5ea6a90025efaa7ef7",
      "2905335829f04b9691e8dd5e001202ec"
     ]
    },
    "id": "KQuylAV8-cEa",
    "outputId": "5ca89b80-0a05-4d75-9126-04b2ef5f4f72"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50faaca8e44f42f89afe65e1ff5ccec8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.8227063777627249 --validation loss: 0.7973103222309375 -- validation accuracy 0.6666666666666666\n",
      "Epoch 0 Step 50 -- training loss: 0.6336311964817296 --validation loss: 0.6284563255076315 -- validation accuracy 0.6544117647058824\n",
      "Epoch 0 Step 100 -- training loss: 0.5854898885314501 --validation loss: 0.5845217669711393 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 150 -- training loss: 0.6027838501730256 --validation loss: 0.5974431528764612 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 200 -- training loss: 0.5556332859857929 --validation loss: 0.5560396164655685 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 250 -- training loss: 0.554062404728663 --validation loss: 0.5548606333779353 -- validation accuracy 0.7254901960784313\n",
      "Epoch 0 Step 300 -- training loss: 0.52816824624741 --validation loss: 0.5331571143047482 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 350 -- training loss: 0.5152218327867699 --validation loss: 0.5266581136806339 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 400 -- training loss: 0.5162422859266174 --validation loss: 0.5278508026225894 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 450 -- training loss: 0.5460571384702633 --validation loss: 0.5630223946828469 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 458 -- training loss: 0.5050774196848631 --validation loss: 0.5188075967279135 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 0 -- training loss: 0.504558651746618 --validation loss: 0.5175848763947394 -- validation accuracy 0.75\n",
      "Epoch 1 Step 50 -- training loss: 0.49686510435636266 --validation loss: 0.4999556278481203 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 100 -- training loss: 0.47200811246901037 --validation loss: 0.48639307594766806 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 150 -- training loss: 0.4663153848487048 --validation loss: 0.48807013677615746 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 200 -- training loss: 0.4963432421221972 --validation loss: 0.5365863530074849 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 250 -- training loss: 0.48572459263414597 --validation loss: 0.528259745561609 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 300 -- training loss: 0.4517246550821531 --validation loss: 0.48723792065592375 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 350 -- training loss: 0.4482333346844239 --validation loss: 0.4798613874351277 -- validation accuracy 0.7818627450980392\n",
      "Epoch 1 Step 400 -- training loss: 0.41985607494585914 --validation loss: 0.46185381681311366 -- validation accuracy 0.7941176470588235\n",
      "Epoch 1 Step 450 -- training loss: 0.43222759290718044 --validation loss: 0.5068007158298119 -- validation accuracy 0.7696078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.41310001273430513 --validation loss: 0.4812466963833454 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 0 -- training loss: 0.4101236175607752 --validation loss: 0.4748167097568512 -- validation accuracy 0.7720588235294118\n",
      "Epoch 2 Step 50 -- training loss: 0.3836513629795939 --validation loss: 0.45156146293761684 -- validation accuracy 0.7916666666666666\n",
      "Epoch 2 Step 100 -- training loss: 0.39850757701204753 --validation loss: 0.47784538859245823 -- validation accuracy 0.7843137254901961\n",
      "Epoch 2 Step 150 -- training loss: 0.4010683991225976 --validation loss: 0.4708154812162998 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 200 -- training loss: 0.3737532847392533 --validation loss: 0.4504278705400579 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 250 -- training loss: 0.37573149996710237 --validation loss: 0.468661579431272 -- validation accuracy 0.7843137254901961\n",
      "Epoch 2 Step 300 -- training loss: 0.36516801717494307 --validation loss: 0.4818098019151127 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 350 -- training loss: 0.3410659749750738 --validation loss: 0.4374338718605976 -- validation accuracy 0.7941176470588235\n",
      "Epoch 2 Step 400 -- training loss: 0.3282953577566575 --validation loss: 0.45645654259943497 -- validation accuracy 0.7941176470588235\n",
      "Epoch 2 Step 450 -- training loss: 0.31350883229560583 --validation loss: 0.44164106688078714 -- validation accuracy 0.7867647058823529\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.31397514985082975 --validation loss: 0.4372760375925139 -- validation accuracy 0.7941176470588235\n",
      "The best accuracy was 0.7941176470588235 after step 400 of epoch 1.\n",
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.8227063777627249 --validation loss: 0.7973103222309375 -- validation accuracy 0.6666666666666666\n",
      "Epoch 0 Step 50 -- training loss: 0.6342576138334337 --validation loss: 0.6293012067383411 -- validation accuracy 0.6544117647058824\n",
      "Epoch 0 Step 100 -- training loss: 0.5869744108393301 --validation loss: 0.585925924427369 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 150 -- training loss: 0.5999328817092775 --validation loss: 0.5944452411403843 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 200 -- training loss: 0.5569603964524071 --validation loss: 0.5564296768576491 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 250 -- training loss: 0.5567826228074259 --validation loss: 0.5567816075156716 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 300 -- training loss: 0.5313059589247299 --validation loss: 0.5369326022325778 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 350 -- training loss: 0.5205980801634279 --validation loss: 0.5297630312396031 -- validation accuracy 0.7352941176470589\n",
      "Epoch 0 Step 400 -- training loss: 0.5218677900910118 --validation loss: 0.5325408940221749 -- validation accuracy 0.7279411764705882\n",
      "Epoch 0 Step 450 -- training loss: 0.5506444977584228 --validation loss: 0.5638863756960514 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 458 -- training loss: 0.5217141749779644 --validation loss: 0.5344229396067414 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 0 -- training loss: 0.5201143148580408 --validation loss: 0.5322878682145885 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 50 -- training loss: 0.49692859026666303 --validation loss: 0.5021261783207164 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 100 -- training loss: 0.4842005523656189 --validation loss: 0.4951519887236988 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 150 -- training loss: 0.47900421888220546 --validation loss: 0.4955465454681247 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 200 -- training loss: 0.489056017679976 --validation loss: 0.516588873722974 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.47920615949986545 --validation loss: 0.5086473060004851 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 300 -- training loss: 0.46285175520740046 --validation loss: 0.48707762068393184 -- validation accuracy 0.7696078431372549\n",
      "Epoch 1 Step 350 -- training loss: 0.458619615123942 --validation loss: 0.4853629805878097 -- validation accuracy 0.7696078431372549\n",
      "Epoch 1 Step 400 -- training loss: 0.449286899567949 --validation loss: 0.4807864658388437 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.44688533868210506 --validation loss: 0.4870007569883384 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 458 -- training loss: 0.4504818728351905 --validation loss: 0.49161500089308796 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 0 -- training loss: 0.4504080959524724 --validation loss: 0.49057405339736565 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 50 -- training loss: 0.44871703269110264 --validation loss: 0.49192650061027676 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 100 -- training loss: 0.43798014594643725 --validation loss: 0.48184238929374545 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 150 -- training loss: 0.43248455304335925 --validation loss: 0.4722153728499132 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 200 -- training loss: 0.43916947188460487 --validation loss: 0.4855102306487514 -- validation accuracy 0.7720588235294118\n",
      "Epoch 2 Step 250 -- training loss: 0.4262987119764544 --validation loss: 0.46796782665392933 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 300 -- training loss: 0.4216200985777352 --validation loss: 0.4677508341915467 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 350 -- training loss: 0.4195712604164298 --validation loss: 0.4676167947404525 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.41839375199185996 --validation loss: 0.46644508078986524 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 450 -- training loss: 0.4183108941662026 --validation loss: 0.46787692314269497 -- validation accuracy 0.7769607843137255\n",
      "Epoch 2 Step 458 -- training loss: 0.41785680801325636 --validation loss: 0.4678891847531001 -- validation accuracy 0.7769607843137255\n",
      "The best accuracy was 0.7794117647058824 after step 50 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.8408855500921185 --validation loss: 0.8118688424720484 -- validation accuracy 0.678921568627451\n",
      "Epoch 0 Step 50 -- training loss: 0.5870723023134119 --validation loss: 0.5790512041718352 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 100 -- training loss: 0.553913808823411 --validation loss: 0.5553118563165852 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 150 -- training loss: 0.5964009175340854 --validation loss: 0.5916385919440026 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 200 -- training loss: 0.5223947916674978 --validation loss: 0.5306053395364799 -- validation accuracy 0.7083333333333334\n",
      "Epoch 0 Step 250 -- training loss: 0.5369174312272622 --validation loss: 0.5524335906786078 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 300 -- training loss: 0.5132735655977835 --validation loss: 0.5310401302926681 -- validation accuracy 0.7475490196078431\n",
      "Epoch 0 Step 350 -- training loss: 0.49914904260167886 --validation loss: 0.5400601283592337 -- validation accuracy 0.7254901960784313\n",
      "Epoch 0 Step 400 -- training loss: 0.4730440098995217 --validation loss: 0.5114928787829829 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 450 -- training loss: 0.4598468710589253 --validation loss: 0.5104889951500238 -- validation accuracy 0.7671568627450981\n",
      "Epoch 0 Step 458 -- training loss: 0.46766442006904313 --validation loss: 0.5216050983643999 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 0 -- training loss: 0.48207574855528107 --validation loss: 0.537484432552375 -- validation accuracy 0.75\n",
      "Epoch 1 Step 50 -- training loss: 0.4377314249512157 --validation loss: 0.49906589353785796 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 100 -- training loss: 0.3978790792115114 --validation loss: 0.4635627126576854 -- validation accuracy 0.7843137254901961\n",
      "Epoch 1 Step 150 -- training loss: 0.4189127063082454 --validation loss: 0.5230690091848373 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 200 -- training loss: 0.4670386583035029 --validation loss: 0.5759169073665843 -- validation accuracy 0.7303921568627451\n",
      "Epoch 1 Step 250 -- training loss: 0.3883280739318052 --validation loss: 0.4932863916836533 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 300 -- training loss: 0.3454395971851411 --validation loss: 0.468426649184788 -- validation accuracy 0.7916666666666666\n",
      "Epoch 1 Step 350 -- training loss: 0.36393989320673975 --validation loss: 0.4704151799281438 -- validation accuracy 0.7696078431372549\n",
      "Epoch 1 Step 400 -- training loss: 0.3054693855166695 --validation loss: 0.4479493846495946 -- validation accuracy 0.7867647058823529\n",
      "Epoch 1 Step 450 -- training loss: 0.39097728261679476 --validation loss: 0.6000174190483841 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 458 -- training loss: 0.3036878111088458 --validation loss: 0.43747394020650904 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 0 -- training loss: 0.31472184041551515 --validation loss: 0.44434001019188 -- validation accuracy 0.7941176470588235\n",
      "Epoch 2 Step 50 -- training loss: 0.2522567385515454 --validation loss: 0.4672655475636323 -- validation accuracy 0.8186274509803921\n",
      "Epoch 2 Step 100 -- training loss: 0.24656851409096472 --validation loss: 0.49431362236831705 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 150 -- training loss: 0.2694610269590076 --validation loss: 0.4994672119033103 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 200 -- training loss: 0.22411156901866522 --validation loss: 0.45504502280085696 -- validation accuracy 0.7965686274509803\n",
      "Epoch 2 Step 250 -- training loss: 0.26300559277709146 --validation loss: 0.506353585451257 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 300 -- training loss: 0.19597522864495617 --validation loss: 0.5172479509138593 -- validation accuracy 0.7843137254901961\n",
      "Epoch 2 Step 350 -- training loss: 0.188136853577979 --validation loss: 0.4364469399054845 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 400 -- training loss: 0.15589647177375512 --validation loss: 0.5334122655730621 -- validation accuracy 0.8088235294117647\n",
      "Epoch 2 Step 450 -- training loss: 0.141142573463274 --validation loss: 0.4640083961627063 -- validation accuracy 0.8161764705882353\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.16688949753548585 --validation loss: 0.5072091576807639 -- validation accuracy 0.7990196078431373\n",
      "The best accuracy was 0.8186274509803921 after step 50 of epoch 2.\n",
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.8408855500921185 --validation loss: 0.8118688424720484 -- validation accuracy 0.678921568627451\n",
      "Epoch 0 Step 50 -- training loss: 0.5880549231905303 --validation loss: 0.5801327339574402 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 100 -- training loss: 0.5547912223081962 --validation loss: 0.5556769674899531 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 150 -- training loss: 0.5942247025912104 --validation loss: 0.5884826989734874 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 200 -- training loss: 0.5202980521977077 --validation loss: 0.5292255299932817 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 250 -- training loss: 0.5379114378901089 --validation loss: 0.5510509031660417 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 300 -- training loss: 0.5097619052935789 --validation loss: 0.52778320628054 -- validation accuracy 0.7426470588235294\n",
      "Epoch 0 Step 350 -- training loss: 0.49496313903586275 --validation loss: 0.5336882320104861 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 400 -- training loss: 0.4737847705162688 --validation loss: 0.5066112034461078 -- validation accuracy 0.7279411764705882\n",
      "Epoch 0 Step 450 -- training loss: 0.4797831385483669 --validation loss: 0.5293726465281319 -- validation accuracy 0.7426470588235294\n",
      "Epoch 0 Step 458 -- training loss: 0.45822654622312725 --validation loss: 0.5079008235650904 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 0 -- training loss: 0.4610492618904654 --validation loss: 0.5120211468607772 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 50 -- training loss: 0.4367855805132644 --validation loss: 0.4826618830362956 -- validation accuracy 0.7745098039215687\n",
      "Epoch 1 Step 100 -- training loss: 0.4082633462087261 --validation loss: 0.4731006604783675 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 150 -- training loss: 0.3949708403666425 --validation loss: 0.49326524459848214 -- validation accuracy 0.7745098039215687\n",
      "Epoch 1 Step 200 -- training loss: 0.40777675635414706 --validation loss: 0.505643844020133 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 250 -- training loss: 0.3727825246670147 --validation loss: 0.4706566988253126 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 300 -- training loss: 0.35929251379436916 --validation loss: 0.4786241200624728 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 350 -- training loss: 0.3736706257905316 --validation loss: 0.4507945816890866 -- validation accuracy 0.7843137254901961\n",
      "Epoch 1 Step 400 -- training loss: 0.3347946098622154 --validation loss: 0.43313366554531396 -- validation accuracy 0.7916666666666666\n",
      "Epoch 1 Step 450 -- training loss: 0.32091415565550196 --validation loss: 0.4632415860599163 -- validation accuracy 0.7843137254901961\n",
      "Epoch 1 Step 458 -- training loss: 0.30725444668258717 --validation loss: 0.4441864874725248 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 0 -- training loss: 0.306316396501524 --validation loss: 0.44095000244823157 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 50 -- training loss: 0.29325126099333265 --validation loss: 0.4295371049175076 -- validation accuracy 0.8161764705882353\n",
      "Epoch 2 Step 100 -- training loss: 0.28384102073402706 --validation loss: 0.4390299657688421 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 150 -- training loss: 0.284866729487456 --validation loss: 0.44909468117882223 -- validation accuracy 0.8161764705882353\n",
      "Epoch 2 Step 200 -- training loss: 0.28153462389033607 --validation loss: 0.4854881553088917 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 250 -- training loss: 0.2576056336639104 --validation loss: 0.44229496431116966 -- validation accuracy 0.8063725490196079\n",
      "Epoch 2 Step 300 -- training loss: 0.2405738454222809 --validation loss: 0.43541814766678155 -- validation accuracy 0.8137254901960784\n",
      "Epoch 2 Step 350 -- training loss: 0.2428305770954308 --validation loss: 0.45941084944734384 -- validation accuracy 0.7990196078431373\n",
      "Epoch 2 Step 400 -- training loss: 0.2336374867731839 --validation loss: 0.4467204540383582 -- validation accuracy 0.8186274509803921\n",
      "Epoch 2 Step 450 -- training loss: 0.24191985304075778 --validation loss: 0.4680482857659751 -- validation accuracy 0.7941176470588235\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.24137903742232483 --validation loss: 0.46728120189087063 -- validation accuracy 0.7941176470588235\n",
      "The best accuracy was 0.8186274509803921 after step 400 of epoch 2.\n",
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.8624716038797416 --validation loss: 0.8309214468680176 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5807699891606707 --validation loss: 0.5738563005830727 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 100 -- training loss: 0.5423233825591655 --validation loss: 0.5493259324746973 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 150 -- training loss: 0.6005775729977487 --validation loss: 0.6038244904256335 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 200 -- training loss: 0.5022916168883476 --validation loss: 0.5206058416880813 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 250 -- training loss: 0.5087184330087342 --validation loss: 0.5390056418437584 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 300 -- training loss: 0.5274269219836898 --validation loss: 0.5483598083842034 -- validation accuracy 0.7549019607843137\n",
      "Epoch 0 Step 350 -- training loss: 0.482880339821829 --validation loss: 0.5342401543668672 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 400 -- training loss: 0.4762674550767298 --validation loss: 0.5322411562882218 -- validation accuracy 0.7328431372549019\n",
      "Epoch 0 Step 450 -- training loss: 0.44411894656344436 --validation loss: 0.5075960880985447 -- validation accuracy 0.7622549019607843\n",
      "Epoch 0 Step 458 -- training loss: 0.5164294988403912 --validation loss: 0.6007342559157633 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 0 -- training loss: 0.4936639853227632 --validation loss: 0.5798813285780888 -- validation accuracy 0.75\n",
      "Epoch 1 Step 50 -- training loss: 0.3811479666816123 --validation loss: 0.4519304770464991 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 100 -- training loss: 0.36822186243235416 --validation loss: 0.4521470078650643 -- validation accuracy 0.7916666666666666\n",
      "Epoch 1 Step 150 -- training loss: 0.39541039838250686 --validation loss: 0.5312714036188874 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 200 -- training loss: 0.3636934962570018 --validation loss: 0.5112258388715631 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 250 -- training loss: 0.3909662075194658 --validation loss: 0.5142409073955873 -- validation accuracy 0.75\n",
      "Epoch 1 Step 300 -- training loss: 0.2836483112964495 --validation loss: 0.4124221033325382 -- validation accuracy 0.7990196078431373\n",
      "Epoch 1 Step 350 -- training loss: 0.30692467739509344 --validation loss: 0.4350806056868796 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 400 -- training loss: 0.2650142262744553 --validation loss: 0.4707009592184834 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 450 -- training loss: 0.2602440047266534 --validation loss: 0.49784987134968534 -- validation accuracy 0.7965686274509803\n",
      "Epoch 1 Step 458 -- training loss: 0.2269309847362031 --validation loss: 0.40812241125340554 -- validation accuracy 0.8112745098039216\n",
      "Epoch 2 Step 0 -- training loss: 0.2308502374845912 --validation loss: 0.41034606186782613 -- validation accuracy 0.8112745098039216\n",
      "Epoch 2 Step 50 -- training loss: 0.3881311422124635 --validation loss: 0.6340291878464175 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.2263784999096835 --validation loss: 0.498633986010271 -- validation accuracy 0.7990196078431373\n",
      "Epoch 2 Step 150 -- training loss: 0.26039808373421447 --validation loss: 0.6534286876227341 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 200 -- training loss: 0.17142024405974254 --validation loss: 0.4663088527672431 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 250 -- training loss: 0.13690771053906345 --validation loss: 0.4886832815759322 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 300 -- training loss: 0.16997250370287656 --validation loss: 0.5774749093049881 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 350 -- training loss: 0.12051907164898898 --validation loss: 0.4342534845950557 -- validation accuracy 0.821078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.09879136262644156 --validation loss: 0.449904173320415 -- validation accuracy 0.8357843137254902\n",
      "Epoch 2 Step 450 -- training loss: 0.09357766768527837 --validation loss: 0.4319850115799436 -- validation accuracy 0.8308823529411765\n",
      "Epoch 2 Step 458 -- training loss: 0.1120167525326894 --validation loss: 0.45806849090492024 -- validation accuracy 0.8161764705882353\n",
      "The best accuracy was 0.8357843137254902 after step 400 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.8624716038797416 --validation loss: 0.8309214468680176 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5809491329333362 --validation loss: 0.5737693695461049 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 100 -- training loss: 0.5432575709939262 --validation loss: 0.5501038379528943 -- validation accuracy 0.7083333333333334\n",
      "Epoch 0 Step 150 -- training loss: 0.5962569055863715 --validation loss: 0.6011319741898892 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 200 -- training loss: 0.5035469085952036 --validation loss: 0.5194860971441456 -- validation accuracy 0.7352941176470589\n",
      "Epoch 0 Step 250 -- training loss: 0.5113799329481873 --validation loss: 0.5387416178104925 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 300 -- training loss: 0.5013098988787541 --validation loss: 0.5233840650203181 -- validation accuracy 0.7524509803921569\n",
      "Epoch 0 Step 350 -- training loss: 0.4775259284087516 --validation loss: 0.5286318087110332 -- validation accuracy 0.7254901960784313\n",
      "Epoch 0 Step 400 -- training loss: 0.45047750598335057 --validation loss: 0.5095659210985782 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 450 -- training loss: 0.423841714712919 --validation loss: 0.48529153565565747 -- validation accuracy 0.7794117647058824\n",
      "Epoch 0 Step 458 -- training loss: 0.4220683632463152 --validation loss: 0.4924127593928692 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 0 -- training loss: 0.4218818850506884 --validation loss: 0.4934199972479951 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 50 -- training loss: 0.39342103422921726 --validation loss: 0.47146787947299434 -- validation accuracy 0.7794117647058824\n",
      "Epoch 1 Step 100 -- training loss: 0.3625344395118082 --validation loss: 0.4601808964621787 -- validation accuracy 0.7818627450980392\n",
      "Epoch 1 Step 150 -- training loss: 0.3665925225482397 --validation loss: 0.5024498359245413 -- validation accuracy 0.7647058823529411\n",
      "Epoch 1 Step 200 -- training loss: 0.39063436365919696 --validation loss: 0.5696835503274319 -- validation accuracy 0.75\n",
      "Epoch 1 Step 250 -- training loss: 0.360505952668216 --validation loss: 0.4930534197711477 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 300 -- training loss: 0.29113971256937077 --validation loss: 0.44113070970656826 -- validation accuracy 0.7916666666666666\n",
      "Epoch 1 Step 350 -- training loss: 0.3061694285237841 --validation loss: 0.44871514509705934 -- validation accuracy 0.7867647058823529\n",
      "Epoch 1 Step 400 -- training loss: 0.27243565135759207 --validation loss: 0.4382842137825255 -- validation accuracy 0.7941176470588235\n",
      "Epoch 1 Step 450 -- training loss: 0.2854444239337265 --validation loss: 0.4939376892996769 -- validation accuracy 0.7843137254901961\n",
      "Epoch 1 Step 458 -- training loss: 0.2736204482842245 --validation loss: 0.4750787536887562 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 0 -- training loss: 0.2703565751042111 --validation loss: 0.4679431674235007 -- validation accuracy 0.7941176470588235\n",
      "Epoch 2 Step 50 -- training loss: 0.22553257491390885 --validation loss: 0.4741651626194225 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 100 -- training loss: 0.19194596759317553 --validation loss: 0.49459345434226243 -- validation accuracy 0.8161764705882353\n",
      "Epoch 2 Step 150 -- training loss: 0.17175354653957234 --validation loss: 0.47869401191379507 -- validation accuracy 0.8308823529411765\n",
      "Epoch 2 Step 200 -- training loss: 0.1688616763524435 --validation loss: 0.4681330431325763 -- validation accuracy 0.821078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.16192878384654427 --validation loss: 0.4688889679371142 -- validation accuracy 0.8259803921568627\n",
      "Epoch 2 Step 300 -- training loss: 0.15175272952379712 --validation loss: 0.4966917330143498 -- validation accuracy 0.8284313725490197\n",
      "Epoch 2 Step 350 -- training loss: 0.15556285991627633 --validation loss: 0.5325094972024945 -- validation accuracy 0.8161764705882353\n",
      "Epoch 2 Step 400 -- training loss: 0.13716222484614335 --validation loss: 0.48834414531787235 -- validation accuracy 0.8308823529411765\n",
      "Epoch 2 Step 450 -- training loss: 0.1534755711975327 --validation loss: 0.5487137327299398 -- validation accuracy 0.8137254901960784\n",
      "Epoch 2 Step 458 -- training loss: 0.15299533288682404 --validation loss: 0.547172396425523 -- validation accuracy 0.8137254901960784\n",
      "The best accuracy was 0.8308823529411765 after step 150 of epoch 2.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "We do not see overfitting in experiment 1 and 2, but we see signs of overfitting in epoch 2 of experiment 3-6.\n",
    "\n",
    "The best result for experiment 1 are at step 350 of epoch 2, where the validation accuracy and validation loss are 79.4% and 0.437, respectively.\n",
    "\n",
    "The best result for experiment 2 are at step 250 of epoch 2, where the validation accuracy and validation loss are 77.7% and 0.468, respectively.\n",
    "\n",
    "In experiment 3, we see some oscillations in both train and validation losses in epoch 1, but the losses overall go down in epoch 1. The best result are at step 458 of epoch 1, where the validation accuracy and validation loss are 78.2% and 0.437, respectively.\n",
    "\n",
    "The best result for experiment 4 are at step 50 of epoch 2, where the validation accuracy and validation loss are 81.6% and 0.430, respectively.\n",
    "\n",
    "In experiment 5, the best result are at step 458 of epoch 1. The validation accuracy at this step is 81.1% whereas the validation loss is 0.408.\n",
    "\n",
    "The best result for experiment 6 are at step 400 of epoch 1, where the validation accuracy and validation loss are 79.4% and 0.438, respectively.\n",
    "\n",
    "Based on these observations, the best results are with experiment 5."
   ],
   "metadata": {
    "id": "ZW9zr6ulUWbo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 114"
   ],
   "metadata": {
    "id": "zcrQ56Bzd96H"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(114)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    # Set padding token to EOS token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0e04376c473b48a2876ef9e7fcd087c0",
      "776783bfd1da4e32935e2cdf6493c49e",
      "cb39b7b9a3814ee9a529cdeea8621b5b",
      "9d17aefb888f4885adcf38663be54887",
      "9fc5a329b0344322a63cc2856cc4fc35",
      "195f388daec34536bd2d76b0d8dc9c40",
      "294f8d2e6cc9406599e186c7b38427c5",
      "3d7f727c943e48bab9d2f95000dfc430",
      "8a896456c39f4ff6bca59ed8e70f33d8",
      "584f6c0528704cbabfa635c2966ba7c4",
      "2d41981164fc4b7b9f16d9d73edbc32f"
     ]
    },
    "id": "w09Vx1U_01JZ",
    "outputId": "41a2c2bf-0364-4b8c-faf3-9bad3a48c8a1"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e04376c473b48a2876ef9e7fcd087c0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 1.0465804818116762 --validation loss: 1.0321396142974788 -- validation accuracy 0.678921568627451\n",
      "Epoch 0 Step 50 -- training loss: 0.6746570381918244 --validation loss: 0.6906085034795836 -- validation accuracy 0.6617647058823529\n",
      "Epoch 0 Step 100 -- training loss: 0.6248471182740591 --validation loss: 0.6325051953979567 -- validation accuracy 0.6691176470588235\n",
      "Epoch 0 Step 150 -- training loss: 0.5992267095445288 --validation loss: 0.6041843645712909 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 200 -- training loss: 0.5888089087339268 --validation loss: 0.5954521497090658 -- validation accuracy 0.7083333333333334\n",
      "Epoch 0 Step 250 -- training loss: 0.5940247537783289 --validation loss: 0.5971872867906795 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 300 -- training loss: 0.5549838284521581 --validation loss: 0.5638869685285232 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 350 -- training loss: 0.576496508873366 --validation loss: 0.5886019649458867 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 400 -- training loss: 0.5389977561752262 --validation loss: 0.5491901840649399 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 450 -- training loss: 0.536246853943484 --validation loss: 0.5442680511988846 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 458 -- training loss: 0.5368621760009421 --validation loss: 0.5457635124524435 -- validation accuracy 0.7230392156862745\n",
      "Epoch 1 Step 0 -- training loss: 0.5376437226541682 --validation loss: 0.5461642227920831 -- validation accuracy 0.7205882352941176\n",
      "Epoch 1 Step 50 -- training loss: 0.5189991390133735 --validation loss: 0.5261882975989697 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 100 -- training loss: 0.531021330383868 --validation loss: 0.5462217772123861 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 150 -- training loss: 0.5158116760986303 --validation loss: 0.5315470245538974 -- validation accuracy 0.7475490196078431\n",
      "Epoch 1 Step 200 -- training loss: 0.5001659021268483 --validation loss: 0.5219757808189766 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 250 -- training loss: 0.48677231949269123 --validation loss: 0.5101149213664672 -- validation accuracy 0.75\n",
      "Epoch 1 Step 300 -- training loss: 0.48034468322407964 --validation loss: 0.501365132191602 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 350 -- training loss: 0.47187172574415187 --validation loss: 0.5040675390000436 -- validation accuracy 0.75\n",
      "Epoch 1 Step 400 -- training loss: 0.4829760410362339 --validation loss: 0.5097991491065306 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 450 -- training loss: 0.4572508220514181 --validation loss: 0.5017511315789878 -- validation accuracy 0.7475490196078431\n",
      "Epoch 1 Step 458 -- training loss: 0.45500547028185234 --validation loss: 0.5026119257889542 -- validation accuracy 0.75\n",
      "Epoch 2 Step 0 -- training loss: 0.45888509268594463 --validation loss: 0.5068797065931208 -- validation accuracy 0.7401960784313726\n",
      "Epoch 2 Step 50 -- training loss: 0.43394087138129217 --validation loss: 0.4848555028438568 -- validation accuracy 0.7647058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.417404175973406 --validation loss: 0.4805682272303338 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 150 -- training loss: 0.45531514379518484 --validation loss: 0.5293515952778798 -- validation accuracy 0.7524509803921569\n",
      "Epoch 2 Step 200 -- training loss: 0.40327272468402753 --validation loss: 0.4739095936803257 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 250 -- training loss: 0.40856025083911707 --validation loss: 0.4832944373289744 -- validation accuracy 0.7720588235294118\n",
      "Epoch 2 Step 300 -- training loss: 0.4103042626984758 --validation loss: 0.5017091406911027 -- validation accuracy 0.75\n",
      "Epoch 2 Step 350 -- training loss: 0.38426361564132905 --validation loss: 0.46970774320995107 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 400 -- training loss: 0.3643043340226404 --validation loss: 0.4939898069874913 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 450 -- training loss: 0.38400555259197106 --validation loss: 0.488993541282766 -- validation accuracy 0.7745098039215687\n",
      "Epoch 2 Step 458 -- training loss: 0.37687363620027736 --validation loss: 0.48510118471641167 -- validation accuracy 0.7647058823529411\n",
      "The best accuracy was 0.7794117647058824 after step 100 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 1.0465804818116762 --validation loss: 1.0321396142974788 -- validation accuracy 0.678921568627451\n",
      "Epoch 0 Step 50 -- training loss: 0.6751514139842884 --validation loss: 0.6914475081013698 -- validation accuracy 0.6666666666666666\n",
      "Epoch 0 Step 100 -- training loss: 0.626175361293853 --validation loss: 0.6342649097536125 -- validation accuracy 0.6666666666666666\n",
      "Epoch 0 Step 150 -- training loss: 0.6019024397358136 --validation loss: 0.6075995517712013 -- validation accuracy 0.6862745098039216\n",
      "Epoch 0 Step 200 -- training loss: 0.5885519529479781 --validation loss: 0.594912561715818 -- validation accuracy 0.7083333333333334\n",
      "Epoch 0 Step 250 -- training loss: 0.5857074765857788 --validation loss: 0.5894725220460518 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 300 -- training loss: 0.5651204162043943 --validation loss: 0.5736875563275581 -- validation accuracy 0.7083333333333334\n",
      "Epoch 0 Step 350 -- training loss: 0.5652372777656792 --validation loss: 0.5757779341702368 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 400 -- training loss: 0.5443117890612492 --validation loss: 0.5537223874353895 -- validation accuracy 0.7303921568627451\n",
      "Epoch 0 Step 450 -- training loss: 0.5417359928095263 --validation loss: 0.5486833213591108 -- validation accuracy 0.7230392156862745\n",
      "Epoch 0 Step 458 -- training loss: 0.5420643016533654 --validation loss: 0.5496309358699649 -- validation accuracy 0.7181372549019608\n",
      "Epoch 1 Step 0 -- training loss: 0.5426072483164033 --validation loss: 0.549783408057456 -- validation accuracy 0.7181372549019608\n",
      "Epoch 1 Step 50 -- training loss: 0.5305996793352701 --validation loss: 0.5378292138670006 -- validation accuracy 0.7475490196078431\n",
      "Epoch 1 Step 100 -- training loss: 0.53633074124784 --validation loss: 0.5472783025573281 -- validation accuracy 0.7279411764705882\n",
      "Epoch 1 Step 150 -- training loss: 0.5151907089683745 --validation loss: 0.525439205122929 -- validation accuracy 0.7426470588235294\n",
      "Epoch 1 Step 200 -- training loss: 0.5139384963478658 --validation loss: 0.5270937351035136 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 250 -- training loss: 0.5056609236077286 --validation loss: 0.5205050744846755 -- validation accuracy 0.7426470588235294\n",
      "Epoch 1 Step 300 -- training loss: 0.5074643729364171 --validation loss: 0.522074032647937 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 350 -- training loss: 0.4974469927206538 --validation loss: 0.514270970342206 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 400 -- training loss: 0.5041374921279276 --validation loss: 0.522534441129834 -- validation accuracy 0.7475490196078431\n",
      "Epoch 1 Step 450 -- training loss: 0.49195356566402126 --validation loss: 0.5142642905314764 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 458 -- training loss: 0.4910888059920995 --validation loss: 0.5141968648223316 -- validation accuracy 0.7475490196078431\n",
      "Epoch 2 Step 0 -- training loss: 0.49224845328102446 --validation loss: 0.5150777376165577 -- validation accuracy 0.7524509803921569\n",
      "Epoch 2 Step 50 -- training loss: 0.48374928624931246 --validation loss: 0.5066671757137075 -- validation accuracy 0.75\n",
      "Epoch 2 Step 100 -- training loss: 0.48194918568877093 --validation loss: 0.5111432846854714 -- validation accuracy 0.7475490196078431\n",
      "Epoch 2 Step 150 -- training loss: 0.4837149292685108 --validation loss: 0.5137698793528127 -- validation accuracy 0.75\n",
      "Epoch 2 Step 200 -- training loss: 0.47045080277719786 --validation loss: 0.5004794097998563 -- validation accuracy 0.75\n",
      "Epoch 2 Step 250 -- training loss: 0.47040306080400557 --validation loss: 0.499879939883363 -- validation accuracy 0.7475490196078431\n",
      "Epoch 2 Step 300 -- training loss: 0.46884811135548654 --validation loss: 0.500810930834097 -- validation accuracy 0.7475490196078431\n",
      "Epoch 2 Step 350 -- training loss: 0.465424514933609 --validation loss: 0.4984388100165947 -- validation accuracy 0.7549019607843137\n",
      "Epoch 2 Step 400 -- training loss: 0.46265502361690297 --validation loss: 0.49651405478225036 -- validation accuracy 0.7549019607843137\n",
      "Epoch 2 Step 450 -- training loss: 0.46285411520721087 --validation loss: 0.49733876305467944 -- validation accuracy 0.75\n",
      "Epoch 2 Step 458 -- training loss: 0.46303722117915913 --validation loss: 0.49734104468541984 -- validation accuracy 0.75\n",
      "The best accuracy was 0.7549019607843137 after step 350 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.9949173327202631 --validation loss: 0.9815634787082672 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6722144740339457 --validation loss: 0.6726028434201783 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 100 -- training loss: 0.6016157772676098 --validation loss: 0.6071371044598374 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 150 -- training loss: 0.583191493270444 --validation loss: 0.587233220245324 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 200 -- training loss: 0.605412658133538 --validation loss: 0.6073397710627201 -- validation accuracy 0.6985294117647058\n",
      "Epoch 0 Step 250 -- training loss: 0.6069199190615049 --validation loss: 0.6082200942670598 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 300 -- training loss: 0.5320766410406899 --validation loss: 0.5462948627331677 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 350 -- training loss: 0.6216035968987251 --validation loss: 0.6374293650482216 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 400 -- training loss: 0.5399726137096845 --validation loss: 0.5623721088848862 -- validation accuracy 0.7377450980392157\n",
      "Epoch 0 Step 450 -- training loss: 0.5150113628126177 --validation loss: 0.5332115952875099 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 458 -- training loss: 0.5182703065651434 --validation loss: 0.5396392590859357 -- validation accuracy 0.7230392156862745\n",
      "Epoch 1 Step 0 -- training loss: 0.5184804378706386 --validation loss: 0.5398345122150346 -- validation accuracy 0.7181372549019608\n",
      "Epoch 1 Step 50 -- training loss: 0.5094915214512084 --validation loss: 0.5442108196370742 -- validation accuracy 0.7303921568627451\n",
      "Epoch 1 Step 100 -- training loss: 0.47151614261348784 --validation loss: 0.5266826766378739 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 150 -- training loss: 0.46465481006112236 --validation loss: 0.5226060245551315 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 200 -- training loss: 0.4615529663941959 --validation loss: 0.5259510267014597 -- validation accuracy 0.7303921568627451\n",
      "Epoch 1 Step 250 -- training loss: 0.42759055012841113 --validation loss: 0.50965662066843 -- validation accuracy 0.7450980392156863\n",
      "Epoch 1 Step 300 -- training loss: 0.5123911591202086 --validation loss: 0.5762801485903123 -- validation accuracy 0.6887254901960784\n",
      "Epoch 1 Step 350 -- training loss: 0.3896110055720624 --validation loss: 0.48540742344716015 -- validation accuracy 0.8014705882352942\n",
      "Epoch 1 Step 400 -- training loss: 0.4039340805189282 --validation loss: 0.5058703036869273 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 450 -- training loss: 0.3651207011509565 --validation loss: 0.47361131713670845 -- validation accuracy 0.7965686274509803\n",
      "Epoch 1 Step 458 -- training loss: 0.3640563097297496 --validation loss: 0.4809921039085762 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 0 -- training loss: 0.3696314999285866 --validation loss: 0.49015509468667645 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 50 -- training loss: 0.33307128571671857 --validation loss: 0.5062075777381074 -- validation accuracy 0.7916666666666666\n",
      "Epoch 2 Step 100 -- training loss: 0.27873969935124215 --validation loss: 0.4299909869829814 -- validation accuracy 0.8259803921568627\n",
      "Epoch 2 Step 150 -- training loss: 0.29687420910626067 --validation loss: 0.4968054924233287 -- validation accuracy 0.7965686274509803\n",
      "Epoch 2 Step 200 -- training loss: 0.27603143088373483 --validation loss: 0.4694478273683903 -- validation accuracy 0.7965686274509803\n",
      "Epoch 2 Step 250 -- training loss: 0.27017404298117476 --validation loss: 0.4598940686852324 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 300 -- training loss: 0.25393398477815593 --validation loss: 0.46541338545434613 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 350 -- training loss: 0.2517983502097639 --validation loss: 0.4475610630184996 -- validation accuracy 0.7965686274509803\n",
      "Epoch 2 Step 400 -- training loss: 0.2615612548469588 --validation loss: 0.5831057228440163 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 450 -- training loss: 0.18353306320303145 --validation loss: 0.425468415314076 -- validation accuracy 0.821078431372549\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2 Step 458 -- training loss: 0.22317763462191964 --validation loss: 0.5035581742139423 -- validation accuracy 0.7867647058823529\n",
      "The best accuracy was 0.8259803921568627 after step 100 of epoch 2.\n",
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.9949173327202631 --validation loss: 0.9815634787082672 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.669341016244265 --validation loss: 0.6700909774677426 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 100 -- training loss: 0.6021291036686347 --validation loss: 0.60791508473602 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 150 -- training loss: 0.5862940742039733 --validation loss: 0.590306865234001 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 200 -- training loss: 0.5974929044449252 --validation loss: 0.6004572209774279 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 250 -- training loss: 0.6009607055997537 --validation loss: 0.6016820601972879 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 300 -- training loss: 0.5351947250579178 --validation loss: 0.5466830590192009 -- validation accuracy 0.7230392156862745\n",
      "Epoch 0 Step 350 -- training loss: 0.6148680073730567 --validation loss: 0.6317615722324333 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 400 -- training loss: 0.5422670749667423 --validation loss: 0.5613213871039596 -- validation accuracy 0.7426470588235294\n",
      "Epoch 0 Step 450 -- training loss: 0.52286038685728 --validation loss: 0.5385798531420091 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 458 -- training loss: 0.5209946307741219 --validation loss: 0.538873938368816 -- validation accuracy 0.7230392156862745\n",
      "Epoch 1 Step 0 -- training loss: 0.5221311854186401 --validation loss: 0.5398760204221688 -- validation accuracy 0.7205882352941176\n",
      "Epoch 1 Step 50 -- training loss: 0.48947045262213107 --validation loss: 0.5108951546397864 -- validation accuracy 0.7524509803921569\n",
      "Epoch 1 Step 100 -- training loss: 0.4825540153484199 --validation loss: 0.5210276292819603 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 150 -- training loss: 0.4918128768538078 --validation loss: 0.5321064655687294 -- validation accuracy 0.7401960784313726\n",
      "Epoch 1 Step 200 -- training loss: 0.4653410491146034 --validation loss: 0.5146522390491822 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.44337731104725586 --validation loss: 0.5019482865053064 -- validation accuracy 0.7598039215686274\n",
      "Epoch 1 Step 300 -- training loss: 0.45840684660509523 --validation loss: 0.5081315671696383 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 350 -- training loss: 0.4159275196281653 --validation loss: 0.48614775316388 -- validation accuracy 0.7843137254901961\n",
      "Epoch 1 Step 400 -- training loss: 0.42337494116268387 --validation loss: 0.48909011395538554 -- validation accuracy 0.7745098039215687\n",
      "Epoch 1 Step 450 -- training loss: 0.38850218497525113 --validation loss: 0.4787692941871344 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 458 -- training loss: 0.3880468461183681 --validation loss: 0.48468629051657286 -- validation accuracy 0.7965686274509803\n",
      "Epoch 2 Step 0 -- training loss: 0.39116186502517436 --validation loss: 0.4889279896137761 -- validation accuracy 0.7916666666666666\n",
      "Epoch 2 Step 50 -- training loss: 0.36230580255486605 --validation loss: 0.4705324070710762 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 100 -- training loss: 0.3439080609020844 --validation loss: 0.46128588827217326 -- validation accuracy 0.7965686274509803\n",
      "Epoch 2 Step 150 -- training loss: 0.35795336172861214 --validation loss: 0.4971992151409972 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 200 -- training loss: 0.32639175787373303 --validation loss: 0.4600095596967959 -- validation accuracy 0.7990196078431373\n",
      "Epoch 2 Step 250 -- training loss: 0.3138917961232932 --validation loss: 0.4583749210133272 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 300 -- training loss: 0.3050163198903625 --validation loss: 0.4577515785600625 -- validation accuracy 0.8137254901960784\n",
      "Epoch 2 Step 350 -- training loss: 0.30048099385822 --validation loss: 0.455781942050831 -- validation accuracy 0.7990196078431373\n",
      "Epoch 2 Step 400 -- training loss: 0.2932975255521035 --validation loss: 0.45054546319970895 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 450 -- training loss: 0.2926610443651806 --validation loss: 0.4507886948538761 -- validation accuracy 0.8063725490196079\n",
      "Epoch 2 Step 458 -- training loss: 0.2927828087656067 --validation loss: 0.4508914295949188 -- validation accuracy 0.8063725490196079\n",
      "The best accuracy was 0.8137254901960784 after step 300 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.9480582174879534 --validation loss: 0.9370095849621529 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.7167714424999451 --validation loss: 0.7094836449798416 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 100 -- training loss: 0.5970809048686931 --validation loss: 0.5961940317761665 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 150 -- training loss: 0.5756784478823344 --validation loss: 0.5841832733621785 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 200 -- training loss: 0.5966290446538032 --validation loss: 0.5982822311275146 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 250 -- training loss: 0.7042008689351071 --validation loss: 0.7079208710906553 -- validation accuracy 0.6862745098039216\n",
      "Epoch 0 Step 300 -- training loss: 0.5505814414658058 --validation loss: 0.5656761941956538 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 350 -- training loss: 0.6262172723680021 --validation loss: 0.648523340622584 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 400 -- training loss: 0.5338845723724573 --validation loss: 0.5553574468575272 -- validation accuracy 0.7279411764705882\n",
      "Epoch 0 Step 450 -- training loss: 0.506991578700236 --validation loss: 0.5303137655936035 -- validation accuracy 0.7352941176470589\n",
      "Epoch 0 Step 458 -- training loss: 0.515143626623164 --validation loss: 0.5408269073448929 -- validation accuracy 0.7279411764705882\n",
      "Epoch 1 Step 0 -- training loss: 0.511973681857643 --validation loss: 0.5374478016998253 -- validation accuracy 0.7303921568627451\n",
      "Epoch 1 Step 50 -- training loss: 0.4653323994287998 --validation loss: 0.50984013022161 -- validation accuracy 0.7475490196078431\n",
      "Epoch 1 Step 100 -- training loss: 0.46913565487513614 --validation loss: 0.5261364871380376 -- validation accuracy 0.7475490196078431\n",
      "Epoch 1 Step 150 -- training loss: 0.43994847859594816 --validation loss: 0.510741769975307 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 200 -- training loss: 0.4220471018539794 --validation loss: 0.49882785333137886 -- validation accuracy 0.7573529411764706\n",
      "Epoch 1 Step 250 -- training loss: 0.37947888464579654 --validation loss: 0.49418606419189304 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 300 -- training loss: 0.4539584240395259 --validation loss: 0.5911583929669624 -- validation accuracy 0.696078431372549\n",
      "Epoch 1 Step 350 -- training loss: 0.35841650501185773 --validation loss: 0.4758870096183291 -- validation accuracy 0.7745098039215687\n",
      "Epoch 1 Step 400 -- training loss: 0.3654057871639599 --validation loss: 0.48301377834058273 -- validation accuracy 0.7549019607843137\n",
      "Epoch 1 Step 450 -- training loss: 0.40035014227844273 --validation loss: 0.5193184801176483 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 458 -- training loss: 0.34691461206521346 --validation loss: 0.48398800165045497 -- validation accuracy 0.7549019607843137\n",
      "Epoch 2 Step 0 -- training loss: 0.36204856086303205 --validation loss: 0.5042855571590218 -- validation accuracy 0.7524509803921569\n",
      "Epoch 2 Step 50 -- training loss: 0.24756517391124322 --validation loss: 0.48246951445060615 -- validation accuracy 0.8137254901960784\n",
      "Epoch 2 Step 100 -- training loss: 0.2764867560091897 --validation loss: 0.5615387618833897 -- validation accuracy 0.7696078431372549\n",
      "Epoch 2 Step 150 -- training loss: 0.22801258249821096 --validation loss: 0.4969850956809287 -- validation accuracy 0.7843137254901961\n",
      "Epoch 2 Step 200 -- training loss: 0.2504611649511946 --validation loss: 0.5105424074857843 -- validation accuracy 0.7573529411764706\n",
      "Epoch 2 Step 250 -- training loss: 0.22384407256338298 --validation loss: 0.5048823168172556 -- validation accuracy 0.7990196078431373\n",
      "Epoch 2 Step 300 -- training loss: 0.27069389140679784 --validation loss: 0.687629121556586 -- validation accuracy 0.7524509803921569\n",
      "Epoch 2 Step 350 -- training loss: 0.1719793384744581 --validation loss: 0.478353024113412 -- validation accuracy 0.8014705882352942\n",
      "Epoch 2 Step 400 -- training loss: 0.19541729064069868 --validation loss: 0.5868380494123581 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 450 -- training loss: 0.12356449756162619 --validation loss: 0.46397439938257723 -- validation accuracy 0.803921568627451\n",
      "Epoch 2 Step 458 -- training loss: 0.15083204361677072 --validation loss: 0.5585478260090538 -- validation accuracy 0.7892156862745098\n",
      "The best accuracy was 0.8137254901960784 after step 50 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.9480582174879534 --validation loss: 0.9370095849621529 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.7159055888587873 --validation loss: 0.7087677179598341 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 100 -- training loss: 0.5955916290579278 --validation loss: 0.5953427670048732 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 150 -- training loss: 0.5809506234390284 --validation loss: 0.5897534489631653 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 200 -- training loss: 0.5864817282927581 --validation loss: 0.5925035026727938 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 250 -- training loss: 0.6546588052624192 --validation loss: 0.6614055370583254 -- validation accuracy 0.6887254901960784\n",
      "Epoch 0 Step 300 -- training loss: 0.5515893860060664 --validation loss: 0.5712361914270064 -- validation accuracy 0.7132352941176471\n",
      "Epoch 0 Step 350 -- training loss: 0.6290121430080701 --validation loss: 0.6526919211827072 -- validation accuracy 0.696078431372549\n",
      "Epoch 0 Step 400 -- training loss: 0.5417077221901588 --validation loss: 0.5637352828885994 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 450 -- training loss: 0.5057002540052846 --validation loss: 0.5270202738397262 -- validation accuracy 0.7426470588235294\n",
      "Epoch 0 Step 458 -- training loss: 0.5162957440534188 --validation loss: 0.5403671004608566 -- validation accuracy 0.7181372549019608\n",
      "Epoch 1 Step 0 -- training loss: 0.5156957739903256 --validation loss: 0.5397570267611859 -- validation accuracy 0.7205882352941176\n",
      "Epoch 1 Step 50 -- training loss: 0.5019747442799196 --validation loss: 0.5467827207609719 -- validation accuracy 0.7328431372549019\n",
      "Epoch 1 Step 100 -- training loss: 0.4554864706426924 --validation loss: 0.5127591110912024 -- validation accuracy 0.7818627450980392\n",
      "Epoch 1 Step 150 -- training loss: 0.44579318336217233 --validation loss: 0.5218910937215767 -- validation accuracy 0.7622549019607843\n",
      "Epoch 1 Step 200 -- training loss: 0.4415969371730725 --validation loss: 0.5136498729972279 -- validation accuracy 0.7426470588235294\n",
      "Epoch 1 Step 250 -- training loss: 0.3883887617514024 --validation loss: 0.4958963116594389 -- validation accuracy 0.7794117647058824\n",
      "Epoch 1 Step 300 -- training loss: 0.48782324667589855 --validation loss: 0.5712573534133387 -- validation accuracy 0.696078431372549\n",
      "Epoch 1 Step 350 -- training loss: 0.3895065824385562 --validation loss: 0.4891721693908467 -- validation accuracy 0.7745098039215687\n",
      "Epoch 1 Step 400 -- training loss: 0.3820707516213128 --validation loss: 0.4802641515053955 -- validation accuracy 0.7794117647058824\n",
      "Epoch 1 Step 450 -- training loss: 0.3312512233139123 --validation loss: 0.4649688858611911 -- validation accuracy 0.803921568627451\n",
      "Epoch 1 Step 458 -- training loss: 0.33570291693596277 --validation loss: 0.4768187625735414 -- validation accuracy 0.7892156862745098\n",
      "Epoch 2 Step 0 -- training loss: 0.34000206286643586 --validation loss: 0.48378054885303273 -- validation accuracy 0.7818627450980392\n",
      "Epoch 2 Step 50 -- training loss: 0.28918568900337926 --validation loss: 0.4653381172056292 -- validation accuracy 0.8088235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.26067432128948065 --validation loss: 0.46682366056769503 -- validation accuracy 0.8088235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.31269391547190534 --validation loss: 0.5857736411340096 -- validation accuracy 0.7867647058823529\n",
      "Epoch 2 Step 200 -- training loss: 0.2637284812933414 --validation loss: 0.5166477908690771 -- validation accuracy 0.8063725490196079\n",
      "Epoch 2 Step 250 -- training loss: 0.2389769140744586 --validation loss: 0.5214519001105252 -- validation accuracy 0.8186274509803921\n",
      "Epoch 2 Step 300 -- training loss: 0.219358436958073 --validation loss: 0.5133880029122034 -- validation accuracy 0.8112745098039216\n",
      "Epoch 2 Step 350 -- training loss: 0.20272837647831388 --validation loss: 0.4840825055451954 -- validation accuracy 0.8063725490196079\n",
      "Epoch 2 Step 400 -- training loss: 0.20322014042227032 --validation loss: 0.503350330918443 -- validation accuracy 0.8137254901960784\n",
      "Epoch 2 Step 450 -- training loss: 0.19663086726506745 --validation loss: 0.49117910409090565 -- validation accuracy 0.8235294117647058\n",
      "Epoch 2 Step 458 -- training loss: 0.19705354065831127 --validation loss: 0.4920525683784017 -- validation accuracy 0.8235294117647058\n",
      "The best accuracy was 0.8235294117647058 after step 450 of epoch 2.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiment 1, we do not observe overfitting. The best result is at step 350 of epoch 2, where the validation accuracy is 77.5% and validation loss is 0.470.\n",
    "\n",
    "We do not see overfitting in experiment 2 as well. The best result is at step 400 of epoch 2. The validation accuracy and validation loss are 75.5% and 0.497 at this step.\n",
    "\n",
    "In experiment 3, we see signs of overfitting in later steps of epoch 2. We also see some oscillations in both train and validation losses, but overall losses go down. The best result is at step 100 of epoch 2, where the validation accuracy and validation loss are 82.6% and 0.430, respectively.\n",
    "\n",
    "In experiment 4, we see some oscillations in both train and validation losses, but the losses go down. We do not observe any signs of overfitting. The best result is at step 400 of epoch 2, where the validation accuracy is 80.4% and validation loss is 0.451.\n",
    "\n",
    "We observe large oscillations in validation loss in epoch 2, and hence, decide to ignore this epoch. There are also some oscillations in both train and validation losses in epoch 1 as well, but they are relatively small oscillations and the losses overall go down. The best result for this experiment is at step 400 of epoch 1. The validation accuracy and validation loss at this step are 75.5% and 0.483, respectively.\n",
    "\n",
    "In experiment 6, we observe overfitting after epoch 1. The best result is at step 450 of epoch 1. The validation accuracy at this step is 80.4% whereas the validation loss is 0.465.\n",
    "\n",
    "Therefore, we conclude that the best results are achieved with experiment 3."
   ],
   "metadata": {
    "id": "3448T8UqXA3X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "We conclude that the experiment with a random seed of 23 with a constant learning rate of $5\\times 10^{-5}$ leads to the best result (validation loss of 0.408) if we stop after step 458 of epoch 1."
   ],
   "metadata": {
    "id": "qU1lBYDyZIDy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Repeating the best performing experiment\n",
    "with the stopping condition to get the\n",
    "model weights and to calculate test accuracy.\n",
    "'''\n",
    "\n",
    "lr = 5e-5\n",
    "lr_scheduler = False\n",
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "stopping_condition = {'step': 458, 'epoch': 1}\n",
    "\n",
    "set_seed(23)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "# Set padding token to EOS token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "trainer_config = {'optimizer' : AdamW,\n",
    "              'num_epochs' : num_epochs,\n",
    "              'learning_rate' : lr,\n",
    "              'lr_scheduler' : lr_scheduler,\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "trainer = sentence_similarity_trainer(model=model,\n",
    "                  train_dataloader = train_dataloader,\n",
    "                  val_dataloader = val_dataloader,\n",
    "                  device = device,\n",
    "                  trainer_config = trainer_config,\n",
    "                  stopping_condition = stopping_condition,\n",
    "                  )\n",
    "\n",
    "# Running the training loops\n",
    "trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UAfOxkhlZHS3",
    "outputId": "648a4963-4a5f-42f8-9183-963d6baa8769"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 Step 0 -- training loss: 0.8624716038797416 --validation loss: 0.8309214468680176 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5807699891606707 --validation loss: 0.5738563005830727 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 100 -- training loss: 0.5423233825591655 --validation loss: 0.5493259324746973 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 150 -- training loss: 0.6005775729977487 --validation loss: 0.6038244904256335 -- validation accuracy 0.7034313725490197\n",
      "Epoch 0 Step 200 -- training loss: 0.5022916168883476 --validation loss: 0.5206058416880813 -- validation accuracy 0.7401960784313726\n",
      "Epoch 0 Step 250 -- training loss: 0.5087184330087342 --validation loss: 0.5390056418437584 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 300 -- training loss: 0.5274269219836898 --validation loss: 0.5483598083842034 -- validation accuracy 0.7549019607843137\n",
      "Epoch 0 Step 350 -- training loss: 0.482880339821829 --validation loss: 0.5342401543668672 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 400 -- training loss: 0.4762674550767298 --validation loss: 0.5322411562882218 -- validation accuracy 0.7328431372549019\n",
      "Epoch 0 Step 450 -- training loss: 0.44411894656344436 --validation loss: 0.5075960880985447 -- validation accuracy 0.7622549019607843\n",
      "Epoch 0 Step 458 -- training loss: 0.5164294988403912 --validation loss: 0.6007342559157633 -- validation accuracy 0.7352941176470589\n",
      "Epoch 1 Step 0 -- training loss: 0.4936639853227632 --validation loss: 0.5798813285780888 -- validation accuracy 0.75\n",
      "Epoch 1 Step 50 -- training loss: 0.3811479666816123 --validation loss: 0.4519304770464991 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 100 -- training loss: 0.36822186243235416 --validation loss: 0.4521470078650643 -- validation accuracy 0.7916666666666666\n",
      "Epoch 1 Step 150 -- training loss: 0.39541039838250686 --validation loss: 0.5312714036188874 -- validation accuracy 0.7671568627450981\n",
      "Epoch 1 Step 200 -- training loss: 0.3636934962570018 --validation loss: 0.5112258388715631 -- validation accuracy 0.7720588235294118\n",
      "Epoch 1 Step 250 -- training loss: 0.3909662075194658 --validation loss: 0.5142409073955873 -- validation accuracy 0.75\n",
      "Epoch 1 Step 300 -- training loss: 0.2836483112964495 --validation loss: 0.4124221033325382 -- validation accuracy 0.7990196078431373\n",
      "Epoch 1 Step 350 -- training loss: 0.30692467739509344 --validation loss: 0.4350806056868796 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 400 -- training loss: 0.2650142262744553 --validation loss: 0.4707009592184834 -- validation accuracy 0.7892156862745098\n",
      "Epoch 1 Step 450 -- training loss: 0.2602440047266534 --validation loss: 0.49784987134968534 -- validation accuracy 0.7965686274509803\n",
      "Epoch 1 Step 458 -- training loss: 0.2269309847362031 --validation loss: 0.40812241125340554 -- validation accuracy 0.8112745098039216\n",
      "The best accuracy was 0.8112745098039216 after step 458 of epoch 1.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Calculating the test loss\n",
    "'''\n",
    "\n",
    "def test_evaluation():\n",
    "\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "      test_losses = []\n",
    "      test_accuracies = []\n",
    "\n",
    "      for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "        # Getting the batch loss\n",
    "        batch = {k: v.to(trainer.device) for k, v in batch.items()}\n",
    "        outputs = trainer.model(**batch)\n",
    "        test_losses.append(outputs.loss.item())\n",
    "        # Getting the batch accuracy\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        test_accuracy = (predictions == batch['labels']).float().mean()\n",
    "        test_accuracies.append(test_accuracy.item())\n",
    "\n",
    "      avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "      avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "    trainer.model.train()\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy\n",
    "\n",
    "test_loss, test_acc = test_evaluation()\n",
    "print(f\"{test_loss=}\")\n",
    "print(f\"{test_acc=}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CcsYFrhanDS",
    "outputId": "d376aeb7-ffb3-44e5-9412-0b9704edc844"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_loss=0.4346150653091846\n",
      "test_acc=0.8003472222222222\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Uploading the weights on HF\n",
    "'''\n",
    "\n",
    "# Save model weights\n",
    "file_name = \"model_weights.pth\"\n",
    "trainer.save_model(file_name)\n",
    "\n",
    "# Logging into Hugging face Hub\n",
    "hf_token = userdata.get('hf_TOKEN')\n",
    "login(token=hf_token)\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"mudassirmoosa/sentence-similarity-transformer-comparison\"\n",
    "\n",
    "# Uploading model weights\n",
    "api.upload_file(\n",
    "    path_or_fileobj=file_name,\n",
    "    path_in_repo=\"GPT2_for_sentence_similarity.pth\",\n",
    "    repo_id=repo_id,\n",
    "    token=hf_token\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "referenced_widgets": [
      "bb1f430b060c48c9ad10f565674cb290",
      "b8eea493661442048c80ffce017b8cd5",
      "6362c2d0f6f6497ea6476bc12f90914a",
      "2903219aacc84c98bcfe59d0559572a4",
      "67c7ac650e754a149526356d84be892b",
      "27d72ae791f24ad6b0bdd769d70534d0",
      "0b6e33ce06134e3fa9b6ee1a2f875152",
      "ffd0fc3e79484c1d929a828dcb6bcb0d",
      "2c19c3d51ccf41f9a0c179e76906bb4f",
      "f32632b318e1466e8912b29aafd8a0bd",
      "94ad0afa22ed40bba5158a28b0d042f4",
      "d47e105c7174458db525df8901a9c373",
      "32c44313cf63475c85c80fa2a2e9ced7",
      "60d6b294bc8d465b9c72f9d8ac8a3410",
      "96d183d3ee664b3e9258f9c54e25d0f9",
      "db20bb3a0bc24067b4428c5dd70ee050",
      "8e9def8fc9464d4f8633e728163db837",
      "03b8e5c00026407aaf1e3d3c4c0a8d61",
      "9a111dd6dd6f452fa562dc8fbaf56b4e",
      "c3fa1dc48ad34834b3f94c0bf097f985",
      "8a366c13512b4e70b5d6e0cc6615160d",
      "e7cf046cfb89424f83c357ba25d9a033",
      "1a08ed1376f14eaa916f130cd9ead2b4",
      "e125dd84bcdc4f65ab0418d0a61c3b53",
      "499fc8f2dc214496a569d106206969a2",
      "57926a681615425aacced06a017272a1",
      "3835291297344897b327b59ba9133469",
      "43462b3a4f214eb18c6c958ed3763aba",
      "a51d1a1f93fb4dc688e1724f0cb45ade",
      "c769b2b061514ef6bc934fc127fb7268",
      "7137fd24acd64cf4a038c84f8a2303b6",
      "2e75067f026646e1a466e5b4bd5fdfb7",
      "f5f53c967e634781b9f27d2be4d1c8a0"
     ]
    },
    "id": "G9GTgUQZaoA8",
    "outputId": "340ad6db-13d2-4d9a-c305-890bbf4cda7f"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb1f430b060c48c9ad10f565674cb290"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d47e105c7174458db525df8901a9c373"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  model_weights.pth                     :   0%|          |  552kB /  498MB            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a08ed1376f14eaa916f130cd9ead2b4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mudassirmoosa/sentence-similarity-transformer-comparison/commit/e9bdb38f09547072f4c3880cd349886dfe390feb', commit_message='Upload GPT2_for_sentence_similarity.pth with huggingface_hub', commit_description='', oid='e9bdb38f09547072f4c3880cd349886dfe390feb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mudassirmoosa/sentence-similarity-transformer-comparison', endpoint='https://huggingface.co', repo_type='model', repo_id='mudassirmoosa/sentence-similarity-transformer-comparison'), pr_revision=None, pr_num=None)"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  }
 ]
}