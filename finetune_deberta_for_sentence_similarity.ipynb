{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "collapsed_sections": [
    "T4oNyr44Q328",
    "HCp-cKAeb5R8",
    "q6BmimuCcHEs",
    "HdfrP6QhcJs6"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u88zo-xxO5vY"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import set_seed\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from huggingface_hub import HfApi, login, hf_hub_download\n",
    "from google.colab import userdata\n",
    "\n",
    "from supplementary_file_for_sentence_similarity import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the tokenizer and a dataset"
   ],
   "metadata": {
    "id": "_L4TSubBPCmT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading the tokenizer\n",
    "\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "id": "wg-rNyjRPGE4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279,
     "referenced_widgets": [
      "5db883d3f5834e75b556651be3c38002",
      "a0d2002f02d44d25ac7a0cb18d0ec601",
      "8d035fc3a8084dedb8efba8f4518a220",
      "b9177c70286d41cab963bef36010392c",
      "e95c239c8878457586265f425f7917bd",
      "6e213c09087e48db942c9519e8f7c1e1",
      "0c1e622d9863490eb5909a2342116b95",
      "67dc6fb51877444685bdaa456e0cfce9",
      "3f6655b7fbe34c9c9e51e9201a9ced4a",
      "fcc8d3ada3474074b273498e934b6266",
      "324f4d1a912845a3b3a9d837936d689b",
      "b4d7dc42014d4e049ce8bfd3db5b6b52",
      "390cc21ed5ce40fcaeb3175c25e79d47",
      "84b62280ca154671be0632744a72c9d7",
      "dcc9acfad22b4a39a43ebd926699983d",
      "4c8dea467c3f4cc3ac4d9f2e3ec599e9",
      "980f53fa45bc47ad802a97fc00922aaa",
      "13fff8ee5c96494b8ee9e67c73143911",
      "d96aaf1fda3945c1b7a2b4ad2f395537",
      "1e66e54187e94211a7cc9dc6a02b35fa",
      "84df3ec3c1894ecd97efd4ddd3d37b71",
      "89eab043390b4021abf9ff20582fd8cd",
      "b731590690184daf922b190a84da6824",
      "90b844515c6546198e7d4325a11ac848",
      "d0e2b16bb0e54e2983410d45991fc0d9",
      "1adeff761ed04baea33320bc907f09eb",
      "4a5a508e6e8645a1ba0512621e784b0d",
      "8e81dd3676704a64a45c2369f357d559",
      "86ea08d2a86f4b6a8e78c2bed7527598",
      "ffb02598f6a94b25b1b0499915b00d92",
      "178b340c39f043668a93bf6be35a52be",
      "afdcd3e1ccc74d488c49289c4b45a55b",
      "a23cd1a93510403c8fd779f48ea06ef0"
     ]
    },
    "outputId": "94c45c3f-8ad9-4714-96dd-1e784eceabba"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5db883d3f5834e75b556651be3c38002"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4d7dc42014d4e049ce8bfd3db5b6b52"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b731590690184daf922b190a84da6824"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "dataloader = sentence_similarity_dataloaders(tokenizer)\n",
    "\n",
    "set_seed(42)\n",
    "train_dataloader, val_dataloader, test_dataloader = dataloader.get_dataloaders()"
   ],
   "metadata": {
    "id": "k-8IUA_JP9zN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375,
     "referenced_widgets": [
      "d3a12d4e1cbf41749188cec3bf480eab",
      "90d3b96c5fce4ab18f7257e99262c3b7",
      "59df4e7cf5064cc1ae02d12400cdf8a9",
      "80dabd47b71f472ab77f7abe9f304060",
      "86da7b05592b46dc80890c5fc1a2f312",
      "9770081ec3cd40ddb22c509714f1c6e1",
      "9eb6dd55970d49ac8a97349aa21aadcd",
      "628cf15409a54623b3287258832ba6e9",
      "32385d39982b4f75a359bf6437a7b936",
      "808d75bebd934e29b99a8941c219b1ac",
      "b45b1c3753a74487a97f8ed7207af710",
      "e675082c9bc649bd92fac9860a0c6b3e",
      "691c561b5f424baa9b22fdde73632588",
      "77d212ca3f184eea91eede4d9b8ac6f1",
      "36df8c95d4974e4088c966a0850d6e14",
      "197e59705aee4cb8b9df66b2945efbc0",
      "5c8665447fb3499bb0a96abbc47c9b40",
      "18e3dcd28907477bb5fe0c4a6afe26c5",
      "d6c6489dfb004c4286caef7a3b6195f2",
      "a24e824e3f4a4d0cab262bcbbf2366dd",
      "4c2f28b0e4c545d7b6edfb2fd8040138",
      "ff448595be374db49527c608cd598f4f",
      "18663ddea68c436198e539d250be1311",
      "d865a7c75bf34c2084123b0d3359d8ba",
      "5d3d0f39bfc0467a935724443e45e048",
      "870d759a32b747b2b9705715cbd76bcd",
      "9f5317123ce248cd8ec188f6a3902cd2",
      "052f30ca60464155831c4bc995d16db9",
      "9e564ceadca0427d9d03cdae240fc84f",
      "2870df9f81a24b81bda49c83f392a2b3",
      "ede6e7e37e83481989b562dcabb9ac3f",
      "8b445678d8544a9db6c9467da6dde57f",
      "e9b7b3cc672d4d6490f7454298ff2548",
      "ddd1ec3bba3d4ace987790aefbe45b84",
      "1eb7772ba7c843d0886a8b1410428bb4",
      "22cdddeb789d4e0da1405828d97a1e90",
      "77709eb17a744357a0f13f89119f0e4c",
      "a9334997a59b4ab99bb5ad36263bef2d",
      "7f1c97f5d4c2489abb2ef690a640321c",
      "832f3bc88b3d47919c289407294048ad",
      "94fa415f12884bc48d4a7032c12cdce9",
      "25195292f7ef4869a0c8add433be5971",
      "7cd29c1d18a54ecea958817739c21939",
      "f93b44c9a4d54b728780c49b950ff705",
      "c08171c60d3444c58c16805f3db50d70",
      "2a13e6234e2d4ab89309e008a9287473",
      "882a90c131da48d4b1f9b5e69896c73d",
      "82097eae07cd426fa3b84507aafe27a5",
      "d2cde8c86c3a46f79b8c67528a920438",
      "373aa8e8e41448b6abdebbd9631323dc",
      "2144977262444195b75dc12759c3af83",
      "ec32e76f96d443efa528b196a937e967",
      "43f8563f94a2493b9471287c2b66fc44",
      "856a4df28aac48cda6950d3c9888c42a",
      "5678a4c49e444de9bda9977c4d1fcc31",
      "d9b27de9ff4848e2a8fa90bd4e2c3548",
      "852ded25acc34a5f92e0a33250579aed",
      "e462f6c3127b483997450520deaa7646",
      "74eb084fb0f4406ca2fcbe3703b00c18",
      "38348af77e6e4496bef0400ac4863a7d",
      "bc94638ef52643f2997d4cfab1047b8e",
      "010432135805404aaa091a6399ffa462",
      "22f9e572c6934345b9218bd1133f82fd",
      "6a723e4a1dd54fa28b6f437e7caf2a15",
      "f2be65a2d32c48d48c6714bb8aaad0fe",
      "f320f51f53c04af0a30caeb2cf2c3e0e",
      "ae9caff2d4c54b4184ddacfb9d623c31",
      "75e1c7cbd2ce4bb3b2343ed08d17226a",
      "334ec6532fff4f61a12d6041e949da72",
      "e44fedc8697f4af3a14fda78ece985f6",
      "30a0a989bb6348e2a76b5dad973ca65a",
      "d5c5ef1aa7bb4c9d96c4df0de83a5718",
      "1a6d74975f0349a1a6b1639b987055de",
      "d474c42256e54fe6a1d2c43de7aca7c1",
      "332bfdf32d5b45389a31108639ac45f9",
      "3a064513ac6449919ffca654c069f4bb",
      "fe07444a19ca45b49b5d14c301b819c4",
      "810656e5a88a41cf9ecdf5fefdd13417",
      "e67528ce47de4c3dab73e67b4de2a02f",
      "d08daff1c51040dc9b397b671e8d1bf7",
      "44c7d88dcdd3408eaf459882bb3a1952",
      "bd6ad714257847d28109ba8a3e4b82ee",
      "e9414a6d1a7948a69767a360ea42600e",
      "c278a06cf30d4d7191c5305b91ec43ab",
      "0ec631f462634f9aa944632e1e1ed9bc",
      "398db6f2e1cf441595af5fcab2808a37",
      "8950a7144978415d82fabceb07ed4112",
      "f78b0ce42f8444b094c05eb3cd25fe6f",
      "ff317d4e84e14279a4d95cdd0f3d4759",
      "14f132becd2c4897b1e88dc502ac69e6",
      "0670055439784408bbc6d5eed66196cc",
      "0fdfc52233014613956e144164ea3383",
      "1e0de3fbfb204c54a65384a7033b4013",
      "7ef68acd33b24d96a41e25e6a4dd72c1",
      "35bbc5f10e324482a8144314b090021a",
      "e021138e3c844a708e80efb9db74ca52",
      "a1a8e91db9ef4d6c8f8f901b054fed0f",
      "69e5c153b1ab44979827291c973c4a9a",
      "161bd6593bd44fc39eecdb02fb5b1d3f",
      "779ac9080fb34803abb4f89b6adba500",
      "b767589d265a4d629d66e0c4f7769386",
      "2eadcce997f749e998a35c72290f2109",
      "8cffdedf39e44b69826af4242b574569",
      "abe87753e4754ea58868499c1e70257e",
      "a3cf169d0eed42899a2d2ce204caf1ac",
      "d4f21332f4b043d4ba7e13850ec6cd1e",
      "ce5de115e86841d1be596ace63b8dac1",
      "78e5d5ad86bc4364b0ca6e8e5f94ea67",
      "0e0af8463310452783113cbab5663c80",
      "68b16dc75e0d471993ecfdfa332c74c6"
     ]
    },
    "outputId": "57481341-ef5b-422c-999c-aa996e022d94"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3a12d4e1cbf41749188cec3bf480eab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e675082c9bc649bd92fac9860a0c6b3e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18663ddea68c436198e539d250be1311"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "mrpc/test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddd1ec3bba3d4ace987790aefbe45b84"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c08171c60d3444c58c16805f3db50d70"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9b27de9ff4848e2a8fa90bd4e2c3548"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae9caff2d4c54b4184ddacfb9d623c31"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "810656e5a88a41cf9ecdf5fefdd13417"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff317d4e84e14279a4d95cdd0f3d4759"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "779ac9080fb34803abb4f89b6adba500"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Experiments"
   ],
   "metadata": {
    "id": "T4oNyr44Q328"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "lr_list = [1e-5, 3e-5, 5e-5]\n",
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ],
   "metadata": {
    "id": "PqytZjpiXnjN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 137"
   ],
   "metadata": {
    "id": "HCp-cKAeb5R8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(137)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "id": "f16tsvQ3G5xt",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "35e813aaae284d71930affbcbf5d7dd0",
      "b5f17d98b0f94ccf9cc2d7c8f430ad0c",
      "d460aaabcedd47f1b57efae62da88c22",
      "5720a2575ec44826a5414363d1d42be2",
      "f6a9c5e31fc54b9a9e9b65689251037f",
      "a49f4791de0e47abbdc3ae1c9f93d1a4",
      "5d0db9192e3e400a97c17dad3283e3f0",
      "cec6a4660f094e7896242227f36eba40",
      "16519cb3d57d42dcb0e41172787eed64",
      "12c8833c64c24a01b7ead21fa114963b",
      "867f13baf2e64f129ecfa9a42ef73aab",
      "ef61fa63bda44fdfbc929e9e550941bc",
      "4bc1424ac5df4b5bb433a3125d5d3a63",
      "fb07633f73be4e6ba982d58bcc7029da",
      "a5a9b1f5d002486085778f503baca70b",
      "41a60911e8a2455e8f03c21ff84e076a",
      "12707715d31e4b80b18174da18fbbb78",
      "52843d43efe046ea90be72ba2ef455b2",
      "8b883f7c04ef436088e01b24aa18bc63",
      "f74350c534a04c10ab975956978e25d0",
      "54463508bd17493d929150ca111c6e73",
      "03de311a64d848a8aa957b3356940c26"
     ]
    },
    "outputId": "275e5367-9e25-4759-802a-b020b26863f5"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35e813aaae284d71930affbcbf5d7dd0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef61fa63bda44fdfbc929e9e550941bc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6667869357242044 --validation loss: 0.6652079060965893 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6108060662263359 --validation loss: 0.604514034355388 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5875314903285249 --validation loss: 0.5804770939490375 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5104838929794453 --validation loss: 0.5008577152210123 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.47521460546517424 --validation loss: 0.47357424684599336 -- validation accuracy 0.7573529411764706\n",
      "Epoch 0 Step 250 -- training loss: 0.3851829305583355 --validation loss: 0.39071178786894856 -- validation accuracy 0.8382352941176471\n",
      "Epoch 0 Step 300 -- training loss: 0.3571056387425768 --validation loss: 0.39046551915360433 -- validation accuracy 0.8382352941176471\n",
      "Epoch 0 Step 350 -- training loss: 0.3150216830987686 --validation loss: 0.34944847328405754 -- validation accuracy 0.8333333333333334\n",
      "Epoch 0 Step 400 -- training loss: 0.2982059477672208 --validation loss: 0.3482222820029539 -- validation accuracy 0.8455882352941176\n",
      "Epoch 0 Step 450 -- training loss: 0.24766258871860494 --validation loss: 0.29184780445169 -- validation accuracy 0.8774509803921569\n",
      "Epoch 0 Step 458 -- training loss: 0.25905178757769937 --validation loss: 0.32777255090574425 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 0 -- training loss: 0.26655995946840133 --validation loss: 0.3392710953804792 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 50 -- training loss: 0.21875902778450765 --validation loss: 0.2968566472842997 -- validation accuracy 0.875\n",
      "Epoch 1 Step 100 -- training loss: 0.218936649599561 --validation loss: 0.3578229873788123 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 150 -- training loss: 0.21165789983971836 --validation loss: 0.3020951506846091 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 200 -- training loss: 0.17018313928911044 --validation loss: 0.29358453420447367 -- validation accuracy 0.875\n",
      "Epoch 1 Step 250 -- training loss: 0.18641327240977087 --validation loss: 0.32615122295843035 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 300 -- training loss: 0.14368284798038553 --validation loss: 0.2717582244316445 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 350 -- training loss: 0.1454044294914876 --validation loss: 0.3162013822801265 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 400 -- training loss: 0.12950348652887092 --validation loss: 0.2635523070234294 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 450 -- training loss: 0.1498972860536252 --validation loss: 0.26148319536564396 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 458 -- training loss: 0.12598305930584378 --validation loss: 0.2937404807547436 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 0 -- training loss: 0.13248747447099787 --validation loss: 0.31123662871472974 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 50 -- training loss: 0.10131756584657141 --validation loss: 0.31662741152788787 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 100 -- training loss: 0.09121056984702211 --validation loss: 0.32763633422334404 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 150 -- training loss: 0.09482923178164561 --validation loss: 0.3361441094939615 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 200 -- training loss: 0.07492017117379668 --validation loss: 0.29925098057434546 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 250 -- training loss: 0.06345434617535221 --validation loss: 0.3321066858091702 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 300 -- training loss: 0.05488637355556975 --validation loss: 0.3696831423154685 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 350 -- training loss: 0.05432085893426318 --validation loss: 0.35029501715382816 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 400 -- training loss: 0.056810701991307645 --validation loss: 0.27531957782476263 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 450 -- training loss: 0.046350186166185116 --validation loss: 0.3447290176306577 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 458 -- training loss: 0.0412168258107176 --validation loss: 0.32772507182066785 -- validation accuracy 0.8970588235294118\n",
      "The best accuracy was 0.8995098039215687 after step 450 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6667869357242044 --validation loss: 0.6652079060965893 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.611308614932374 --validation loss: 0.6050015337326947 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5840976108393119 --validation loss: 0.5767654566203847 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5168867855290182 --validation loss: 0.5071192301955878 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.48207208541808305 --validation loss: 0.48114749467840384 -- validation accuracy 0.7598039215686274\n",
      "Epoch 0 Step 250 -- training loss: 0.3968831540972059 --validation loss: 0.3993559815720016 -- validation accuracy 0.8406862745098039\n",
      "Epoch 0 Step 300 -- training loss: 0.37397385549311546 --validation loss: 0.4044988792316586 -- validation accuracy 0.8333333333333334\n",
      "Epoch 0 Step 350 -- training loss: 0.30822469400392116 --validation loss: 0.3397928906568125 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 400 -- training loss: 0.3073551132382261 --validation loss: 0.3512895178853297 -- validation accuracy 0.8333333333333334\n",
      "Epoch 0 Step 450 -- training loss: 0.2543831991360468 --validation loss: 0.30343349774678546 -- validation accuracy 0.8651960784313726\n",
      "Epoch 0 Step 458 -- training loss: 0.26202480608398554 --validation loss: 0.3337178684624971 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 0 -- training loss: 0.266189583283007 --validation loss: 0.34024184631804627 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 50 -- training loss: 0.23323390423675314 --validation loss: 0.3050836024111977 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 100 -- training loss: 0.22113061705624487 --validation loss: 0.3165080824538189 -- validation accuracy 0.875\n",
      "Epoch 1 Step 150 -- training loss: 0.22283954323068553 --validation loss: 0.30687569563879685 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 200 -- training loss: 0.19200677619049883 --validation loss: 0.3002355766354823 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 250 -- training loss: 0.1966793384435455 --validation loss: 0.3238709566786009 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 300 -- training loss: 0.16680545574520797 --validation loss: 0.2937868794828069 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 350 -- training loss: 0.21250668575394743 --validation loss: 0.39590518176555634 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 400 -- training loss: 0.1553617995242489 --validation loss: 0.2987979312664738 -- validation accuracy 0.875\n",
      "Epoch 1 Step 450 -- training loss: 0.14643882657553442 --validation loss: 0.2781404395788616 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 458 -- training loss: 0.143616490993316 --validation loss: 0.2765580440560977 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 0 -- training loss: 0.14311679354858683 --validation loss: 0.2776455308182859 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 50 -- training loss: 0.13531737885090941 --validation loss: 0.29472282839318115 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 100 -- training loss: 0.11812537607142382 --validation loss: 0.31772030385978084 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 150 -- training loss: 0.1183347764926149 --validation loss: 0.30053601779189765 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 200 -- training loss: 0.10686476921260941 --validation loss: 0.2946400849477333 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 250 -- training loss: 0.10130064698820833 --validation loss: 0.3028039947407795 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 300 -- training loss: 0.10000452684128985 --validation loss: 0.33299270712350515 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 350 -- training loss: 0.09426092640608387 --validation loss: 0.317266693416362 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.0923071481943869 --validation loss: 0.31929154721928726 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 450 -- training loss: 0.09109911154083145 --validation loss: 0.3223485189088273 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 458 -- training loss: 0.09110339210025788 --validation loss: 0.3222329793954451 -- validation accuracy 0.8848039215686274\n",
      "The best accuracy was 0.8946078431372549 after step 350 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6591756247746918 --validation loss: 0.6570563000791213 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6045872434032249 --validation loss: 0.6037704290128222 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6063164926432316 --validation loss: 0.6066348938380971 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6250636219848474 --validation loss: 0.6229115791764914 -- validation accuracy 0.7058823529411765\n",
      "Epoch 0 Step 200 -- training loss: 0.5063443529320178 --validation loss: 0.4988422744414386 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.42094168622119754 --validation loss: 0.4089221083650402 -- validation accuracy 0.8284313725490197\n",
      "Epoch 0 Step 300 -- training loss: 0.3618074394519033 --validation loss: 0.3452436760360119 -- validation accuracy 0.8676470588235294\n",
      "Epoch 0 Step 350 -- training loss: 0.37968750033438337 --validation loss: 0.3709062242916986 -- validation accuracy 0.8700980392156863\n",
      "Epoch 0 Step 400 -- training loss: 0.32009408721996546 --validation loss: 0.3206392344744766 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 450 -- training loss: 0.3703664113525991 --validation loss: 0.3645857391404171 -- validation accuracy 0.8774509803921569\n",
      "Epoch 0 Step 458 -- training loss: 0.32822336669613594 --validation loss: 0.33793178949432046 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 0 -- training loss: 0.32834279266528965 --validation loss: 0.34748198070070324 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 50 -- training loss: 0.2766078537885984 --validation loss: 0.2917821121529913 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 100 -- training loss: 0.2753437895110701 --validation loss: 0.35339019546175704 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 150 -- training loss: 0.24168878629365387 --validation loss: 0.30958647240756776 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 200 -- training loss: 0.24442876246402725 --validation loss: 0.30575847742604273 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.20155328651585805 --validation loss: 0.31069885024472194 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 300 -- training loss: 0.18354346233060936 --validation loss: 0.27550452947616577 -- validation accuracy 0.8995098039215687\n",
      "Epoch 1 Step 350 -- training loss: 0.20795104581931675 --validation loss: 0.3430182312012595 -- validation accuracy 0.875\n",
      "Epoch 1 Step 400 -- training loss: 0.1717978075779731 --validation loss: 0.2689787874034807 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 450 -- training loss: 0.26008299187897077 --validation loss: 0.3480225041800854 -- validation accuracy 0.8382352941176471\n",
      "Epoch 1 Step 458 -- training loss: 0.1736961145741228 --validation loss: 0.27408529072999954 -- validation accuracy 0.875\n",
      "Epoch 2 Step 0 -- training loss: 0.17146625142536392 --validation loss: 0.2792065094645117 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 50 -- training loss: 0.19511688660124157 --validation loss: 0.4329309866161031 -- validation accuracy 0.8602941176470589\n",
      "Epoch 2 Step 100 -- training loss: 0.1270494964318695 --validation loss: 0.3063362475265475 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 150 -- training loss: 0.1241142453680582 --validation loss: 0.33574503820900825 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 200 -- training loss: 0.08965963852330068 --validation loss: 0.2836603015186448 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 250 -- training loss: 0.11844002785265632 --validation loss: 0.39850769042923095 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 300 -- training loss: 0.11655469824030411 --validation loss: 0.31334589915715305 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 350 -- training loss: 0.0805688566063614 --validation loss: 0.3095977190589788 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 400 -- training loss: 0.1040865334944418 --validation loss: 0.36819996202693267 -- validation accuracy 0.8504901960784313\n",
      "Epoch 2 Step 450 -- training loss: 0.0820979426284209 --validation loss: 0.31677740140288485 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 458 -- training loss: 0.07559967187714148 --validation loss: 0.27248223719424475 -- validation accuracy 0.8995098039215687\n",
      "The best accuracy was 0.8995098039215687 after step 300 of epoch 1.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6591756247746918 --validation loss: 0.6570563000791213 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5996672137110841 --validation loss: 0.5985263989252203 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6024950027206105 --validation loss: 0.5991765026952706 -- validation accuracy 0.6862745098039216\n",
      "Epoch 0 Step 150 -- training loss: 0.5394540047658555 --validation loss: 0.5386286924282709 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.49501757180898537 --validation loss: 0.4905316233634949 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 250 -- training loss: 0.49872024149546695 --validation loss: 0.5059807034684163 -- validation accuracy 0.7450980392156863\n",
      "Epoch 0 Step 300 -- training loss: 0.3676024107404524 --validation loss: 0.38787424403662774 -- validation accuracy 0.8137254901960784\n",
      "Epoch 0 Step 350 -- training loss: 0.3229543870651774 --validation loss: 0.33085837909111787 -- validation accuracy 0.8700980392156863\n",
      "Epoch 0 Step 400 -- training loss: 0.3118483647663544 --validation loss: 0.3639081800173895 -- validation accuracy 0.8431372549019608\n",
      "Epoch 0 Step 450 -- training loss: 0.25411034948425876 --validation loss: 0.2795481211414524 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 458 -- training loss: 0.2529141232087267 --validation loss: 0.31161092484698577 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 0 -- training loss: 0.25110222943419336 --validation loss: 0.3106758566938487 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 50 -- training loss: 0.20541537783772143 --validation loss: 0.30180102256218005 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 100 -- training loss: 0.20296935725567583 --validation loss: 0.31732049965135317 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 150 -- training loss: 0.19054974177913145 --validation loss: 0.28524330506722134 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 200 -- training loss: 0.1766007909721701 --validation loss: 0.2778006111655165 -- validation accuracy 0.875\n",
      "Epoch 1 Step 250 -- training loss: 0.148492799105005 --validation loss: 0.31827207810848074 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 300 -- training loss: 0.1274061173166114 --validation loss: 0.2682039056740263 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 350 -- training loss: 0.1240374493303106 --validation loss: 0.3004286214435363 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 400 -- training loss: 0.10482321232952957 --validation loss: 0.2892841241486809 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 450 -- training loss: 0.09619341839271271 --validation loss: 0.2868439665648575 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.08278995125720882 --validation loss: 0.2784144153142823 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 0 -- training loss: 0.08107227654437776 --validation loss: 0.2797835262711434 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.06755313488567544 --validation loss: 0.3373552139223024 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 100 -- training loss: 0.05873489337501548 --validation loss: 0.30538977827995506 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 150 -- training loss: 0.049968352319149215 --validation loss: 0.30982561843862355 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 200 -- training loss: 0.048360465371916336 --validation loss: 0.29150611260796294 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 250 -- training loss: 0.0402679089946299 --validation loss: 0.3066020119369176 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 300 -- training loss: 0.03875250831535005 --validation loss: 0.3357803070091405 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 350 -- training loss: 0.03312940385308287 --validation loss: 0.3286019083747056 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 400 -- training loss: 0.030637029104552602 --validation loss: 0.3373989943955915 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 450 -- training loss: 0.02951527789373596 --validation loss: 0.3359857618845269 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 458 -- training loss: 0.02946559265968623 --validation loss: 0.3355833533067055 -- validation accuracy 0.8897058823529411\n",
      "The best accuracy was 0.8995098039215687 after step 100 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6530743077689526 --validation loss: 0.6504536878828909 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.6041894336931066 --validation loss: 0.6024449187166551 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5668509719418544 --validation loss: 0.5647742415175718 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 150 -- training loss: 0.42323150146501 --validation loss: 0.42123525399787753 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 200 -- training loss: 0.4348972865617743 --validation loss: 0.4295421901578997 -- validation accuracy 0.8088235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.40494480410951933 --validation loss: 0.411915618707152 -- validation accuracy 0.8161764705882353\n",
      "Epoch 0 Step 300 -- training loss: 0.3825738120718589 --validation loss: 0.39533209844547157 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 350 -- training loss: 0.3574557396094264 --validation loss: 0.37554267311797424 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 400 -- training loss: 0.32070217060822026 --validation loss: 0.37963922687020957 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 450 -- training loss: 0.3803612941587932 --validation loss: 0.4032050476354711 -- validation accuracy 0.8186274509803921\n",
      "Epoch 0 Step 458 -- training loss: 0.4375905370124675 --validation loss: 0.47911164011148843 -- validation accuracy 0.7965686274509803\n",
      "Epoch 1 Step 0 -- training loss: 0.4015011631585414 --validation loss: 0.441154216726621 -- validation accuracy 0.8063725490196079\n",
      "Epoch 1 Step 50 -- training loss: 0.29858908573599746 --validation loss: 0.37702354010851946 -- validation accuracy 0.8480392156862745\n",
      "Epoch 1 Step 100 -- training loss: 0.2591186544456172 --validation loss: 0.356641423687631 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 150 -- training loss: 0.22671826798793474 --validation loss: 0.32537726236178593 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 200 -- training loss: 0.2298110322681842 --validation loss: 0.2946387413962215 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 250 -- training loss: 0.2797423103024822 --validation loss: 0.45611835119551886 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 300 -- training loss: 0.20784588399990453 --validation loss: 0.2998984153656399 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 350 -- training loss: 0.197387538249716 --validation loss: 0.3205264193170211 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 400 -- training loss: 0.18815654280447364 --validation loss: 0.3004120357115479 -- validation accuracy 0.875\n",
      "Epoch 1 Step 450 -- training loss: 0.1741484631672664 --validation loss: 0.2941729783573571 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 458 -- training loss: 0.21374815316923562 --validation loss: 0.3301518059098253 -- validation accuracy 0.8480392156862745\n",
      "Epoch 2 Step 0 -- training loss: 0.20957193915247269 --validation loss: 0.3255215905168477 -- validation accuracy 0.8406862745098039\n",
      "Epoch 2 Step 50 -- training loss: 0.1683167680151444 --validation loss: 0.36304988460523974 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 100 -- training loss: 0.14625155020906938 --validation loss: 0.33825836411914695 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 150 -- training loss: 0.15806953385391137 --validation loss: 0.3599427408885722 -- validation accuracy 0.8602941176470589\n",
      "Epoch 2 Step 200 -- training loss: 0.2636123711714006 --validation loss: 0.42513523762132605 -- validation accuracy 0.7794117647058824\n",
      "Epoch 2 Step 250 -- training loss: 0.24074191222989968 --validation loss: 0.38004809340425566 -- validation accuracy 0.8333333333333334\n",
      "Epoch 2 Step 300 -- training loss: 0.14599762587302845 --validation loss: 0.33922758249237256 -- validation accuracy 0.8651960784313726\n",
      "Epoch 2 Step 350 -- training loss: 0.09698788382514727 --validation loss: 0.377468468931814 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 400 -- training loss: 0.1263996231103872 --validation loss: 0.33199714080375786 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 450 -- training loss: 0.09167787538788612 --validation loss: 0.37330013235994414 -- validation accuracy 0.8480392156862745\n",
      "Epoch 2 Step 458 -- training loss: 0.09560915242935367 --validation loss: 0.40548254628026603 -- validation accuracy 0.8480392156862745\n",
      "The best accuracy was 0.8848039215686274 after step 300 of epoch 1.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6530743077689526 --validation loss: 0.6504536878828909 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5885026410773948 --validation loss: 0.5932766123145234 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 100 -- training loss: 0.4981065565204828 --validation loss: 0.5012698307925579 -- validation accuracy 0.7671568627450981\n",
      "Epoch 0 Step 150 -- training loss: 0.6168347671465676 --validation loss: 0.6194208413362503 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 200 -- training loss: 0.4332171979163467 --validation loss: 0.42427294160805495 -- validation accuracy 0.7965686274509803\n",
      "Epoch 0 Step 250 -- training loss: 0.3859522763582876 --validation loss: 0.3772841899418363 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 300 -- training loss: 0.42545673160251707 --validation loss: 0.4165697752260694 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 350 -- training loss: 0.3408134720067053 --validation loss: 0.37901294457854007 -- validation accuracy 0.8308823529411765\n",
      "Epoch 0 Step 400 -- training loss: 0.3704724622634696 --validation loss: 0.44496481931384874 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 450 -- training loss: 0.29990927137694195 --validation loss: 0.36742250482533495 -- validation accuracy 0.8480392156862745\n",
      "Epoch 0 Step 458 -- training loss: 0.23517709479855944 --validation loss: 0.2737598398736879 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 0 -- training loss: 0.24728005707328876 --validation loss: 0.2843869678383949 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 50 -- training loss: 0.2559941659878314 --validation loss: 0.31452473552495824 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 100 -- training loss: 0.21841967946693527 --validation loss: 0.3238362530794214 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 150 -- training loss: 0.23655743015857011 --validation loss: 0.40259606268841264 -- validation accuracy 0.8529411764705882\n",
      "Epoch 1 Step 200 -- training loss: 0.16711989248248552 --validation loss: 0.27616583366020053 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 250 -- training loss: 0.16246530122462505 --validation loss: 0.3155737305607866 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 300 -- training loss: 0.13508811327456324 --validation loss: 0.26652809079079065 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 350 -- training loss: 0.12765649708255736 --validation loss: 0.3029483526616412 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 400 -- training loss: 0.11583572261650237 --validation loss: 0.306852829332153 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 450 -- training loss: 0.12665440497944266 --validation loss: 0.2927870979057808 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 458 -- training loss: 0.10922156755400574 --validation loss: 0.27086746615960317 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 0 -- training loss: 0.10718115784779743 --validation loss: 0.26955338412274915 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 50 -- training loss: 0.07066775502054698 --validation loss: 0.305669809394863 -- validation accuracy 0.9068627450980392\n",
      "Epoch 2 Step 100 -- training loss: 0.07265478683839002 --validation loss: 0.30968978166050626 -- validation accuracy 0.9093137254901961\n",
      "Epoch 2 Step 150 -- training loss: 0.047008308091744666 --validation loss: 0.2773008292572865 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 200 -- training loss: 0.04404588343300664 --validation loss: 0.2798303230665624 -- validation accuracy 0.9068627450980392\n",
      "Epoch 2 Step 250 -- training loss: 0.04074377622792684 --validation loss: 0.34194948727506963 -- validation accuracy 0.9093137254901961\n",
      "Epoch 2 Step 300 -- training loss: 0.03483546386657522 --validation loss: 0.32382122988529577 -- validation accuracy 0.9117647058823529\n",
      "Epoch 2 Step 350 -- training loss: 0.031894118872304776 --validation loss: 0.3219237260773833 -- validation accuracy 0.9093137254901961\n",
      "Epoch 2 Step 400 -- training loss: 0.02862563930147009 --validation loss: 0.3374528541713588 -- validation accuracy 0.9093137254901961\n",
      "Epoch 2 Step 450 -- training loss: 0.026641763733676584 --validation loss: 0.3496471611627688 -- validation accuracy 0.9044117647058824\n",
      "Epoch 2 Step 458 -- training loss: 0.026638173312684296 --validation loss: 0.3501283192673844 -- validation accuracy 0.9044117647058824\n",
      "The best accuracy was 0.9117647058823529 after step 300 of epoch 2.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In the first experiment, we see overfitting after epoch 1. The best result for this experiment is after step 400 of epoch 1, where the validation accuracy was 88.2 and the validation loss is 0.264.\n",
    "\n",
    "In the second experiment, we again see overfitting after epoch 1. The best result for for this experiment is at step 458 of epoch 1, where the validation accuracy is 88.5 and the validation loss is 0.277.\n",
    "\n",
    "In the third experiment, both the train and validation losses starts osciallting after step 300 of epoch 1. Until then, both losses follow the same pattern. Step 300 of epoch 1 is also the step where we have achieve the best result: validation accuracy of 90.0 and the validation loss is 0.276. Thus, we deduce that training until step 300 of epoch 1 is the best option.\n",
    "\n",
    "In the fourth experiment, we can see clear signs of overfitting after epoch 1. Even during epoch 1, we see some oscillations in both train and validation losses, but the losses go down overall. The best result that we get in this experiment is after step 450 of epoch 1, where the validation accuracy is 89.5 and the validation loss is 0.287.\n",
    "\n",
    "In the fifth experiment, we see osciallions in the train and validation losses even in the first epoch. This suggests that the constant learning rate of $5\\times 10^{-5}$ is too large, and hence, we do not consider this experiment.\n",
    "\n",
    "In the sixth experiment, we also see some osillations in the first few steps of epoch 0, though the general trend is losses going down. The best result is after step 458 of epoch 0 as we see some overfitting after step 100 of epoch 1. The validation accuracy and the validation loss after step 458 of epoch 0 are 88.7 and 0.274, respectively.\n",
    "\n",
    "\n",
    "Based on these observations, we conclude that the best result (validation accuracy of 90.0 and validation loss 0.276) is achieved with experiment 3 if we stop after step 300 of epoch 1."
   ],
   "metadata": {
    "id": "pkh82NhnX_1I"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 23"
   ],
   "metadata": {
    "id": "q6BmimuCcHEs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(23)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "id": "B70kkf9UG5DC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ad99b8048f654ed088ff3eb59c779fd3",
      "95a2f390c6ec495d909263577b37fea8",
      "a3b60977b11a4150afa7871a2a0cc8a9",
      "fc4fd36ae3944193be98af11ffaf72d8",
      "8a5892f8509f4e6394815c156ea20156",
      "52960641cf0c43869cf54a3ebeb45d17",
      "ab3b2d8c7c0f4fd3b3b12a6c0f017bfe",
      "326ef886874c4760bf2c95bc24e8a375",
      "3645517db1f24862bc1fd84f8b1d07b8",
      "77aaed885d8b461d9ad04f7ba6c69350",
      "8f75d02178e2463d9613ed3869aaff97",
      "37e6f407fb714a268e9a971838a31ce8",
      "18c1c8d54304420cbe1a3f7b302005cd",
      "9ab8f38b0bb743dfbed48e1d2a8fb097",
      "7d98e0a95d5449d3bb5bb1588b05d840",
      "dbd8f2e715a14c1cbac7a75563c2923f",
      "eb940237abf245fb91ca6a4e0b928456",
      "2b0d8c72f76d48f18774822dbcd19537",
      "8f27be1d58c64e8f9c51e8c6b46feb15",
      "6e1af296499149abb6ec0b9ebaead31a",
      "930fd03fd1d942a7ab546f8bb8d3afd0",
      "c9ac154b86944cbdb03a63f8d8ee66a2"
     ]
    },
    "outputId": "b329679d-a041-4809-c9d8-ad57ba922b19"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad99b8048f654ed088ff3eb59c779fd3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37e6f407fb714a268e9a971838a31ce8"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.7142540099574071 --validation loss: 0.7153000247244742 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.570311360726689 --validation loss: 0.560642758713049 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5881208696915953 --validation loss: 0.5761717227744121 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5373942655285978 --validation loss: 0.5286628329286388 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.5190942451065662 --validation loss: 0.5136880085748785 -- validation accuracy 0.696078431372549\n",
      "Epoch 0 Step 250 -- training loss: 0.4686998418311148 --validation loss: 0.46450843296799005 -- validation accuracy 0.7769607843137255\n",
      "Epoch 0 Step 300 -- training loss: 0.4501490399144054 --validation loss: 0.4550619046477711 -- validation accuracy 0.75\n",
      "Epoch 0 Step 350 -- training loss: 0.36895703992244333 --validation loss: 0.4096969353655974 -- validation accuracy 0.8284313725490197\n",
      "Epoch 0 Step 400 -- training loss: 0.3303338972961201 --validation loss: 0.3622506231653924 -- validation accuracy 0.875\n",
      "Epoch 0 Step 450 -- training loss: 0.35203397651416024 --validation loss: 0.38961823525674205 -- validation accuracy 0.8382352941176471\n",
      "Epoch 0 Step 458 -- training loss: 0.31885760407367303 --validation loss: 0.3462414816021919 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 0 -- training loss: 0.32044130625418327 --validation loss: 0.3465193974621156 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 50 -- training loss: 0.27380957238554693 --validation loss: 0.3332617290537147 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 100 -- training loss: 0.2403296010166991 --validation loss: 0.30035730860396925 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 150 -- training loss: 0.20933946581610147 --validation loss: 0.27999258238603086 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 200 -- training loss: 0.20596007966235572 --validation loss: 0.3072667525825547 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 250 -- training loss: 0.2431799590847331 --validation loss: 0.3816037079976762 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 300 -- training loss: 0.34582758359692195 --validation loss: 0.4297148748940113 -- validation accuracy 0.8063725490196079\n",
      "Epoch 1 Step 350 -- training loss: 0.18758160474837995 --validation loss: 0.3428430627008863 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 400 -- training loss: 0.14333402702264278 --validation loss: 0.24958882773039387 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.12381999345784418 --validation loss: 0.263335103607353 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 458 -- training loss: 0.12339471721887783 --validation loss: 0.2637468321869771 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 0 -- training loss: 0.12122815434287317 --validation loss: 0.2625158256394606 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.08552616439031312 --validation loss: 0.32268036407984646 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 100 -- training loss: 0.08794984682402239 --validation loss: 0.3548926504000145 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 150 -- training loss: 0.12708794468585685 --validation loss: 0.3593650600945979 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 200 -- training loss: 0.0947110481919875 --validation loss: 0.3856234889952283 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.06339193371019056 --validation loss: 0.322092066245044 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 300 -- training loss: 0.08617137166370145 --validation loss: 0.37296495773354726 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 350 -- training loss: 0.05887319742141937 --validation loss: 0.29732650490112456 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.046146586286269276 --validation loss: 0.33851083327888276 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 450 -- training loss: 0.04057633792849619 --validation loss: 0.322172875059586 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 458 -- training loss: 0.06801464210095975 --validation loss: 0.4233149969767706 -- validation accuracy 0.8897058823529411\n",
      "The best accuracy was 0.8995098039215687 after step 450 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.7142540099574071 --validation loss: 0.7153000247244742 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.569115438687256 --validation loss: 0.5595281498104918 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5632154047489166 --validation loss: 0.5549696274832183 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5090930817044119 --validation loss: 0.4985926151275635 -- validation accuracy 0.7156862745098039\n",
      "Epoch 0 Step 200 -- training loss: 0.4451178344279073 --validation loss: 0.4644574575564441 -- validation accuracy 0.7892156862745098\n",
      "Epoch 0 Step 250 -- training loss: 0.38742662795813254 --validation loss: 0.40392495750212204 -- validation accuracy 0.8063725490196079\n",
      "Epoch 0 Step 300 -- training loss: 0.35251127074681593 --validation loss: 0.3634080594661189 -- validation accuracy 0.8578431372549019\n",
      "Epoch 0 Step 350 -- training loss: 0.35305716888066013 --validation loss: 0.416183452249742 -- validation accuracy 0.8406862745098039\n",
      "Epoch 0 Step 400 -- training loss: 0.31823005879496696 --validation loss: 0.34240808637410985 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 450 -- training loss: 0.2907253477584433 --validation loss: 0.35065791766871424 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 458 -- training loss: 0.2736151309314636 --validation loss: 0.3175632999662091 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 0 -- training loss: 0.2755171717803982 --validation loss: 0.31775324280355494 -- validation accuracy 0.875\n",
      "Epoch 1 Step 50 -- training loss: 0.24316468516320056 --validation loss: 0.3175389674473919 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 100 -- training loss: 0.21830696847963438 --validation loss: 0.3015210053646097 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 150 -- training loss: 0.22640752800271596 --validation loss: 0.330345851679643 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 200 -- training loss: 0.19223232183824568 --validation loss: 0.29473477565482553 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.1898838075340476 --validation loss: 0.3186023401132986 -- validation accuracy 0.875\n",
      "Epoch 1 Step 300 -- training loss: 0.18414447872142647 --validation loss: 0.2926919797033656 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 350 -- training loss: 0.22995595459487445 --validation loss: 0.40976131577775177 -- validation accuracy 0.8455882352941176\n",
      "Epoch 1 Step 400 -- training loss: 0.1543849618042249 --validation loss: 0.2851490026303366 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 450 -- training loss: 0.145850803567125 --validation loss: 0.29320723265774695 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 458 -- training loss: 0.14049585092374506 --validation loss: 0.26934224564362974 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 0 -- training loss: 0.14152495345924546 --validation loss: 0.268892084412715 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 50 -- training loss: 0.12490736043652872 --validation loss: 0.2864313627794093 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.11372493544983026 --validation loss: 0.2937246288045072 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 150 -- training loss: 0.10857144087423166 --validation loss: 0.2976084979086676 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 200 -- training loss: 0.10494966321565974 --validation loss: 0.29183488429578786 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 250 -- training loss: 0.10044995696925049 --validation loss: 0.2902046322603436 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 300 -- training loss: 0.09693261711352985 --validation loss: 0.3119678115837422 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 350 -- training loss: 0.09624763255561489 --validation loss: 0.29703765783422426 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 400 -- training loss: 0.09602947630219502 --validation loss: 0.3036341906488672 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 450 -- training loss: 0.09084083049909124 --validation loss: 0.3110174926034376 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 458 -- training loss: 0.09081896784368391 --validation loss: 0.3109422082391878 -- validation accuracy 0.8921568627450981\n",
      "The best accuracy was 0.8995098039215687 after step 350 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.7021817983105811 --validation loss: 0.7027251720428467 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.6268695453283314 --validation loss: 0.6207941501748329 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6196970565646303 --validation loss: 0.6143476226750542 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5418916745902667 --validation loss: 0.5393979467597663 -- validation accuracy 0.7083333333333334\n",
      "Epoch 0 Step 200 -- training loss: 0.5461646745342574 --validation loss: 0.5449736758190042 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.5267239064952127 --validation loss: 0.533180893051858 -- validation accuracy 0.7181372549019608\n",
      "Epoch 0 Step 300 -- training loss: 0.36242993072908947 --validation loss: 0.3726842808080654 -- validation accuracy 0.8455882352941176\n",
      "Epoch 0 Step 350 -- training loss: 0.309373537658801 --validation loss: 0.3235904887391656 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 400 -- training loss: 0.2951652210506089 --validation loss: 0.29475822825642195 -- validation accuracy 0.8799019607843137\n",
      "Epoch 0 Step 450 -- training loss: 0.2685545173378292 --validation loss: 0.29861816822313797 -- validation accuracy 0.8872549019607843\n",
      "Epoch 0 Step 458 -- training loss: 0.2362831545129321 --validation loss: 0.269774877192343 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 0 -- training loss: 0.23304269894600435 --validation loss: 0.26903486354093925 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 50 -- training loss: 0.23733243803962384 --validation loss: 0.2989747283213279 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 100 -- training loss: 0.2530593389324633 --validation loss: 0.29234350501906636 -- validation accuracy 0.875\n",
      "Epoch 1 Step 150 -- training loss: 0.1912172881882305 --validation loss: 0.2512113787599054 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 200 -- training loss: 0.18595605384160752 --validation loss: 0.27945454217785715 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.2485811132410123 --validation loss: 0.4183560997549006 -- validation accuracy 0.8431372549019608\n",
      "Epoch 1 Step 300 -- training loss: 0.2512903300607029 --validation loss: 0.36429278070435805 -- validation accuracy 0.8333333333333334\n",
      "Epoch 1 Step 350 -- training loss: 0.13758663843489355 --validation loss: 0.28540264040816066 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 400 -- training loss: 0.11526766282857308 --validation loss: 0.2640552534265261 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 450 -- training loss: 0.11047934236163212 --validation loss: 0.32604507641757235 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 458 -- training loss: 0.08165117607031967 --validation loss: 0.2733851749194311 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 0 -- training loss: 0.08200629211734972 --validation loss: 0.2725347427139972 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 50 -- training loss: 0.08155537259405832 --validation loss: 0.30915801491880535 -- validation accuracy 0.875\n",
      "Epoch 2 Step 100 -- training loss: 0.09767941279516379 --validation loss: 0.3804957361745776 -- validation accuracy 0.8676470588235294\n",
      "Epoch 2 Step 150 -- training loss: 0.08212031536605736 --validation loss: 0.42471678373769073 -- validation accuracy 0.8651960784313726\n",
      "Epoch 2 Step 200 -- training loss: 0.11702430013172564 --validation loss: 0.558792276557891 -- validation accuracy 0.8627450980392157\n",
      "Epoch 2 Step 250 -- training loss: 0.07376429663229457 --validation loss: 0.4070347167697607 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 300 -- training loss: 0.17080489970076107 --validation loss: 0.5618030758980918 -- validation accuracy 0.8504901960784313\n",
      "Epoch 2 Step 350 -- training loss: 0.04946418609513246 --validation loss: 0.367586499007017 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 400 -- training loss: 0.03578558198428938 --validation loss: 0.4291964195572826 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 450 -- training loss: 0.036925885402790244 --validation loss: 0.29771968941478166 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 458 -- training loss: 0.0397656706120202 --validation loss: 0.33038570457959876 -- validation accuracy 0.8848039215686274\n",
      "The best accuracy was 0.8921568627450981 after step 50 of epoch 1.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.7021817983105811 --validation loss: 0.7027251720428467 -- validation accuracy 0.3161764705882353\n",
      "Epoch 0 Step 50 -- training loss: 0.627975876359898 --validation loss: 0.6220578364297455 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6149656856371686 --validation loss: 0.6084020202066384 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6438113289980587 --validation loss: 0.6429845246614194 -- validation accuracy 0.6911764705882353\n",
      "Epoch 0 Step 200 -- training loss: 0.46577885591126733 --validation loss: 0.4613719328361399 -- validation accuracy 0.7107843137254902\n",
      "Epoch 0 Step 250 -- training loss: 0.48408761980876425 --validation loss: 0.4862403764444239 -- validation accuracy 0.7818627450980392\n",
      "Epoch 0 Step 300 -- training loss: 0.3283048054783692 --validation loss: 0.35080594248047064 -- validation accuracy 0.8504901960784313\n",
      "Epoch 0 Step 350 -- training loss: 0.2803406679905415 --validation loss: 0.32615389932385264 -- validation accuracy 0.8848039215686274\n",
      "Epoch 0 Step 400 -- training loss: 0.29086316459708744 --validation loss: 0.32417165035126255 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 450 -- training loss: 0.22994434635087946 --validation loss: 0.2881790604442358 -- validation accuracy 0.8725490196078431\n",
      "Epoch 0 Step 458 -- training loss: 0.21549352558942467 --validation loss: 0.29605611484936056 -- validation accuracy 0.875\n",
      "Epoch 1 Step 0 -- training loss: 0.21385084956981779 --validation loss: 0.3009361356095064 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 50 -- training loss: 0.20564176726676442 --validation loss: 0.3139782889618301 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 100 -- training loss: 0.19947045190515472 --validation loss: 0.26663872994044246 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 150 -- training loss: 0.16846489809577259 --validation loss: 0.2888405753080459 -- validation accuracy 0.8578431372549019\n",
      "Epoch 1 Step 200 -- training loss: 0.1579946685056882 --validation loss: 0.30571898145318105 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 250 -- training loss: 0.1426276374616648 --validation loss: 0.31765377596500055 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 300 -- training loss: 0.1551678186801946 --validation loss: 0.28592766255286395 -- validation accuracy 0.875\n",
      "Epoch 1 Step 350 -- training loss: 0.14780136870427263 --validation loss: 0.3540809329955236 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 400 -- training loss: 0.09569895214579739 --validation loss: 0.27813478291728627 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.07318026003476501 --validation loss: 0.25992135264381183 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 458 -- training loss: 0.07045465454962388 --validation loss: 0.2441105843320781 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 0 -- training loss: 0.07124165378506894 --validation loss: 0.24370334757601514 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 50 -- training loss: 0.04723563940748207 --validation loss: 0.30698327992143404 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 100 -- training loss: 0.05218170986586648 --validation loss: 0.39671973701664615 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 150 -- training loss: 0.04129226675890143 --validation loss: 0.33288018555864324 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 200 -- training loss: 0.038255140570300265 --validation loss: 0.37816531620246324 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.03331473455473949 --validation loss: 0.3415794192034952 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 300 -- training loss: 0.030272542570782563 --validation loss: 0.33626923703545175 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 350 -- training loss: 0.025957709427074323 --validation loss: 0.33327239066620323 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 400 -- training loss: 0.023730054248529153 --validation loss: 0.3433767211470552 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 450 -- training loss: 0.022590851320868383 --validation loss: 0.34951266573853884 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 458 -- training loss: 0.022568889551954283 --validation loss: 0.3493837623003249 -- validation accuracy 0.9019607843137255\n",
      "The best accuracy was 0.9019607843137255 after step 150 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.69170141479808 --validation loss: 0.6917593350597456 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 50 -- training loss: 0.6289774116477675 --validation loss: 0.6248316677177653 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6403157966848552 --validation loss: 0.6374106991524789 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.6214604548509345 --validation loss: 0.6192934150789299 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 200 -- training loss: 0.6368788792416941 --validation loss: 0.6465162424480214 -- validation accuracy 0.6936274509803921\n",
      "Epoch 0 Step 250 -- training loss: 0.6046194216654451 --validation loss: 0.6004008937115762 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 300 -- training loss: 0.6195854262199277 --validation loss: 0.6125239244863099 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 350 -- training loss: 0.6268263589712529 --validation loss: 0.6401337355959649 -- validation accuracy 0.5465686274509803\n",
      "Epoch 0 Step 400 -- training loss: 0.5162792454812521 --validation loss: 0.5405489067528763 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 450 -- training loss: 0.6383632149441829 --validation loss: 0.6289662046759736 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 458 -- training loss: 0.6339537245515645 --validation loss: 0.6288820207118988 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 0 -- training loss: 0.6348751976858816 --validation loss: 0.6296474945311453 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 50 -- training loss: 0.6429426262970843 --validation loss: 0.6325893513127869 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 100 -- training loss: 0.6461346550704608 --validation loss: 0.6426188817211226 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 150 -- training loss: 0.6332464341504381 --validation loss: 0.6252216731800753 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 200 -- training loss: 0.6342206894052834 --validation loss: 0.6255697315814448 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 250 -- training loss: 0.6417760117900657 --validation loss: 0.6321098033119651 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 300 -- training loss: 0.6313386425083759 --validation loss: 0.6240815643002006 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 350 -- training loss: 0.6484406628769727 --validation loss: 0.6383093046207055 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 400 -- training loss: 0.6306288806571421 --validation loss: 0.623979026780409 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 450 -- training loss: 0.6308647346132981 --validation loss: 0.6237166547307781 -- validation accuracy 0.6838235294117647\n",
      "Epoch 1 Step 458 -- training loss: 0.6321525756180416 --validation loss: 0.6263687850213518 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 0 -- training loss: 0.6322623343249552 --validation loss: 0.6265355611548704 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 50 -- training loss: 0.6160148531523145 --validation loss: 0.6135477745065502 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 100 -- training loss: 0.5735618554558889 --validation loss: 0.579212791779462 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 150 -- training loss: 0.5325908238202138 --validation loss: 0.5261709327791252 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 200 -- training loss: 0.6254588718118231 --validation loss: 0.6185571633133233 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 250 -- training loss: 0.5991395893699463 --validation loss: 0.5954616946332595 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 300 -- training loss: 0.593764373582173 --validation loss: 0.5826132694880167 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 350 -- training loss: 0.5443286147122809 --validation loss: 0.5414536583657358 -- validation accuracy 0.7279411764705882\n",
      "Epoch 2 Step 400 -- training loss: 0.6679626800330896 --validation loss: 0.6627661726054024 -- validation accuracy 0.6862745098039216\n",
      "Epoch 2 Step 450 -- training loss: 0.642777951064972 --validation loss: 0.6326807053650126 -- validation accuracy 0.6838235294117647\n",
      "Epoch 2 Step 458 -- training loss: 0.6362013309090225 --validation loss: 0.6269858175633001 -- validation accuracy 0.6838235294117647\n",
      "The best accuracy was 0.7279411764705882 after step 350 of epoch 2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.69170141479808 --validation loss: 0.6917593350597456 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 50 -- training loss: 0.620305874248995 --validation loss: 0.6138201531241921 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6259580749312258 --validation loss: 0.6200506804036159 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5078704053605044 --validation loss: 0.48243172934242323 -- validation accuracy 0.7892156862745098\n",
      "Epoch 0 Step 200 -- training loss: 0.4566218298504815 --validation loss: 0.46827417889646455 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.4288787281136627 --validation loss: 0.41813012665393307 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 300 -- training loss: 0.354830644505346 --validation loss: 0.3623017443745744 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 350 -- training loss: 0.36040909267345156 --validation loss: 0.3638011931496508 -- validation accuracy 0.8431372549019608\n",
      "Epoch 0 Step 400 -- training loss: 0.3098108535449879 --validation loss: 0.32772499571243924 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 450 -- training loss: 0.2898543721190725 --validation loss: 0.32458125347015904 -- validation accuracy 0.875\n",
      "Epoch 0 Step 458 -- training loss: 0.24293037753122046 --validation loss: 0.29083629127810984 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 0 -- training loss: 0.23665927581829962 --validation loss: 0.29053668290668844 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 50 -- training loss: 0.2489336281933686 --validation loss: 0.30846464356371 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 100 -- training loss: 0.28148241752600356 --validation loss: 0.33197012865075876 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 150 -- training loss: 0.24447171413187496 --validation loss: 0.3317127945814647 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 200 -- training loss: 0.19874625399400336 --validation loss: 0.30269853292288734 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 250 -- training loss: 0.23440271235539828 --validation loss: 0.30237261541918214 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 300 -- training loss: 0.21400667659629924 --validation loss: 0.3378351641928448 -- validation accuracy 0.8504901960784313\n",
      "Epoch 1 Step 350 -- training loss: 0.16250445525220764 --validation loss: 0.31115222552462535 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 400 -- training loss: 0.10867965501207606 --validation loss: 0.23326327092945576 -- validation accuracy 0.9019607843137255\n",
      "Epoch 1 Step 450 -- training loss: 0.09186304245886752 --validation loss: 0.2253339757193245 -- validation accuracy 0.9044117647058824\n",
      "Epoch 1 Step 458 -- training loss: 0.09860031344686393 --validation loss: 0.22798997850394717 -- validation accuracy 0.9044117647058824\n",
      "Epoch 2 Step 0 -- training loss: 0.10335716250817208 --validation loss: 0.23202864770941875 -- validation accuracy 0.9044117647058824\n",
      "Epoch 2 Step 50 -- training loss: 0.0687207391465028 --validation loss: 0.3169313643091157 -- validation accuracy 0.9117647058823529\n",
      "Epoch 2 Step 100 -- training loss: 0.06757286798470442 --validation loss: 0.3330607191778208 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 150 -- training loss: 0.06623927142670427 --validation loss: 0.2974158068068837 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 200 -- training loss: 0.05492434215110276 --validation loss: 0.314197723123738 -- validation accuracy 0.9019607843137255\n",
      "Epoch 2 Step 250 -- training loss: 0.05101893188176709 --validation loss: 0.31491904505802426 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 300 -- training loss: 0.04880390196896872 --validation loss: 0.3600188239737797 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 350 -- training loss: 0.0419729765641431 --validation loss: 0.3316162927989282 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 400 -- training loss: 0.03890674311730073 --validation loss: 0.3411611465362869 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 450 -- training loss: 0.037257113675893766 --validation loss: 0.32648831218316715 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 458 -- training loss: 0.037252366090216725 --validation loss: 0.3263868601244016 -- validation accuracy 0.8946078431372549\n",
      "The best accuracy was 0.9117647058823529 after step 50 of epoch 2.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiment 1, we see a monotonic decrease in the train and validation losses until step 150 of epoch 1. After epoch 1, we see clear signs of overfitting. The best result is achieved at step 150 of epoch 1, where the validation accuracy is 89.7 and the validation loss is 0.280.\n",
    "\n",
    "In experiment 2, we see overfitting after epoch 1. Even though the decrease in losses in not monotonic in epoch 1, both losses follow the same pattern. We conclude that the best result in this experiment is achieved at step 458 of epoch 1. The validation accuracy at this step is 89.7 and the validation loss is 0.269.\n",
    "\n",
    "In experiment 3, we see overfitting even after epoch 0, which suggests that the constant learning rate of $3\\times 10^{-5}$ is too large. The best result is at the end (i.e. step 458) of epoch 0 where the validation accuracy is 88.0 and the validation loss is 0.270.\n",
    "\n",
    "In experiment 4, the best result is at step 100 of epoch 1. After this step, we see signs of overfitting. The validation accuracy and the validation loss at this step are 88.0 and 0.267, respectively.\n",
    "\n",
    "In experiment 5, we do not see any significant learning. The train and validation loss has some oscillations, but losses remain constant overall. The validation accuracy also remained a constant.\n",
    "\n",
    "In experiment 6, we see some oscillations in the lossed in epoch 1, but the overall losses decrease in epoch 1. There is overfitting in epoch 2. The best result is validation accuracy of 90.4 and validation loss of 0.228 at step 458 of epoch 1.\n",
    "\n",
    "Therefore, we conclude that the best result (validation accuracy of 90.4 and validation loss of 0.228) is achieved with experiment 6 when we stop after step 458 of epoch 1."
   ],
   "metadata": {
    "id": "EcD-7D7iVVc3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### With Random seed: 114"
   ],
   "metadata": {
    "id": "HdfrP6QhcJs6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for lr in lr_list:\n",
    "\n",
    "  for lr_scheduler in [False, True]:\n",
    "\n",
    "    set_seed(114)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    trainer_config = {'optimizer' : AdamW,\n",
    "                  'num_epochs' : num_epochs,\n",
    "                  'learning_rate' : lr,\n",
    "                  'lr_scheduler' : lr_scheduler,\n",
    "                  }\n",
    "\n",
    "    trainer = sentence_similarity_trainer(model=model,\n",
    "                      train_dataloader = train_dataloader,\n",
    "                      val_dataloader = val_dataloader,\n",
    "                      device = device,\n",
    "                      trainer_config = trainer_config,\n",
    "                      )\n",
    "\n",
    "    # Running the training loops\n",
    "    print(\"=\"*20, f\"{lr=} and {lr_scheduler = }\", \"=\"*20)\n",
    "    trainer.train()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8012873f53544d28b2349f8550bd2e2a",
      "9eb503f7c1fa4e55a2a17b72bf0315ce",
      "29b67642b07944e4a28e7a6351503adb",
      "7355b4a8ad9f4042b5fb7a8f16837d93",
      "39a8426b2f044c63be868e28f166178e",
      "bbe2b762d6fb45599eefd2db31b38b66",
      "e7310c6dde664add83142cbf8ce51c1a",
      "8b20fabc51614ee8ae31017d99ff2aa0",
      "62d886e3cdb2422eb5758429b3c8c592",
      "3a93df6d21ff4312a6a444459617e630",
      "26c74c27dbe64764adbca5bba5c30fad",
      "32d20ef00c09461e9ef7d94f63c356b9",
      "9779e65d91da4e059ab96a4133b46994",
      "9fffa20b9bdb463aab664d713458eeb2",
      "277fbe1bc0c0419287a357f33254b1b0",
      "b270ae7243fd429a9c68688e3dbb1bad",
      "32a9b4ee700e4d8d9eee450b26e65da0",
      "9ae2599fb8034d14b8897d08e1961e19",
      "e2f381698c0d4600ab5ad0384021c1fd",
      "20719b22bfbc44a2b3493b599981c68b",
      "643bdc3b087f490087c5c1aa8907df06",
      "1143e7de287f4b7b9d94da974b48b9ba"
     ]
    },
    "id": "RgBirVymKtT-",
    "outputId": "868ee738-a9c1-4405-8ee3-a43383137634"
   },
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8012873f53544d28b2349f8550bd2e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d20ef00c09461e9ef7d94f63c356b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/371M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.657562812818681 --validation loss: 0.6554916524419597 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5899746712776051 --validation loss: 0.5860051968518425 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5644156907508576 --validation loss: 0.5607577965540045 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5146728846891773 --validation loss: 0.5062470073793449 -- validation accuracy 0.8014705882352942\n",
      "Epoch 0 Step 200 -- training loss: 0.46132878788740805 --validation loss: 0.4713859317057273 -- validation accuracy 0.7720588235294118\n",
      "Epoch 0 Step 250 -- training loss: 0.42014091817382115 --validation loss: 0.4205445559585796 -- validation accuracy 0.803921568627451\n",
      "Epoch 0 Step 300 -- training loss: 0.3693968091233104 --validation loss: 0.38690899327105166 -- validation accuracy 0.8284313725490197\n",
      "Epoch 0 Step 350 -- training loss: 0.284480366312081 --validation loss: 0.3006444110297689 -- validation accuracy 0.8651960784313726\n",
      "Epoch 0 Step 400 -- training loss: 0.2834746441712566 --validation loss: 0.292084701359272 -- validation accuracy 0.8676470588235294\n",
      "Epoch 0 Step 450 -- training loss: 0.27351516461271735 --validation loss: 0.3207675578693549 -- validation accuracy 0.8676470588235294\n",
      "Epoch 0 Step 458 -- training loss: 0.2754607973600005 --validation loss: 0.32733941173144415 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 0 -- training loss: 0.2751434478758629 --validation loss: 0.3254170373593475 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 50 -- training loss: 0.23921535041158884 --validation loss: 0.3088658513939556 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 100 -- training loss: 0.2044727360598402 --validation loss: 0.28961657157496495 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 150 -- training loss: 0.22561516842656731 --validation loss: 0.3584112349313264 -- validation accuracy 0.875\n",
      "Epoch 1 Step 200 -- training loss: 0.22728793030048766 --validation loss: 0.2894782992262466 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 250 -- training loss: 0.17057083364908862 --validation loss: 0.2903228632229216 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 300 -- training loss: 0.15042016752802792 --validation loss: 0.292179736509627 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 350 -- training loss: 0.14474535487543524 --validation loss: 0.26727087123721255 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 400 -- training loss: 0.14818008865933857 --validation loss: 0.2946402014178388 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 450 -- training loss: 0.13734017264641707 --validation loss: 0.2752265715788977 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 458 -- training loss: 0.11175737593704449 --validation loss: 0.25477627445669737 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 0 -- training loss: 0.1111644345146963 --validation loss: 0.2575051354280874 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.09612159835365408 --validation loss: 0.2534832967920046 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 100 -- training loss: 0.0853060176311982 --validation loss: 0.27300570803858776 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 150 -- training loss: 0.0829385246255705 --validation loss: 0.29114021496007253 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 200 -- training loss: 0.09112745323441598 --validation loss: 0.3606304974916081 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 250 -- training loss: 0.07064105633317548 --validation loss: 0.3013638890366636 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 300 -- training loss: 0.07197636665881882 --validation loss: 0.36303600157592814 -- validation accuracy 0.875\n",
      "Epoch 2 Step 350 -- training loss: 0.08645875678724388 --validation loss: 0.3253879323236498 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 400 -- training loss: 0.07145723076090867 --validation loss: 0.35496666585551756 -- validation accuracy 0.875\n",
      "Epoch 2 Step 450 -- training loss: 0.0574588430279456 --validation loss: 0.3429178032549281 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 458 -- training loss: 0.0521895001806757 --validation loss: 0.34728783893618076 -- validation accuracy 0.8921568627450981\n",
      "The best accuracy was 0.8970588235294118 after step 300 of epoch 1.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== lr=1e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.657562812818681 --validation loss: 0.6554916524419597 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5897375623774684 --validation loss: 0.5852120951110241 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5466042453816773 --validation loss: 0.5454187229567883 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5219028904741886 --validation loss: 0.5200861797613257 -- validation accuracy 0.7181372549019608\n",
      "Epoch 0 Step 200 -- training loss: 0.4625421894271909 --validation loss: 0.4670899343841216 -- validation accuracy 0.7843137254901961\n",
      "Epoch 0 Step 250 -- training loss: 0.5759434616254047 --validation loss: 0.5776195718961603 -- validation accuracy 0.7205882352941176\n",
      "Epoch 0 Step 300 -- training loss: 0.38130468505887166 --validation loss: 0.3955984138244507 -- validation accuracy 0.8308823529411765\n",
      "Epoch 0 Step 350 -- training loss: 0.3872553391507898 --validation loss: 0.42910920697100025 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 400 -- training loss: 0.3571482823922224 --validation loss: 0.3609115016811034 -- validation accuracy 0.8308823529411765\n",
      "Epoch 0 Step 450 -- training loss: 0.3274223581930391 --validation loss: 0.3791461802982524 -- validation accuracy 0.8455882352941176\n",
      "Epoch 0 Step 458 -- training loss: 0.3170074714197572 --validation loss: 0.344916541238918 -- validation accuracy 0.8529411764705882\n",
      "Epoch 1 Step 0 -- training loss: 0.32057594669037265 --validation loss: 0.3443407192826271 -- validation accuracy 0.8553921568627451\n",
      "Epoch 1 Step 50 -- training loss: 0.29422497570977296 --validation loss: 0.34519715260202977 -- validation accuracy 0.8480392156862745\n",
      "Epoch 1 Step 100 -- training loss: 0.2706666175511408 --validation loss: 0.3078879763682683 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 150 -- training loss: 0.2394271387550209 --validation loss: 0.2996230265673469 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 200 -- training loss: 0.3027345347735617 --validation loss: 0.341143386036742 -- validation accuracy 0.8431372549019608\n",
      "Epoch 1 Step 250 -- training loss: 0.2252786866306025 --validation loss: 0.28864971855107474 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 300 -- training loss: 0.20031113034694542 --validation loss: 0.3016068849018684 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 350 -- training loss: 0.20442742807080477 --validation loss: 0.28584066175800915 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 400 -- training loss: 0.21005467236780587 --validation loss: 0.326673890719665 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 450 -- training loss: 0.20337429516066133 --validation loss: 0.2859761868694834 -- validation accuracy 0.8700980392156863\n",
      "Epoch 1 Step 458 -- training loss: 0.17286358903565957 --validation loss: 0.27030859494983567 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 0 -- training loss: 0.17046032818176324 --validation loss: 0.27042638641946454 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 50 -- training loss: 0.15478308983187725 --validation loss: 0.28450060921593334 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 100 -- training loss: 0.14816722700124796 --validation loss: 0.29544585436473 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 150 -- training loss: 0.14664283632006586 --validation loss: 0.31977831837995085 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 200 -- training loss: 0.13918861101558005 --validation loss: 0.28349981561084003 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 250 -- training loss: 0.13949476250128776 --validation loss: 0.33431775902635325 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 300 -- training loss: 0.12467535820227595 --validation loss: 0.3032834591234432 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 350 -- training loss: 0.12207424464130323 --validation loss: 0.2964330030532152 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 400 -- training loss: 0.12036918659343472 --validation loss: 0.2956313363678169 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 450 -- training loss: 0.11967003402910915 --validation loss: 0.2959612642834876 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 458 -- training loss: 0.11947975233745049 --validation loss: 0.29616055743513153 -- validation accuracy 0.8970588235294118\n",
      "The best accuracy was 0.8995098039215687 after step 50 of epoch 2.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6503948523847626 --validation loss: 0.6477908270031798 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5639889576596112 --validation loss: 0.5648062982979942 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.4981486070130126 --validation loss: 0.4912154870290382 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.46128876947174924 --validation loss: 0.478360834367135 -- validation accuracy 0.7892156862745098\n",
      "Epoch 0 Step 200 -- training loss: 0.4300896714731629 --validation loss: 0.45183326070215185 -- validation accuracy 0.803921568627451\n",
      "Epoch 0 Step 250 -- training loss: 0.29606001811560595 --validation loss: 0.32452241502994417 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 300 -- training loss: 0.3270285313133321 --validation loss: 0.3448021739867388 -- validation accuracy 0.8848039215686274\n",
      "Epoch 0 Step 350 -- training loss: 0.2740149050849553 --validation loss: 0.3172207623720169 -- validation accuracy 0.875\n",
      "Epoch 0 Step 400 -- training loss: 0.3703217822693142 --validation loss: 0.37123935728096497 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 450 -- training loss: 0.22290557846102318 --validation loss: 0.278763018256309 -- validation accuracy 0.8848039215686274\n",
      "Epoch 0 Step 458 -- training loss: 0.22799507015605897 --validation loss: 0.28044206722109927 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 0 -- training loss: 0.22846277902199033 --validation loss: 0.2805667835123399 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 50 -- training loss: 0.1845105519327528 --validation loss: 0.27863281848383886 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 100 -- training loss: 0.18003742321351773 --validation loss: 0.2747736776284143 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 150 -- training loss: 0.19455652345227553 --validation loss: 0.359996344451336 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 200 -- training loss: 0.16843283392716207 --validation loss: 0.2673044297981131 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 250 -- training loss: 0.15686781077254117 --validation loss: 0.29129244222798767 -- validation accuracy 0.875\n",
      "Epoch 1 Step 300 -- training loss: 0.11322848358666342 --validation loss: 0.3187726463519913 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 350 -- training loss: 0.12019567773931036 --validation loss: 0.2738437887427269 -- validation accuracy 0.8799019607843137\n",
      "Epoch 1 Step 400 -- training loss: 0.10063100025090257 --validation loss: 0.2914445773954047 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 450 -- training loss: 0.08038647129141557 --validation loss: 0.23751649510699743 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 458 -- training loss: 0.07945973301724346 --validation loss: 0.2713320609090813 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 0 -- training loss: 0.07704308406198256 --validation loss: 0.27044454666639806 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 50 -- training loss: 0.05616069644991885 --validation loss: 0.34450740000123486 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 100 -- training loss: 0.05361879416964623 --validation loss: 0.38782303793556694 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 150 -- training loss: 0.07605612053270076 --validation loss: 0.30662377395977575 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 200 -- training loss: 0.04774014684962604 --validation loss: 0.44714673887367595 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 250 -- training loss: 0.05219017607554304 --validation loss: 0.4643789025448153 -- validation accuracy 0.8651960784313726\n",
      "Epoch 2 Step 300 -- training loss: 0.052893992326367434 --validation loss: 0.38408310846516897 -- validation accuracy 0.8602941176470589\n",
      "Epoch 2 Step 350 -- training loss: 0.07728544351226835 --validation loss: 0.33923272041640445 -- validation accuracy 0.8651960784313726\n",
      "Epoch 2 Step 400 -- training loss: 0.03530062475939325 --validation loss: 0.47043246815241324 -- validation accuracy 0.8774509803921569\n",
      "Epoch 2 Step 450 -- training loss: 0.04264174104466693 --validation loss: 0.3838816836257191 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 458 -- training loss: 0.04209411569873164 --validation loss: 0.436455294812856 -- validation accuracy 0.8676470588235294\n",
      "The best accuracy was 0.8970588235294118 after step 0 of epoch 1.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== lr=3e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6503948523847626 --validation loss: 0.6477908270031798 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5635546353160685 --validation loss: 0.5734213275067946 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.5559465202760593 --validation loss: 0.5535504338788051 -- validation accuracy 0.7769607843137255\n",
      "Epoch 0 Step 150 -- training loss: 0.40484985783046884 --validation loss: 0.410572336584914 -- validation accuracy 0.821078431372549\n",
      "Epoch 0 Step 200 -- training loss: 0.3122581255364522 --validation loss: 0.3331249437349684 -- validation accuracy 0.8578431372549019\n",
      "Epoch 0 Step 250 -- training loss: 0.2841679236094806 --validation loss: 0.35342315224674986 -- validation accuracy 0.8651960784313726\n",
      "Epoch 0 Step 300 -- training loss: 0.24771744119965172 --validation loss: 0.289398949465477 -- validation accuracy 0.8897058823529411\n",
      "Epoch 0 Step 350 -- training loss: 0.19568698781426824 --validation loss: 0.2686780423711182 -- validation accuracy 0.8897058823529411\n",
      "Epoch 0 Step 400 -- training loss: 0.2240786382883852 --validation loss: 0.27657684632668306 -- validation accuracy 0.8823529411764706\n",
      "Epoch 0 Step 450 -- training loss: 0.1862188231784339 --validation loss: 0.2757677873048712 -- validation accuracy 0.8823529411764706\n",
      "Epoch 0 Step 458 -- training loss: 0.18144895370505865 --validation loss: 0.25346771145568175 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 0 -- training loss: 0.1810892587142118 --validation loss: 0.2527196946389535 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 50 -- training loss: 0.14968626995338635 --validation loss: 0.2966011222725844 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 100 -- training loss: 0.13863155899329968 --validation loss: 0.25399326518470167 -- validation accuracy 0.8848039215686274\n",
      "Epoch 1 Step 150 -- training loss: 0.12742559670588338 --validation loss: 0.33205250576686335 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 200 -- training loss: 0.11316777096578369 --validation loss: 0.24646215604654714 -- validation accuracy 0.9019607843137255\n",
      "Epoch 1 Step 250 -- training loss: 0.11253790534659408 --validation loss: 0.27263377818698975 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 300 -- training loss: 0.08958699404970136 --validation loss: 0.3293991672496001 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 350 -- training loss: 0.08907559903415654 --validation loss: 0.2438556680127102 -- validation accuracy 0.9068627450980392\n",
      "Epoch 1 Step 400 -- training loss: 0.08337666123267466 --validation loss: 0.3413159470165185 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 450 -- training loss: 0.048360290196024225 --validation loss: 0.248788983031523 -- validation accuracy 0.8946078431372549\n",
      "Epoch 1 Step 458 -- training loss: 0.045022253258547425 --validation loss: 0.2596822007668807 -- validation accuracy 0.8970588235294118\n",
      "Epoch 2 Step 0 -- training loss: 0.04508912322225053 --validation loss: 0.2625022887471406 -- validation accuracy 0.9044117647058824\n",
      "Epoch 2 Step 50 -- training loss: 0.03186770473340068 --validation loss: 0.29852099691097644 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 100 -- training loss: 0.035726026231412876 --validation loss: 0.3827754547294485 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 150 -- training loss: 0.02968120489110724 --validation loss: 0.3574508259931177 -- validation accuracy 0.8823529411764706\n",
      "Epoch 2 Step 200 -- training loss: 0.035872232483411794 --validation loss: 0.4244959497249083 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 250 -- training loss: 0.027706778573008226 --validation loss: 0.37729005328968496 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 300 -- training loss: 0.021567132766561456 --validation loss: 0.34895955972537834 -- validation accuracy 0.8995098039215687\n",
      "Epoch 2 Step 350 -- training loss: 0.01911381177664055 --validation loss: 0.3522636192216191 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.017267010694502576 --validation loss: 0.3465908168011582 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 450 -- training loss: 0.016593056331968954 --validation loss: 0.3478819660262625 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 458 -- training loss: 0.0165846587878029 --validation loss: 0.3481749145898457 -- validation accuracy 0.8897058823529411\n",
      "The best accuracy was 0.9068627450980392 after step 350 of epoch 1.\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = False ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6437579537528793 --validation loss: 0.6405308632289662 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5854075681539922 --validation loss: 0.5804453649941612 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6949990572233345 --validation loss: 0.697086355265449 -- validation accuracy 0.4362745098039216\n",
      "Epoch 0 Step 150 -- training loss: 0.4270197641356059 --validation loss: 0.41953683542270287 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 200 -- training loss: 0.3696685207516669 --validation loss: 0.361798552905812 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 250 -- training loss: 0.29921283268152626 --validation loss: 0.3049929860029735 -- validation accuracy 0.8725490196078431\n",
      "Epoch 0 Step 300 -- training loss: 0.3199972248715318 --validation loss: 0.36409587895168977 -- validation accuracy 0.8676470588235294\n",
      "Epoch 0 Step 350 -- training loss: 0.24979968704202077 --validation loss: 0.2619040373201464 -- validation accuracy 0.8995098039215687\n",
      "Epoch 0 Step 400 -- training loss: 0.3065135686583249 --validation loss: 0.3434832982865034 -- validation accuracy 0.8848039215686274\n",
      "Epoch 0 Step 450 -- training loss: 0.23091688722956413 --validation loss: 0.30746325076210734 -- validation accuracy 0.8676470588235294\n",
      "Epoch 0 Step 458 -- training loss: 0.23666611373879032 --validation loss: 0.3112259475039501 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 0 -- training loss: 0.23860629339558367 --validation loss: 0.3136870156900555 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 50 -- training loss: 0.30085148449686877 --validation loss: 0.38771625118804914 -- validation accuracy 0.8063725490196079\n",
      "Epoch 1 Step 100 -- training loss: 0.20269221771906143 --validation loss: 0.31172488074676663 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 150 -- training loss: 0.1799339053296121 --validation loss: 0.3216823449029642 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 200 -- training loss: 0.19640820420677885 --validation loss: 0.28260975287241097 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 250 -- training loss: 0.14587826707475454 --validation loss: 0.2990421218541907 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 300 -- training loss: 0.12499130828648984 --validation loss: 0.30950410059634964 -- validation accuracy 0.8676470588235294\n",
      "Epoch 1 Step 350 -- training loss: 0.16547897376915469 --validation loss: 0.2786039008083297 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 400 -- training loss: 0.14953339173385471 --validation loss: 0.38638212824897733 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 450 -- training loss: 0.09267345440121517 --validation loss: 0.2550153271751661 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 458 -- training loss: 0.09147612925229315 --validation loss: 0.26026353999680163 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 0 -- training loss: 0.0887999201927959 --validation loss: 0.26338099852642594 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 50 -- training loss: 0.10714316071053735 --validation loss: 0.3064854835689652 -- validation accuracy 0.8676470588235294\n",
      "Epoch 2 Step 100 -- training loss: 0.09323373288808955 --validation loss: 0.3867893942686565 -- validation accuracy 0.8529411764705882\n",
      "Epoch 2 Step 150 -- training loss: 0.09476317404307757 --validation loss: 0.3600146844206999 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 200 -- training loss: 0.07660545276014807 --validation loss: 0.5293930865089208 -- validation accuracy 0.8578431372549019\n",
      "Epoch 2 Step 250 -- training loss: 0.08417699958272847 --validation loss: 0.3596244669135879 -- validation accuracy 0.8651960784313726\n",
      "Epoch 2 Step 300 -- training loss: 0.07795926010589195 --validation loss: 0.4884806620367967 -- validation accuracy 0.875\n",
      "Epoch 2 Step 350 -- training loss: 0.12285185092552879 --validation loss: 0.3700101915746927 -- validation accuracy 0.8725490196078431\n",
      "Epoch 2 Step 400 -- training loss: 0.052646735768048965 --validation loss: 0.36861413493569867 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 450 -- training loss: 0.04472916952396737 --validation loss: 0.3073322667612457 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 458 -- training loss: 0.04973330701501484 --validation loss: 0.315772477975663 -- validation accuracy 0.8823529411764706\n",
      "The best accuracy was 0.8995098039215687 after step 350 of epoch 0.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==================== lr=5e-05 and lr_scheduler = True ====================\n",
      "Epoch 0 Step 0 -- training loss: 0.6437579537528793 --validation loss: 0.6405308632289662 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 50 -- training loss: 0.5449232753845081 --validation loss: 0.5432528774527943 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.7164638395662661 --validation loss: 0.7205202334067401 -- validation accuracy 0.3946078431372549\n",
      "Epoch 0 Step 150 -- training loss: 0.38416464573222825 --validation loss: 0.3925265924018972 -- validation accuracy 0.7965686274509803\n",
      "Epoch 0 Step 200 -- training loss: 0.3352461500430159 --validation loss: 0.35935068641807516 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 250 -- training loss: 0.30024435040327946 --validation loss: 0.3468008282612644 -- validation accuracy 0.8700980392156863\n",
      "Epoch 0 Step 300 -- training loss: 0.2817195933433919 --validation loss: 0.3196397645435497 -- validation accuracy 0.8651960784313726\n",
      "Epoch 0 Step 350 -- training loss: 0.2316614325971937 --validation loss: 0.27883019532058756 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 400 -- training loss: 0.2251080384392754 --validation loss: 0.28354914048138785 -- validation accuracy 0.8627450980392157\n",
      "Epoch 0 Step 450 -- training loss: 0.18887200466842108 --validation loss: 0.28514149262770716 -- validation accuracy 0.8774509803921569\n",
      "Epoch 0 Step 458 -- training loss: 0.18362383678766508 --validation loss: 0.2560638240447231 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 0 -- training loss: 0.18503748867782502 --validation loss: 0.2554090550425006 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 50 -- training loss: 0.2165323292028995 --validation loss: 0.4006645165465991 -- validation accuracy 0.8504901960784313\n",
      "Epoch 1 Step 100 -- training loss: 0.16501803688648156 --validation loss: 0.30185962534126115 -- validation accuracy 0.8897058823529411\n",
      "Epoch 1 Step 150 -- training loss: 0.1354954726141847 --validation loss: 0.29054807698098467 -- validation accuracy 0.8872549019607843\n",
      "Epoch 1 Step 200 -- training loss: 0.1338352043839062 --validation loss: 0.25443356739831907 -- validation accuracy 0.8921568627450981\n",
      "Epoch 1 Step 250 -- training loss: 0.10004415179852372 --validation loss: 0.2531283571950945 -- validation accuracy 0.9068627450980392\n",
      "Epoch 1 Step 300 -- training loss: 0.10402326698973978 --validation loss: 0.365843708225179 -- validation accuracy 0.8529411764705882\n",
      "Epoch 1 Step 350 -- training loss: 0.08651991927497138 --validation loss: 0.2350258868114621 -- validation accuracy 0.9044117647058824\n",
      "Epoch 1 Step 400 -- training loss: 0.054118736798231835 --validation loss: 0.2907971474889885 -- validation accuracy 0.8823529411764706\n",
      "Epoch 1 Step 450 -- training loss: 0.03238410900766943 --validation loss: 0.30910007922919286 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 458 -- training loss: 0.04926351708951477 --validation loss: 0.3914268595422162 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 0 -- training loss: 0.05023294551998543 --validation loss: 0.3971632532387351 -- validation accuracy 0.875\n",
      "Epoch 2 Step 50 -- training loss: 0.02915567808864691 --validation loss: 0.40293115207939134 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 100 -- training loss: 0.029351712978081798 --validation loss: 0.40478638621896285 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 150 -- training loss: 0.025856397296418688 --validation loss: 0.3978172925845309 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 200 -- training loss: 0.023396550650388297 --validation loss: 0.396587333403409 -- validation accuracy 0.8799019607843137\n",
      "Epoch 2 Step 250 -- training loss: 0.02056768350493394 --validation loss: 0.3903106648700914 -- validation accuracy 0.8872549019607843\n",
      "Epoch 2 Step 300 -- training loss: 0.017881587275985145 --validation loss: 0.39717434801152157 -- validation accuracy 0.8921568627450981\n",
      "Epoch 2 Step 350 -- training loss: 0.017247582727482426 --validation loss: 0.3905204575047737 -- validation accuracy 0.8946078431372549\n",
      "Epoch 2 Step 400 -- training loss: 0.015614072881952995 --validation loss: 0.39211197861175817 -- validation accuracy 0.8897058823529411\n",
      "Epoch 2 Step 450 -- training loss: 0.013977372441729956 --validation loss: 0.38391021712610096 -- validation accuracy 0.8848039215686274\n",
      "Epoch 2 Step 458 -- training loss: 0.013970652380783197 --validation loss: 0.3841046661517455 -- validation accuracy 0.8848039215686274\n",
      "The best accuracy was 0.9068627450980392 after step 250 of epoch 1.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Observations**:\n",
    "\n",
    "In experiment 1, we see some oscillations in the validation loss in epoch 1, but the validation loss goes down overall. After epoch 1, we see clear signs of overfitting. The best result in this experiment is after step 458 of epoch 1, where the validation accuracy is 88.7 and validation loss is 0.255.\n",
    "\n",
    "In experiment 2, we see overfitting in epoch 2. Even though there are oscillations in both of the losses in epoch 1, the losses follow the same pattern and they both go down overall. The result is at step 458 of epoch 1, where the validation accuracy is 89.3 and the validation loss is 0.270.\n",
    "\n",
    "In experiment 3, we see the best result at step 200 of epoch 1, after which we see signs of overfitting. The validation accuracy and validation loss at this step are 89.7 and 0.267, respectively.\n",
    "\n",
    "In experiment 4, we see overfitting after epoch 0, which is slightly confusing. The best result is at step 458 of epoch 0, where the validation accuracy is 89.0 and the validation loss is 0.253.\n",
    "\n",
    "In experiment 5, we see oscillations in the train and validation losses even in epoch 0. Nevertheless, the losses overall go down in epoch 0 and 1. The best result is at step 450 of epoch 1, where the validation accuracy is 89.0 and the validation loss is 0.253.\n",
    "\n",
    "In experiment 6, we see overfitting after step 250 of epoch 1. Until this step, both losses follow the same pattern and they overall go down. The best result is also at this step, where the validation accuracy and validation loss are 90.7 and 0.253, respectively.\n",
    "\n",
    "Based on this analysis, we conclude that the best result are acheived when we stop experiment 6 after step 250 of epoch 1."
   ],
   "metadata": {
    "id": "PDl_zWoteCrB"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "We conclude that the experiment with a random seed of 23 with a linearly decreasing learning rate from $5\\times 10^{-5}$ to zero led to the best result if we stop after step 458 of epoch 1."
   ],
   "metadata": {
    "id": "b9sUJjnGYKLu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Repeating the best performing experiment\n",
    "with the stopping condition to get the\n",
    "model weights and to calculate test accuracy.\n",
    "'''\n",
    "\n",
    "lr = 5e-5\n",
    "lr_scheduler = True\n",
    "num_epochs = 3\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "stopping_condition = {'step': 458, 'epoch': 1}\n",
    "\n",
    "set_seed(23)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "trainer_config = {'optimizer' : AdamW,\n",
    "              'num_epochs' : num_epochs,\n",
    "              'learning_rate' : lr,\n",
    "              'lr_scheduler' : lr_scheduler,\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "trainer = sentence_similarity_trainer(model=model,\n",
    "                  train_dataloader = train_dataloader,\n",
    "                  val_dataloader = val_dataloader,\n",
    "                  device = device,\n",
    "                  trainer_config = trainer_config,\n",
    "                  stopping_condition = stopping_condition,\n",
    "                  )\n",
    "\n",
    "# Running the training loops\n",
    "trainer.train()"
   ],
   "metadata": {
    "id": "69eYbg-aoesB",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "548c3e52-4311-4b7c-8419-387f6de55a15"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 Step 0 -- training loss: 0.69170141479808 --validation loss: 0.6917593350597456 -- validation accuracy 0.7009803921568627\n",
      "Epoch 0 Step 50 -- training loss: 0.620305874248995 --validation loss: 0.6138201531241921 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 100 -- training loss: 0.6259580749312258 --validation loss: 0.6200506804036159 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 150 -- training loss: 0.5078704053605044 --validation loss: 0.48243172934242323 -- validation accuracy 0.7892156862745098\n",
      "Epoch 0 Step 200 -- training loss: 0.4566218298504815 --validation loss: 0.46827417889646455 -- validation accuracy 0.6838235294117647\n",
      "Epoch 0 Step 250 -- training loss: 0.4288787281136627 --validation loss: 0.41813012665393307 -- validation accuracy 0.8357843137254902\n",
      "Epoch 0 Step 300 -- training loss: 0.354830644505346 --validation loss: 0.3623017443745744 -- validation accuracy 0.8602941176470589\n",
      "Epoch 0 Step 350 -- training loss: 0.36040909267345156 --validation loss: 0.3638011931496508 -- validation accuracy 0.8431372549019608\n",
      "Epoch 0 Step 400 -- training loss: 0.3098108535449879 --validation loss: 0.32772499571243924 -- validation accuracy 0.8553921568627451\n",
      "Epoch 0 Step 450 -- training loss: 0.2898543721190725 --validation loss: 0.32458125347015904 -- validation accuracy 0.875\n",
      "Epoch 0 Step 458 -- training loss: 0.24293037753122046 --validation loss: 0.29083629127810984 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 0 -- training loss: 0.23665927581829962 --validation loss: 0.29053668290668844 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 50 -- training loss: 0.2489336281933686 --validation loss: 0.30846464356371 -- validation accuracy 0.8774509803921569\n",
      "Epoch 1 Step 100 -- training loss: 0.28148241752600356 --validation loss: 0.33197012865075876 -- validation accuracy 0.8627450980392157\n",
      "Epoch 1 Step 150 -- training loss: 0.24447171413187496 --validation loss: 0.3317127945814647 -- validation accuracy 0.8602941176470589\n",
      "Epoch 1 Step 200 -- training loss: 0.19874625399400336 --validation loss: 0.30269853292288734 -- validation accuracy 0.8725490196078431\n",
      "Epoch 1 Step 250 -- training loss: 0.23440271235539828 --validation loss: 0.30237261541918214 -- validation accuracy 0.8970588235294118\n",
      "Epoch 1 Step 300 -- training loss: 0.21400667659629924 --validation loss: 0.3378351641928448 -- validation accuracy 0.8504901960784313\n",
      "Epoch 1 Step 350 -- training loss: 0.16250445525220764 --validation loss: 0.31115222552462535 -- validation accuracy 0.8651960784313726\n",
      "Epoch 1 Step 400 -- training loss: 0.10867965501207606 --validation loss: 0.23326327092945576 -- validation accuracy 0.9019607843137255\n",
      "Epoch 1 Step 450 -- training loss: 0.09186304245886752 --validation loss: 0.2253339757193245 -- validation accuracy 0.9044117647058824\n",
      "Epoch 1 Step 458 -- training loss: 0.09860031344686393 --validation loss: 0.22798997850394717 -- validation accuracy 0.9044117647058824\n",
      "The best accuracy was 0.9044117647058824 after step 450 of epoch 1.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Calculating the test loss\n",
    "'''\n",
    "\n",
    "def test_evaluation():\n",
    "\n",
    "    trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "      test_losses = []\n",
    "      test_accuracies = []\n",
    "\n",
    "      for i, batch in enumerate(test_dataloader):\n",
    "\n",
    "        # Getting the batch loss\n",
    "        batch = {k: v.to(trainer.device) for k, v in batch.items()}\n",
    "        outputs = trainer.model(**batch)\n",
    "        test_losses.append(outputs.loss.item())\n",
    "        # Getting the batch accuracy\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        test_accuracy = (predictions == batch['labels']).float().mean()\n",
    "        test_accuracies.append(test_accuracy.item())\n",
    "\n",
    "      avg_test_loss = sum(test_losses) / len(test_losses)\n",
    "      avg_test_accuracy = sum(test_accuracies) / len(test_accuracies)\n",
    "\n",
    "    trainer.model.train()\n",
    "\n",
    "    return avg_test_loss, avg_test_accuracy\n",
    "\n",
    "test_loss, test_acc = test_evaluation()\n",
    "print(f\"{test_loss=}\")\n",
    "print(f\"{test_acc=}\")"
   ],
   "metadata": {
    "id": "zxw7TCStYN7F",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c6dd39c6-5a71-4249-b7db-6eee61e180b3"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test_loss=0.32305042116247396\n",
      "test_acc=0.8715277777777778\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Uploading the weights on HF\n",
    "'''\n",
    "\n",
    "# Save model weights\n",
    "file_name = \"model_weights.pth\"\n",
    "trainer.save_model(file_name)\n",
    "\n",
    "# Logging into Hugging face Hub\n",
    "hf_token = userdata.get('hf_TOKEN')\n",
    "login(token=hf_token)\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = \"mudassirmoosa/sentence-similarity-transformer-comparison\"\n",
    "\n",
    "# Uploading model weights\n",
    "api.upload_file(\n",
    "    path_or_fileobj=file_name,\n",
    "    path_in_repo=\"DeBERTa_for_sentence_similarity.pth\",\n",
    "    repo_id=repo_id,\n",
    "    token=hf_token\n",
    ")\n"
   ],
   "metadata": {
    "id": "tD7HrdqLp1uE",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204,
     "referenced_widgets": [
      "2ff46a2a8f3446b39a2d5113c0f0ec50",
      "a8ff3fb6608446af8d582609c53c24e3",
      "f706c9d6fda946c2968ca69a78bb83c0",
      "a5f968668be543e1aa2a23554dc46ef6",
      "942fdd470bab4f1fa6bc1e5805dab7a6",
      "93affd9071f343ef9bbca0fa28a3c174",
      "16130ea21f28495f8cdca1f567634c1c",
      "c4e1cade98194ed1b5c36aeb25340c66",
      "6f5aaeb0a072409c9e1110a3cd3848e3",
      "6ee5cbfa3e4c4e0e8475f8eb54989a5f",
      "7435ad6916564b48b252f84bcdec78a4",
      "cbfb8b298e664618b87dca0958420470",
      "1dc7965bbca04400ade2993c2cf2e34d",
      "7d02ed4eb4f444fd86a7d91e317e8956",
      "cdb023d0df184c2b92a1188f6388f917",
      "c4227364754949f1b87e150c8217b2f5",
      "1bdb8212e747483dbfae96b673ff4fa7",
      "dc4b242e484c4e659463c07b9f174c7c",
      "461f235c04ee4a7e88d3461d967f0923",
      "6023d9fee597466bb67d18f51346849f",
      "48c3704a336846deb9aac677aae09e85",
      "82dc11edf597403d8989671e45af7b8e",
      "ee8e501852dd453e925a99426071e02e",
      "5183f9ea69074fc5925bb282d587aa92",
      "7f2a77610f404456b993dd8b571afbf2",
      "bfaa3f5b0cca4b21940c161f69201ff9",
      "adfff1e084bf4e6e82b759d5edaedfe9",
      "9764373fa6e64a4da3ef430ed0030371",
      "a975802418354078bef0505f1841573b",
      "a79c1cb0d87244ae83bafe0305353d97",
      "0696ce76ca4b4ab7a322936e27f9deb5",
      "7bd06266cee7475882e163c23dd32694",
      "84942a28f2c04b3fb7b13aa08dfdb4f8"
     ]
    },
    "outputId": "c1400ffc-02a1-4cf7-8736-4ee53a857365"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ff46a2a8f3446b39a2d5113c0f0ec50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "New Data Upload                         : |          |  0.00B /  0.00B            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbfb8b298e664618b87dca0958420470"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  model_weights.pth                     :   0%|          |  555kB /  738MB            "
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee8e501852dd453e925a99426071e02e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mudassirmoosa/sentence-similarity-transformer-comparison/commit/2b526901bcf6255d37b998a3adcf00a9b006ff02', commit_message='Upload DeBERTa_for_sentence_similarity.pth with huggingface_hub', commit_description='', oid='2b526901bcf6255d37b998a3adcf00a9b006ff02', pr_url=None, repo_url=RepoUrl('https://huggingface.co/mudassirmoosa/sentence-similarity-transformer-comparison', endpoint='https://huggingface.co', repo_type='model', repo_id='mudassirmoosa/sentence-similarity-transformer-comparison'), pr_revision=None, pr_num=None)"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  }
 ]
}